{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jax_on_cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fb0rfDrH4nQ",
        "colab_type": "code",
        "outputId": "c4555865-2722-4fa1-ade6-34457fb58c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "!pip install neural-tangents"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: neural-tangents in /usr/local/lib/python3.6/dist-packages (0.1.9)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.6/dist-packages (from neural-tangents) (1.2)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from neural-tangents) (0.7)\n",
            "Requirement already satisfied: jax>=0.1.58 in /usr/local/lib/python3.6/dist-packages (from neural-tangents) (0.1.62)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from jax>=0.1.58->neural-tangents) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.6/dist-packages (from jax>=0.1.58->neural-tangents) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from jax>=0.1.58->neural-tangents) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py->jax>=0.1.58->neural-tangents) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbuYAvktiDw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import itertools\n",
        "\n",
        "import numpy.random as npr\n",
        "\n",
        "import jax.numpy as np\n",
        "from jax.config import config\n",
        "from jax import jit, grad, random\n",
        "from  jax.nn import log_softmax\n",
        "\n",
        "from jax.experimental import optimizers\n",
        "import jax.experimental.stax as jax_stax\n",
        "import neural_tangents.stax as nt_stax\n",
        "\n",
        "import neural_tangents\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.datasets import FashionMNIST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al_eETI_iMnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_to_numpy(dataloader):\n",
        "    X = []\n",
        "    y = []\n",
        "    for batch_id, (cur_X, cur_y) in enumerate(dataloader):\n",
        "        X.extend(cur_X.numpy())\n",
        "        y.extend(cur_y.numpy())\n",
        "    X = np.asarray(X)\n",
        "    y = np.asarray(y)\n",
        "    return X, y\n",
        "\n",
        "def _one_hot(x, k, dtype=np.float32):\n",
        "  \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
        "  return np.array(x[:, None] == np.arange(k), dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxobG2mUlVkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cifar_10():\n",
        "  torch.manual_seed(0)\n",
        "\n",
        "  D = 32\n",
        "  num_classes = 10\n",
        "\n",
        "  torch.manual_seed(0)\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "      device = torch.device('cuda:0')\n",
        "  else:\n",
        "      device = torch.device('cpu')\n",
        "\n",
        "  cifar10_stats = {\n",
        "      \"mean\" : (0.4914, 0.4822, 0.4465),\n",
        "      \"std\"  : (0.24705882352941178, 0.24352941176470588, 0.2615686274509804),\n",
        "  }\n",
        "\n",
        "  simple_transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(cifar10_stats['mean'], cifar10_stats['std']),\n",
        "  ])\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "                    datasets.CIFAR10(root='./data', train=True, download=True, transform=simple_transform),\n",
        "                batch_size=2048, shuffle=True, pin_memory=True)\n",
        "\n",
        "  test_loader  = torch.utils.data.DataLoader(\n",
        "                    datasets.CIFAR10(root='./data', train=False, download=True, transform=simple_transform),\n",
        "                batch_size=2048, shuffle=True, pin_memory=True)\n",
        "  \n",
        "  train_images, train_labels = data_to_numpy(train_loader)\n",
        "  test_images,  test_labels  = data_to_numpy(test_loader)\n",
        "\n",
        "  train_images = np.transpose(train_images, (0, 2, 3, 1))\n",
        "  test_images  = np.transpose(test_images , (0, 2, 3, 1))\n",
        "\n",
        "  train_labels = _one_hot(train_labels, num_classes)\n",
        "  test_labels  = _one_hot(test_labels,  num_classes)\n",
        "  return train_images, train_labels, test_images, test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po4zTFUOlqc_",
        "colab_type": "code",
        "outputId": "f93ad6bd-ef9c-4c6e-9b8e-3b96f95bc4d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "train_images, train_labels, test_images, test_labels = cifar_10()\n",
        "train_images.shape, train_labels.shape, test_images.shape, test_labels.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "CPU times: user 51.2 s, sys: 17.2 s, total: 1min 8s\n",
            "Wall time: 53.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPdVuVLYoXBg",
        "colab_type": "code",
        "outputId": "d7512dab-a0b4-4bf2-af59-107c9a45e8a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_images.shape, train_labels.shape, test_images.shape, test_labels.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 10), (10000, 32, 32, 3), (10000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfZ3JeDRonFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(params, batch):\n",
        "  inputs, targets = batch\n",
        "  preds = predict(params, inputs)\n",
        "  return -np.mean(np.sum(log_softmax(preds, axis=1) * targets, axis=1))\n",
        "\n",
        "def accuracy(params, batch):\n",
        "  inputs, targets = batch\n",
        "  target_class = np.argmax(targets, axis=1)\n",
        "  predicted_class = np.argmax(predict(params, inputs), axis=1)\n",
        "  return np.mean(predicted_class == target_class)\n",
        "\n",
        "@jit\n",
        "def update(i, opt_state, batch):\n",
        "  params = get_params(opt_state)\n",
        "  return opt_update(i, grad(loss)(params, batch), opt_state)\n",
        "\n",
        "rng_state = npr.RandomState(0)\n",
        "\n",
        "def data_stream_of(images, labels, batch_size=500, batch_limit=None):\n",
        "  assert len(images) == len(labels)\n",
        "  rng = npr.RandomState(0)\n",
        "\n",
        "  n = len(images)\n",
        "  perm = rng.permutation(n)\n",
        "  for i in range(n // batch_size):\n",
        "    if (batch_limit is not None) and i >= batch_limit:\n",
        "      break\n",
        "    batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
        "    yield images[batch_idx], labels[batch_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQlpRpDBotR-",
        "colab_type": "code",
        "outputId": "3c4a6e6b-3391-41bd-d384-0c04aa3f82e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "channels = 32\n",
        "num_classes = 10\n",
        "\n",
        "init_random_params, predict = jax_stax.serial(\n",
        "      jax_stax.Conv(channels, (3, 3), padding='SAME'),                jax_stax.BatchNorm(), jax_stax.Relu,\n",
        "      jax_stax.Conv(channels, (3, 3), strides=(2,2), padding='SAME'), jax_stax.BatchNorm(), jax_stax.Relu,\n",
        "      jax_stax.Conv(channels, (3, 3), strides=(2,2), padding='SAME'), jax_stax.BatchNorm(), jax_stax.Relu,\n",
        "      jax_stax.Conv(channels, (3, 3), strides=(2,2), padding='SAME'), jax_stax.BatchNorm(), jax_stax.Relu,\n",
        "      jax_stax.AvgPool((1, 1)),    jax_stax.Flatten, \n",
        "      jax_stax.Dense(num_classes)\n",
        ")\n",
        "rng = random.PRNGKey(0)\n",
        "\n",
        "step_size = 0.05\n",
        "num_epochs = 2\n",
        "batch_size = 500\n",
        "momentum_mass = 0.9\n",
        "\n",
        "opt_init, opt_update, get_params = optimizers.momentum(step_size, mass=momentum_mass)\n",
        "\n",
        "_, init_params = init_random_params(rng, (batch_size, 32, 32, 3))\n",
        "opt_state = opt_init(init_params)\n",
        "itercount = itertools.count()\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "\n",
        "  for batch in data_stream_of(train_images, train_labels):\n",
        "    opt_state = update(next(itercount), opt_state, batch)\n",
        "  params = get_params(opt_state)\n",
        "\n",
        "  train_accs = [accuracy(params, batch) for batch in data_stream_of(train_images, train_labels)]  \n",
        "  train_acc  = np.average(train_accs)\n",
        "  test_accs  = [accuracy(params, batch) for batch in data_stream_of(test_images, test_labels)]  \n",
        "  test_acc   = np.average(test_accs)\n",
        "  \n",
        "  epoch_time = time.time() - start_time\n",
        "\n",
        "  print(f\"Epoch {epoch} in {epoch_time:0.2f} sec\")\n",
        "  print(f\"Training set accuracy {train_acc}\")\n",
        "  print(f\"Test set accuracy {test_acc}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training...\n",
            "Epoch 0 in 15.22 sec\n",
            "Training set accuracy 0.5342999696731567\n",
            "Test set accuracy 0.5160000324249268\n",
            "Epoch 1 in 6.35 sec\n",
            "Training set accuracy 0.6130399703979492\n",
            "Test set accuracy 0.5840000510215759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRZBEgV5sIS6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "4ce11d45-3de0-46e5-a5f2-737fef012c30"
      },
      "source": [
        "channels = 32\n",
        "num_classes = 10\n",
        "\n",
        "init_random_params, predict = jax_stax.serial(\n",
        "      jax_stax.Conv(channels, (3, 3), padding='SAME'),                jax_stax.Relu,\n",
        "      jax_stax.Conv(channels, (3, 3), strides=(2,2), padding='SAME'), jax_stax.Relu,\n",
        "      jax_stax.Conv(channels, (3, 3), strides=(2,2), padding='SAME'), jax_stax.Relu,\n",
        "      jax_stax.Conv(channels, (3, 3), strides=(2,2), padding='SAME'), jax_stax.Relu,\n",
        "      jax_stax.AvgPool((1, 1)),    jax_stax.Flatten, \n",
        "      jax_stax.Dense(num_classes)\n",
        ")\n",
        "rng = random.PRNGKey(0)\n",
        "\n",
        "step_size = 0.05\n",
        "num_epochs = 2\n",
        "momentum_mass = 0.9\n",
        "\n",
        "opt_init, opt_update, get_params = optimizers.momentum(step_size, mass=momentum_mass)\n",
        "\n",
        "_, init_params = init_random_params(rng, (batch_size, 32, 32, 3))\n",
        "opt_state = opt_init(init_params)\n",
        "itercount = itertools.count()\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "\n",
        "  for batch in data_stream_of(train_images, train_labels):\n",
        "    opt_state = update(next(itercount), opt_state, batch)\n",
        "  params = get_params(opt_state)\n",
        "\n",
        "  train_accs = [accuracy(params, batch) for batch in data_stream_of(train_images, train_labels)]  \n",
        "  train_acc  = np.average(train_accs)\n",
        "  test_accs  = [accuracy(params, batch) for batch in data_stream_of(test_images, test_labels)]  \n",
        "  test_acc   = np.average(test_accs)\n",
        "  \n",
        "  epoch_time = time.time() - start_time\n",
        "\n",
        "  print(f\"Epoch {epoch} in {epoch_time:0.2f} sec\")\n",
        "  print(f\"Training set accuracy {train_acc}\")\n",
        "  print(f\"Test set accuracy {test_acc}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training...\n",
            "Epoch 0 in 3.88 sec\n",
            "Training set accuracy 0.46296000480651855\n",
            "Test set accuracy 0.46550002694129944\n",
            "Epoch 1 in 3.19 sec\n",
            "Training set accuracy 0.5372400283813477\n",
            "Test set accuracy 0.5246999859809875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw_2zOQ1JHa-",
        "colab_type": "code",
        "outputId": "1544aa20-085a-47cb-b124-d7164808aee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "channels = 32\n",
        "num_classes = 10\n",
        "\n",
        "init_random_params, predict, _ = nt_stax.serial(\n",
        "      nt_stax.Conv(channels, (3, 3), padding='SAME'),                nt_stax.Relu(),\n",
        "      nt_stax.Conv(channels, (3, 3), strides=(2,2), padding='SAME'), nt_stax.Relu(),\n",
        "      nt_stax.Conv(channels, (3, 3), strides=(2,2), padding='SAME'), nt_stax.Relu(),\n",
        "      nt_stax.Conv(channels, (3, 3), strides=(2,2), padding='SAME'), nt_stax.Relu(),\n",
        "      nt_stax.AvgPool((1, 1)),   nt_stax.Flatten(), \n",
        "      nt_stax.Dense(num_classes)\n",
        ")\n",
        "rng = random.PRNGKey(0)\n",
        "\n",
        "step_size = 10.\n",
        "num_epochs = 10\n",
        "batch_size = 500\n",
        "momentum_mass = 0.9\n",
        "\n",
        "opt_init, opt_update, get_params = optimizers.momentum(step_size, mass=momentum_mass)\n",
        "\n",
        "_, init_params = init_random_params(rng, (batch_size, 32, 32, 3))\n",
        "opt_state = opt_init(init_params)\n",
        "itercount = itertools.count()\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "\n",
        "  for batch in data_stream_of(train_images, train_labels):\n",
        "    opt_state = update(next(itercount), opt_state, batch)\n",
        "  params = get_params(opt_state)\n",
        "\n",
        "  train_accs = [accuracy(params, batch) for batch in data_stream_of(train_images, train_labels)]  \n",
        "  train_acc  = np.average(train_accs)\n",
        "  test_accs  = [accuracy(params, batch) for batch in data_stream_of(test_images, test_labels)]  \n",
        "  test_acc   = np.average(test_accs)\n",
        "  \n",
        "  epoch_time = time.time() - start_time\n",
        "\n",
        "  print(f\"Epoch {epoch} in {epoch_time:0.2f} sec\")\n",
        "  print(f\"Training set accuracy {train_acc}\")\n",
        "  print(f\"Test set accuracy {test_acc}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training...\n",
            "Epoch 0 in 5.73 sec\n",
            "Training set accuracy 0.0\n",
            "Test set accuracy 0.0\n",
            "Epoch 1 in 5.00 sec\n",
            "Training set accuracy 0.0\n",
            "Test set accuracy 0.0\n",
            "Epoch 2 in 4.98 sec\n",
            "Training set accuracy 0.0\n",
            "Test set accuracy 0.0\n",
            "Epoch 3 in 5.13 sec\n",
            "Training set accuracy 0.0\n",
            "Test set accuracy 0.0\n",
            "Epoch 4 in 4.95 sec\n",
            "Training set accuracy 0.0\n",
            "Test set accuracy 0.0\n",
            "Epoch 5 in 4.91 sec\n",
            "Training set accuracy 0.0\n",
            "Test set accuracy 0.0\n",
            "Epoch 6 in 4.89 sec\n",
            "Training set accuracy 0.0\n",
            "Test set accuracy 0.0\n",
            "Epoch 7 in 4.89 sec\n",
            "Training set accuracy 0.0\n",
            "Test set accuracy 0.0\n",
            "Epoch 8 in 4.89 sec\n",
            "Training set accuracy 0.0\n",
            "Test set accuracy 0.0\n",
            "Epoch 9 in 4.95 sec\n",
            "Training set accuracy 0.0\n",
            "Test set accuracy 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z46NcGJd3HxL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "8da66fb7-a011-42a6-85d2-05b169755ea8"
      },
      "source": [
        "num_classes = 10\n",
        "\n",
        "def WideResnetBlock(channels, strides=(1, 1), channel_mismatch=False):\n",
        "  Main = nt_stax.serial(\n",
        "      nt_stax.Relu(), nt_stax.Conv(channels, (3, 3), strides, padding='SAME'),\n",
        "      nt_stax.Relu(), nt_stax.Conv(channels, (3, 3), padding='SAME')\n",
        "  )\n",
        "  Shortcut = nt_stax.Identity() if not channel_mismatch else nt_stax.Conv(channels, (3, 3), strides, padding='SAME')\n",
        "  return nt_stax.serial(nt_stax.FanOut(2),\n",
        "                        nt_stax.parallel(Main, Shortcut),\n",
        "                        nt_stax.FanInSum())\n",
        "\n",
        "def WideResnetGroup(n, channels, strides=(1, 1)):\n",
        "  blocks = []\n",
        "  blocks += [WideResnetBlock(channels, strides, channel_mismatch=True)]\n",
        "  for _ in range(n - 1):\n",
        "    blocks += [WideResnetBlock(channels, (1, 1))]\n",
        "  return nt_stax.serial(*blocks)\n",
        "\n",
        "def WideResnet(num_classes, num_channels=32, block_size=1):\n",
        "  return nt_stax.serial(\n",
        "      nt_stax.Conv(num_channels, (3, 3), padding='SAME'),\n",
        "      WideResnetGroup(block_size, num_channels),\n",
        "      WideResnetGroup(block_size, num_channels, (2, 2)),\n",
        "      WideResnetGroup(block_size, num_channels, (2, 2)),\n",
        "      nt_stax.Relu(),\n",
        "      nt_stax.AvgPool((1, 1)),\n",
        "      nt_stax.Flatten(),\n",
        "      nt_stax.Dense(num_classes)\n",
        "  )\n",
        "\n",
        "init_random_params, predict, _ = WideResnet(num_classes)\n",
        "\n",
        "rng = random.PRNGKey(0)\n",
        "\n",
        "step_size = 10.\n",
        "num_epochs = 10\n",
        "momentum_mass = 0.9\n",
        "\n",
        "opt_init, opt_update, get_params = optimizers.momentum(step_size, mass=momentum_mass)\n",
        "\n",
        "_, init_params = init_random_params(rng, (batch_size, 32, 32, 3))\n",
        "opt_state = opt_init(init_params)\n",
        "itercount = itertools.count()\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "\n",
        "  for batch in data_stream_of(train_images, train_labels):\n",
        "    opt_state = update(next(itercount), opt_state, batch)\n",
        "  params = get_params(opt_state)\n",
        "\n",
        "  train_accs = [accuracy(params, batch) for batch in data_stream_of(train_images, train_labels, batch_limit=4)]  \n",
        "  train_acc  = np.average(train_accs)\n",
        "  test_accs  = [accuracy(params, batch) for batch in data_stream_of(test_images, test_labels, batch_limit=4)]  \n",
        "  test_acc   = np.average(test_accs)\n",
        "  \n",
        "  epoch_time = time.time() - start_time\n",
        "\n",
        "  print(f\"Epoch {epoch} in {epoch_time:0.2f} sec\")\n",
        "  print(f\"Training set accuracy {train_acc}\")\n",
        "  print(f\"Test set accuracy {test_acc}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training...\n",
            "Epoch 0 in 5.48 sec\n",
            "Training set accuracy 0.4625000059604645\n",
            "Test set accuracy 0.4825000464916229\n",
            "Epoch 1 in 5.48 sec\n",
            "Training set accuracy 0.5559999942779541\n",
            "Test set accuracy 0.5355000495910645\n",
            "Epoch 2 in 5.46 sec\n",
            "Training set accuracy 0.5850000381469727\n",
            "Test set accuracy 0.562999963760376\n",
            "Epoch 3 in 5.45 sec\n",
            "Training set accuracy 0.6270000338554382\n",
            "Test set accuracy 0.5889999866485596\n",
            "Epoch 4 in 5.47 sec\n",
            "Training set accuracy 0.6610000133514404\n",
            "Test set accuracy 0.6050000190734863\n",
            "Epoch 5 in 5.49 sec\n",
            "Training set accuracy 0.6920000314712524\n",
            "Test set accuracy 0.6365000605583191\n",
            "Epoch 6 in 5.53 sec\n",
            "Training set accuracy 0.7000000476837158\n",
            "Test set accuracy 0.6355000138282776\n",
            "Epoch 7 in 5.55 sec\n",
            "Training set accuracy 0.7105000019073486\n",
            "Test set accuracy 0.6390000581741333\n",
            "Epoch 8 in 5.51 sec\n",
            "Training set accuracy 0.7260000109672546\n",
            "Test set accuracy 0.6405000686645508\n",
            "Epoch 9 in 5.48 sec\n",
            "Training set accuracy 0.722000002861023\n",
            "Test set accuracy 0.6260000467300415\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}