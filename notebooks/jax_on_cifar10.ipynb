{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jax_on_cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fb0rfDrH4nQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "da6784ff-1a8d-43b9-b337-9ad8317bc75e"
      },
      "source": [
        "!pip install neural-tangents"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: neural-tangents in /usr/local/lib/python3.6/dist-packages (0.1.9)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.6/dist-packages (from neural-tangents) (1.2)\n",
            "Requirement already satisfied: jax>=0.1.58 in /usr/local/lib/python3.6/dist-packages (from neural-tangents) (0.1.62)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from neural-tangents) (0.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from jax>=0.1.58->neural-tangents) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from jax>=0.1.58->neural-tangents) (1.18.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.6/dist-packages (from jax>=0.1.58->neural-tangents) (3.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py->jax>=0.1.58->neural-tangents) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbuYAvktiDw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import itertools\n",
        "\n",
        "import numpy.random as npr\n",
        "\n",
        "import jax.numpy as np\n",
        "from jax.config import config\n",
        "from jax import jit, grad, random\n",
        "from jax.experimental import optimizers\n",
        "\n",
        "import jax.experimental.stax as ostax\n",
        "from neural_tangents import stax\n",
        "\n",
        "import neural_tangents\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.datasets import FashionMNIST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al_eETI_iMnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_to_numpy(dataloader):\n",
        "    X = []\n",
        "    y = []\n",
        "    for batch_id, (cur_X, cur_y) in enumerate(dataloader):\n",
        "        X.extend(cur_X.numpy())\n",
        "        y.extend(cur_y.numpy())\n",
        "    X = np.asarray(X)\n",
        "    y = np.asarray(y)\n",
        "    return X, y\n",
        "\n",
        "def _one_hot(x, k, dtype=np.float32):\n",
        "  \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
        "  return np.array(x[:, None] == np.arange(k), dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxobG2mUlVkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cifar_10():\n",
        "  torch.manual_seed(0)\n",
        "\n",
        "  D = 32\n",
        "  num_classes = 10\n",
        "\n",
        "  torch.manual_seed(0)\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "      device = torch.device('cuda:0')\n",
        "  else:\n",
        "      device = torch.device('cpu')\n",
        "\n",
        "  cifar10_stats = {\n",
        "      \"mean\" : (0.4914, 0.4822, 0.4465),\n",
        "      \"std\"  : (0.24705882352941178, 0.24352941176470588, 0.2615686274509804),\n",
        "  }\n",
        "\n",
        "  simple_transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(cifar10_stats['mean'], cifar10_stats['std']),\n",
        "  ])\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "                    datasets.CIFAR10(root='./data', train=True, download=True, transform=simple_transform),\n",
        "                batch_size=2048, shuffle=True, pin_memory=True)\n",
        "\n",
        "  test_loader  = torch.utils.data.DataLoader(\n",
        "                    datasets.CIFAR10(root='./data', train=False, download=True, transform=simple_transform),\n",
        "                batch_size=2048, shuffle=True, pin_memory=True)\n",
        "  \n",
        "  train_images, train_labels = data_to_numpy(train_loader)\n",
        "  test_images,  test_labels  = data_to_numpy(test_loader)\n",
        "\n",
        "  train_images = np.transpose(train_images, (0, 2, 3, 1))\n",
        "  test_images  = np.transpose(test_images , (0, 2, 3, 1))\n",
        "\n",
        "  train_labels = _one_hot(train_labels, num_classes)\n",
        "  test_labels  = _one_hot(test_labels,  num_classes)\n",
        "  return train_images, train_labels, test_images, test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po4zTFUOlqc_",
        "colab_type": "code",
        "outputId": "97e5fe53-fb9e-4ced-9187-50482df2026e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "train_images, train_labels, test_images, test_labels = cifar_10()\n",
        "train_images.shape, train_labels.shape, test_images.shape, test_labels.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "CPU times: user 56.7 s, sys: 18.1 s, total: 1min 14s\n",
            "Wall time: 1min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPdVuVLYoXBg",
        "colab_type": "code",
        "outputId": "6cb249d5-4d83-4e33-81b9-618a0b17edbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_images.shape, train_labels.shape, test_images.shape, test_labels.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 10), (10000, 32, 32, 3), (10000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfZ3JeDRonFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(params, batch):\n",
        "  inputs, targets = batch\n",
        "  preds = predict(params, inputs)\n",
        "  return -np.mean(np.sum(preds * targets, axis=1))\n",
        "\n",
        "def accuracy(params, batch):\n",
        "  inputs, targets = batch\n",
        "  target_class = np.argmax(targets, axis=1)\n",
        "  predicted_class = np.argmax(predict(params, inputs), axis=1)\n",
        "  return np.mean(predicted_class == target_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQlpRpDBotR-",
        "colab_type": "code",
        "outputId": "052747a9-5bda-443a-acdb-a9d4421a8a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "channels = 32\n",
        "num_classes = 10\n",
        "\n",
        "init_random_params, predict = ostax.serial(\n",
        "      ostax.Conv(channels, (3, 3), padding='SAME'),                ostax.BatchNorm(), ostax.Relu,\n",
        "      ostax.Conv(channels, (3, 3), strides=(2,2), padding='SAME'), ostax.BatchNorm(), ostax.Relu,\n",
        "      ostax.Conv(channels, (3, 3), strides=(2,2), padding='SAME'), ostax.BatchNorm(), ostax.Relu,\n",
        "      ostax.Conv(channels, (3, 3), strides=(2,2), padding='SAME'), ostax.BatchNorm(), ostax.Relu,\n",
        "      ostax.AvgPool((1, 1)),    ostax.Flatten, \n",
        "      ostax.Dense(num_classes), ostax.LogSoftmax\n",
        ")\n",
        "rng = random.PRNGKey(0)\n",
        "\n",
        "step_size = 0.05\n",
        "num_epochs = 2\n",
        "batch_size = 500\n",
        "momentum_mass = 0.9\n",
        "\n",
        "def data_stream_of(images, labels):\n",
        "  assert len(images) == len(labels)\n",
        "  rng = npr.RandomState(0)\n",
        "\n",
        "  n = len(images)\n",
        "  perm = rng.permutation(n)\n",
        "  for i in range(n // batch_size):\n",
        "    batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
        "    yield images[batch_idx], labels[batch_idx]\n",
        "\n",
        "opt_init, opt_update, get_params = optimizers.momentum(step_size, mass=momentum_mass)\n",
        "\n",
        "@jit\n",
        "def update(i, opt_state, batch):\n",
        "  params = get_params(opt_state)\n",
        "  return opt_update(i, grad(loss)(params, batch), opt_state)\n",
        "\n",
        "_, init_params = init_random_params(rng, (batch_size, 32, 32, 3))\n",
        "opt_state = opt_init(init_params)\n",
        "itercount = itertools.count()\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "\n",
        "  for batch in data_stream_of(train_images, train_labels):\n",
        "    opt_state = update(next(itercount), opt_state, batch)\n",
        "  params = get_params(opt_state)\n",
        "\n",
        "  train_accs = [accuracy(params, batch) for batch in data_stream_of(train_images, train_labels)]  \n",
        "  train_acc  = np.average(train_accs)\n",
        "  test_accs  = [accuracy(params, batch) for batch in data_stream_of(test_images, test_labels)]  \n",
        "  test_acc   = np.average(test_accs)\n",
        "  \n",
        "  epoch_time = time.time() - start_time\n",
        "\n",
        "  print(f\"Epoch {epoch} in {epoch_time:0.2f} sec\")\n",
        "  print(f\"Training set accuracy {train_acc}\")\n",
        "  print(f\"Test set accuracy {test_acc}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training...\n",
            "Epoch 0 in 8.78 sec\n",
            "Training set accuracy 0.5424399971961975\n",
            "Test set accuracy 0.5254001021385193\n",
            "Epoch 1 in 6.65 sec\n",
            "Training set accuracy 0.6125800013542175\n",
            "Test set accuracy 0.5837000608444214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw_2zOQ1JHa-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "dc5b1f15-109e-46bd-8f71-f2f572cdcb2b"
      },
      "source": [
        "channels = 32\n",
        "num_classes = 10\n",
        "\n",
        "init_random_params, predict = ostax.serial(\n",
        "      stax.Conv(channels, (3, 3), padding='SAME'),                stax.Relu(),\n",
        "      stax.Conv(channels, (3, 3), strides=(2,2), padding='SAME'), stax.Relu(),\n",
        "      stax.Conv(channels, (3, 3), strides=(2,2), padding='SAME'), stax.Relu(),\n",
        "      stax.Conv(channels, (3, 3), strides=(2,2), padding='SAME'), stax.Relu(),\n",
        "      stax.AvgPool((1, 1)), stax.Flatten(), \n",
        "      stax.Dense(num_classes), ostax.LogSoftmax,\n",
        ")\n",
        "rng = random.PRNGKey(0)\n",
        "\n",
        "step_size = 0.05\n",
        "num_epochs = 10\n",
        "batch_size = 500\n",
        "momentum_mass = 0.9\n",
        "\n",
        "def data_stream_of(images, labels):\n",
        "  assert len(images) == len(labels)\n",
        "  rng = npr.RandomState(0)\n",
        "\n",
        "  n = len(images)\n",
        "  perm = rng.permutation(n)\n",
        "  for i in range(n // batch_size):\n",
        "    batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
        "    yield images[batch_idx], labels[batch_idx]\n",
        "\n",
        "opt_init, opt_update, get_params = optimizers.momentum(step_size, mass=momentum_mass)\n",
        "\n",
        "@jit\n",
        "def update(i, opt_state, batch):\n",
        "  params = get_params(opt_state)\n",
        "  return opt_update(i, grad(loss)(params, batch), opt_state)\n",
        "\n",
        "_, init_params = init_random_params(rng, (batch_size, 32, 32, 3))\n",
        "opt_state = opt_init(init_params)\n",
        "itercount = itertools.count()\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "\n",
        "  for batch in data_stream_of(train_images, train_labels):\n",
        "    opt_state = update(next(itercount), opt_state, batch)\n",
        "  params = get_params(opt_state)\n",
        "\n",
        "  train_accs = [accuracy(params, batch) for batch in data_stream_of(train_images, train_labels)]  \n",
        "  train_acc  = np.average(train_accs)\n",
        "  test_accs  = [accuracy(params, batch) for batch in data_stream_of(test_images, test_labels)]  \n",
        "  test_acc   = np.average(test_accs)\n",
        "  \n",
        "  epoch_time = time.time() - start_time\n",
        "\n",
        "  print(f\"Epoch {epoch} in {epoch_time:0.2f} sec\")\n",
        "  print(f\"Training set accuracy {train_acc}\")\n",
        "  print(f\"Test set accuracy {test_acc}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training...\n",
            "Epoch 0 in 6.94 sec\n",
            "Training set accuracy 0.11660000681877136\n",
            "Test set accuracy 0.11510000377893448\n",
            "Epoch 1 in 5.46 sec\n",
            "Training set accuracy 0.13234001398086548\n",
            "Test set accuracy 0.13300000131130219\n",
            "Epoch 2 in 5.31 sec\n",
            "Training set accuracy 0.14414000511169434\n",
            "Test set accuracy 0.14420002698898315\n",
            "Epoch 3 in 5.30 sec\n",
            "Training set accuracy 0.15338000655174255\n",
            "Test set accuracy 0.1527000069618225\n",
            "Epoch 4 in 5.24 sec\n",
            "Training set accuracy 0.163100004196167\n",
            "Test set accuracy 0.16040001809597015\n",
            "Epoch 5 in 5.27 sec\n",
            "Training set accuracy 0.17414000630378723\n",
            "Test set accuracy 0.1704999953508377\n",
            "Epoch 6 in 5.27 sec\n",
            "Training set accuracy 0.19156000018119812\n",
            "Test set accuracy 0.1883000135421753\n",
            "Epoch 7 in 5.25 sec\n",
            "Training set accuracy 0.21338000893592834\n",
            "Test set accuracy 0.20910003781318665\n",
            "Epoch 8 in 5.33 sec\n",
            "Training set accuracy 0.22944000363349915\n",
            "Test set accuracy 0.22550003230571747\n",
            "Epoch 9 in 5.32 sec\n",
            "Training set accuracy 0.24201999604701996\n",
            "Test set accuracy 0.24170003831386566\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}