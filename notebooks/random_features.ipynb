{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import urllib.request\n",
    "\n",
    "def download_repo(url, save_to):\n",
    "    zip_filename = save_to + '.zip'\n",
    "    urllib.request.urlretrieve(url, zip_filename)\n",
    "    \n",
    "    if os.path.exists(save_to):\n",
    "        shutil.rmtree(save_to)\n",
    "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "    del zip_ref\n",
    "    assert os.path.exists(save_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_PATH = 'LinearizedNNs-master'\n",
    "\n",
    "# download_repo(url='https://github.com/maxkvant/LinearizedNNs/archive/master.zip', save_to=REPO_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(f\"{REPO_PATH}/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "from estimator import Estimator\n",
    "from pytorch_impl.estimators import SgdEstimator\n",
    "from pytorch_impl.nns import Myrtle5, Myrtle7, Myrtle10\n",
    "from pytorch_impl import ClassifierTraining\n",
    "from pytorch_impl.matrix_exp import matrix_exp, compute_exp_term\n",
    "from pytorch_impl.nns.utils import to_one_hot, print_sizes\n",
    "from from_neural_kernels import to_zca, CustomTensorDataset, get_cifar_zca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if (torch.cuda.is_available()) else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cifar 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GpEstimator(Estimator):\n",
    "    def __init__(self, models, n_classes, learning_rate, x_example, device):\n",
    "        super(GpEstimator, self).__init__()\n",
    "        self.models    = models\n",
    "        self.lr        = learning_rate\n",
    "        self.n_classes = n_classes\n",
    "        self.device    = device\n",
    "        \n",
    "        n = len(models)\n",
    "        X = torch.stack([x_example]).to(device)\n",
    "        \n",
    "        model = models[0].to(device)\n",
    "        readout_size = model.readout(X).size()[1]\n",
    "    \n",
    "        # TODO: Assert that models have the same readout size\n",
    "        \n",
    "        self.w      = torch.zeros([n, readout_size, n_classes]).to(device)\n",
    "        self.w_size = n * readout_size \n",
    "        \n",
    "    def get_w_update(self, X, right_vector):\n",
    "        with torch.no_grad():\n",
    "            assert len(X) == len(right_vector)\n",
    "\n",
    "            X            = X.to(self.device)\n",
    "            right_vector = right_vector.to(self.device)\n",
    "\n",
    "            n = len(X)\n",
    "            w_updates = []\n",
    "            \n",
    "            for model in models:\n",
    "                features = self.to_model_features(X, model)\n",
    "                update = torch.matmul(features.T, right_vector)\n",
    "                w_updates.append(update)\n",
    "            return torch.stack(w_updates)\n",
    "                                  \n",
    "    def to_model_features(self, X, model):\n",
    "        with torch.no_grad():\n",
    "            model = model.to(device)\n",
    "            return model.readout(X) * (1. / np.sqrt(self.w_size))\n",
    "        \n",
    "    def calc_kernel(self, X):\n",
    "        with torch.no_grad():\n",
    "            X = X.to(device)\n",
    "            \n",
    "            res = torch.zeros([len(X), len(X)]).to(device)\n",
    "            for model in models:\n",
    "                features_x = self.to_model_features(X, model)\n",
    "                \n",
    "                res += torch.matmul(features_x, features_x.T)\n",
    "            return res\n",
    "        \n",
    "    def calc_kernels(self, X_train, X_test):\n",
    "        with torch.no_grad():\n",
    "            X_train = X_train.to(device)\n",
    "            X_test  = X_test.to(device)\n",
    "            \n",
    "            res_train = torch.zeros([len(X_train), len(X_train)]).to(device)\n",
    "            res_test  = torch.zeros([len(X_test),  len(X_train)]).to(device)\n",
    "            for model in models:\n",
    "                features_train = self.to_model_features(X_train, model)\n",
    "                features_test  = self.to_model_features(X_test,  model)\n",
    "                \n",
    "                res_train += torch.matmul(features_train, features_train.T)\n",
    "                res_test  += torch.matmul(features_test,  features_train.T)\n",
    "            return res_train, res_test\n",
    "            \n",
    "    def predict(self, X):\n",
    "        X = X.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            n = len(X)\n",
    "            res = torch.zeros([n, self.n_classes]).to(device)\n",
    "\n",
    "            for model, w in zip(models, self.w):\n",
    "                features = self.to_model_features(X, model)\n",
    "                res += torch.matmul(features, w)\n",
    "            return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_right_vector(kernel, y, learning_rate=1e4, reg_param=0):\n",
    "    with torch.no_grad():\n",
    "        y      = y.to(device)\n",
    "        kernel = kernel.to(device)\n",
    "        \n",
    "        n      = len(kernel)\n",
    "        reg = torch.eye(n).to(device) * reg_param\n",
    "        \n",
    "        exp_term = - learning_rate * compute_exp_term(- learning_rate * (kernel + reg), device)\n",
    "        right_vector = torch.matmul(exp_term, - y)\n",
    "        return right_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "CPU times: user 3min 49s, sys: 1min 4s, total: 4min 54s\n",
      "Wall time: 44.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train, labels_train, X_test, labels_test = get_cifar_zca()\n",
    "\n",
    "N_train = 12800\n",
    "N_test  = 1000\n",
    "\n",
    "X_train      = torch.tensor(X_train[:N_train]).float()\n",
    "labels_train = torch.tensor(labels_train[:N_train], dtype=torch.long)\n",
    "\n",
    "X_test       = torch.tensor(X_test[:N_test]).float()\n",
    "labels_test  = torch.tensor(labels_test[:N_test],  dtype=torch.long)\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "y_train = to_one_hot(labels_train, num_classes).to(device)\n",
    "y_test  = to_one_hot(labels_test,  num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxkvant/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "cifar_train = CustomTensorDataset(torch.tensor(X_train), torch.tensor(labels_train, dtype=torch.long), transform='all')\n",
    "train_loader = torch.utils.data.DataLoader(cifar_train, batch_size=1280)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 ======================= \n",
      "train_acc 0.09921874850988388\n",
      "batch_0 took 57.80506658554077s\n",
      "\n",
      "train_acc 0.09140624850988388\n",
      "batch_1 took 55.33869671821594s\n",
      "\n",
      "train_acc 0.1328125\n",
      "batch_2 took 55.32820272445679s\n",
      "\n",
      "train_acc 0.09296875447034836\n",
      "batch_3 took 55.33759117126465s\n",
      "\n",
      "train_acc 0.09375\n",
      "batch_4 took 55.329872846603394s\n",
      "\n",
      "train_acc 0.1171875\n",
      "batch_5 took 55.33920168876648s\n",
      "\n",
      "train_acc 0.09765625\n",
      "batch_6 took 55.32954454421997s\n",
      "\n",
      "train_acc 0.17734375596046448\n",
      "batch_7 took 55.33659553527832s\n",
      "\n",
      "train_acc 0.09375\n",
      "batch_8 took 55.32691836357117s\n",
      "\n",
      "train_acc 0.17499999701976776\n",
      "batch_9 took 55.34224081039429s\n",
      "\n",
      "iter 0 done, test_acc = 0.1120000034570694\n",
      "iter 1 ======================= \n",
      "train_acc 0.11015625298023224\n",
      "batch_0 took 55.32840847969055s\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-9519a5e3e32e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"train_acc {train_acc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-3e9447a2e52e>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_model_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-3e9447a2e52e>\u001b[0m in \u001b[0;36mto_model_features\u001b[0;34m(self, X, model)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalc_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_models = 5000\n",
    "\n",
    "models = [Myrtle5(num_filters=32) for _ in range(n_models)]\n",
    "\n",
    "learning_rate = 0.2\n",
    "estimator = GpEstimator(models, num_classes, learning_rate, X_train[0], device)\n",
    "\n",
    "n_iter = 20\n",
    "\n",
    "for iter_ in range(n_iter):\n",
    "    print(f\"iter {iter_} ======================= \")\n",
    "    \n",
    "    for batch_i, (X, labels) in enumerate(train_loader):\n",
    "        batch_start = time.time()\n",
    "        \n",
    "        X      = X.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        y_pred = estimator.predict(X)\n",
    "        train_acc = (y_pred.argmax(dim=1) == labels).float().mean().item()\n",
    "        print(f\"train_acc {train_acc}\")\n",
    "        \n",
    "        y_pred.requires_grad = True\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()(y_pred, labels)\n",
    "        loss.backward()\n",
    "        grad = y_pred.grad\n",
    "        \n",
    "        estimator.w += -learning_rate * estimator.get_w_update(X, grad)\n",
    "        \n",
    "        print(f\"batch_{batch_i} took {time.time() - batch_start:0}s\")\n",
    "        print()\n",
    "        \n",
    "    y_pred = estimator.predict(X_test)\n",
    "    test_acc = (y_pred.argmax(dim=1) == labels_test.to(device)).float().mean().item()\n",
    "    print(f\"iter {iter_} done, test_acc = {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X_train, labels_train, X_test, labels_test = get_cifar_zca()\n",
    "\n",
    "N = 1280\n",
    "\n",
    "X_train      = torch.tensor(X_train[:N]).float()\n",
    "X_test       = torch.tensor(X_test[:N]).float()\n",
    "labels_train = torch.tensor(labels_train[:N], dtype=torch.long)\n",
    "labels_test  = torch.tensor(labels_test[:N],  dtype=torch.long)\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "y_train = to_one_hot(labels_train, num_classes).to(device)\n",
    "y_test  = to_one_hot(labels_test,  num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = 5000\n",
    "\n",
    "models = [Myrtle5(num_filters=32) for _ in range(n_models)]\n",
    "\n",
    "estimator = GpEstimator(models, num_classes, 1e4, X_train[0], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6102)\n",
      "\n",
      "CPU times: user 1min 16s, sys: 25.5 s, total: 1min 42s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_kernel, test_kernel = estimator.calc_kernels(X_train, X_test)\n",
    "\n",
    "right_vector = calc_right_vector(train_kernel, y_train, learning_rate=1e5, reg_param=0)\n",
    "y_pred = torch.matmul(test_kernel, right_vector).argmax(dim=1)\n",
    "\n",
    "test_acc = (y_pred.cpu() == labels_test).float().mean()\n",
    "print(test_acc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 32, 10])\n",
      "\n",
      "CPU times: user 34.7 s, sys: 14.7 s, total: 49.4 s\n",
      "Wall time: 49.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w_update = estimator.get_w_update(X_train, right_vector)\n",
    "\n",
    "print(w_update.size())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.w = w_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6102)\n",
      "\n",
      "CPU times: user 35.2 s, sys: 14.9 s, total: 50.1 s\n",
      "Wall time: 50 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_pred = estimator.predict(X_test).argmax(dim=1)\n",
    "\n",
    "test_acc = (y_pred.cpu() == labels_test).float().mean()\n",
    "print(test_acc)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
