{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run-jax-exampe.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvV7-8FG3zdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import itertools\n",
        "\n",
        "import numpy as regurlar_np\n",
        "import numpy.random as npr\n",
        "\n",
        "import jax.numpy as np\n",
        "from jax.config import config\n",
        "from jax import jit, grad, random\n",
        "from jax.experimental import optimizers\n",
        "from jax.experimental import stax\n",
        "from jax.experimental.stax import Dense, Relu, LogSoftmax\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.datasets import FashionMNIST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOMNgaEa5Nqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_to_numpy(dataloader, flatten=True):\n",
        "    X = []\n",
        "    y = []\n",
        "    for batch_id, (cur_X, cur_y) in enumerate(dataloader):\n",
        "        X.extend(cur_X.numpy())\n",
        "        y.extend(cur_y.numpy())\n",
        "    X = np.asarray(X)\n",
        "    y = np.asarray(y)\n",
        "    if flatten:\n",
        "        l = len(X)\n",
        "        X = X.reshape(l, -1)\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBiXkqQQ6D4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _one_hot(x, k, dtype=np.float32):\n",
        "  \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
        "  return np.array(x[:, None] == np.arange(k), dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyk8OuYL5ZSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fashionMnist():\n",
        "  torch.manual_seed(0)\n",
        "\n",
        "  D = 28\n",
        "  num_classes = 10\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "    FashionMNIST(root='.', train=True, download=True,\n",
        "          transform=transforms.ToTensor()),\n",
        "    batch_size=4096, shuffle=True, pin_memory=True)\n",
        "\n",
        "  test_loader = torch.utils.data.DataLoader(\n",
        "    FashionMNIST(root='.', train=False, transform=transforms.ToTensor()),\n",
        "    batch_size=4096, shuffle=True, pin_memory=True)\n",
        "  \n",
        "  train_images, train_labels = data_to_numpy(train_loader)\n",
        "  test_images,  test_labels  = data_to_numpy(test_loader)\n",
        "\n",
        "  train_labels = _one_hot(train_labels, num_classes)\n",
        "  test_labels  = _one_hot(test_labels,  num_classes)\n",
        "  return train_images, train_labels, test_images, test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzQHOtfI6Vvl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c6291306-92d9-4a49-dc3e-9210f74b69d4"
      },
      "source": [
        "%%time\n",
        "\n",
        "train_images, train_labels, test_images, test_labels = fashionMnist()\n",
        "train_images.shape, train_labels.shape, test_images.shape, test_labels.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 53.6 s, sys: 17.9 s, total: 1min 11s\n",
            "Wall time: 55 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRAHZR8N8MNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(params, batch):\n",
        "  inputs, targets = batch\n",
        "  preds = predict(params, inputs)\n",
        "  return -np.mean(np.sum(preds * targets, axis=1))\n",
        "\n",
        "def accuracy(params, batch):\n",
        "  inputs, targets = batch\n",
        "  target_class = np.argmax(targets, axis=1)\n",
        "  predicted_class = np.argmax(predict(params, inputs), axis=1)\n",
        "  return np.mean(predicted_class == target_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8sYPp-E1Q2y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "fe442edb-f010-444b-fdc6-2319bb95a1ac"
      },
      "source": [
        "init_random_params, predict = stax.serial(\n",
        "    Dense(1024), Relu,\n",
        "    Dense(1024), Relu,\n",
        "    Dense(10), LogSoftmax)\n",
        "\n",
        "rng = random.PRNGKey(0)\n",
        "\n",
        "step_size = 0.001\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "momentum_mass = 0.9\n",
        "\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "num_train = train_images.shape[0]\n",
        "num_complete_batches, leftover = divmod(num_train, batch_size)\n",
        "num_batches = num_complete_batches + bool(leftover)\n",
        "\n",
        "def data_stream():\n",
        "  rng = npr.RandomState(0)\n",
        "  while True:\n",
        "    perm = rng.permutation(num_train)\n",
        "    for i in range(num_batches):\n",
        "      batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
        "      yield train_images[batch_idx], train_labels[batch_idx]\n",
        "batches = data_stream()\n",
        "\n",
        "opt_init, opt_update, get_params = optimizers.momentum(step_size, mass=momentum_mass)\n",
        "\n",
        "@jit\n",
        "def update(i, opt_state, batch):\n",
        "  params = get_params(opt_state)\n",
        "  return opt_update(i, grad(loss)(params, batch), opt_state)\n",
        "\n",
        "_, init_params = init_random_params(rng, (-1, 28 * 28))\n",
        "opt_state = opt_init(init_params)\n",
        "itercount = itertools.count()\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "  for _ in range(num_batches):\n",
        "    opt_state = update(next(itercount), opt_state, next(batches))\n",
        "  epoch_time = time.time() - start_time\n",
        "\n",
        "  params = get_params(opt_state)\n",
        "  train_acc = accuracy(params, (train_images, train_labels))\n",
        "  test_acc = accuracy(params, (test_images, test_labels))\n",
        "  print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
        "  print(\"Training set accuracy {}\".format(train_acc))\n",
        "  print(\"Test set accuracy {}\".format(test_acc))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000, 10)\n",
            "\n",
            "Starting training...\n",
            "Epoch 0 in 6.60 sec\n",
            "Training set accuracy 0.781166672706604\n",
            "Test set accuracy 0.7704000473022461\n",
            "Epoch 1 in 3.53 sec\n",
            "Training set accuracy 0.8212500214576721\n",
            "Test set accuracy 0.807200014591217\n",
            "Epoch 2 in 3.44 sec\n",
            "Training set accuracy 0.831933319568634\n",
            "Test set accuracy 0.8203000426292419\n",
            "Epoch 3 in 3.53 sec\n",
            "Training set accuracy 0.8410166501998901\n",
            "Test set accuracy 0.8296000361442566\n",
            "Epoch 4 in 3.46 sec\n",
            "Training set accuracy 0.8459500074386597\n",
            "Test set accuracy 0.835900068283081\n",
            "Epoch 5 in 3.30 sec\n",
            "Training set accuracy 0.8499000072479248\n",
            "Test set accuracy 0.836400032043457\n",
            "Epoch 6 in 3.56 sec\n",
            "Training set accuracy 0.8526666760444641\n",
            "Test set accuracy 0.8388000130653381\n",
            "Epoch 7 in 3.41 sec\n",
            "Training set accuracy 0.8567166924476624\n",
            "Test set accuracy 0.8438000679016113\n",
            "Epoch 8 in 3.39 sec\n",
            "Training set accuracy 0.8595499992370605\n",
            "Test set accuracy 0.8446000218391418\n",
            "Epoch 9 in 3.50 sec\n",
            "Training set accuracy 0.8629000186920166\n",
            "Test set accuracy 0.8466000556945801\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}