{"nbformat":4,"nbformat_minor":5,"metadata":{"notebookId":"499571cd-7ec2-44ca-b6b5-53ba7a0f55ea","language_info":{"mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py","version":"3.7.7"},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"}},"cells":[{"cell_type":"code","source":"#!g1.1\nimport time\nimport numpy as np\nimport seaborn as sns\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport random\nfrom sklearn.utils.extmath import randomized_svd\n\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms, datasets\nfrom torch import utils\nfrom torch.utils.data import TensorDataset, DataLoader\n\nfrom linearized_nns.estimator import Estimator\nfrom linearized_nns.pytorch_impl.estimators import SgdEstimator\nfrom linearized_nns.pytorch_impl.nns import Myrtle5, Myrtle7, Myrtle10\nfrom linearized_nns.pytorch_impl import ClassifierTraining\nfrom linearized_nns.pytorch_impl.matrix_exp import matrix_exp, compute_exp_term\nfrom linearized_nns.pytorch_impl.nns.utils import to_one_hot, print_sizes\nfrom linearized_nns.from_neural_kernels import to_zca, CustomTensorDataset, get_cifar_zca\nfrom sklearn.utils.extmath import randomized_svd\n\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier\n\nimport tqdm","metadata":{"cellId":"rk2v0dxoxe9g9fjx4lq8p","trusted":true},"outputs":[],"execution_count":31},{"cell_type":"code","source":"#!g1.1\nDEVICE = 'cuda'\nNUM_CLASSES = 200\nTRAIN_DIR = 'tiny-imagenet-200/train'\nTEST_DIR  = 'tiny-imagenet-200/val'","metadata":{"cellId":"2wl9tmxrcgsw155mxrq3a","trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"#!g1.1\ndef to_zca_faster(train, test, zca_bias=0.01, n_components=1000):\n    print('faster zca')\n    orig_train_shape = train.shape\n    orig_test_shape = test.shape\n\n    train = np.ascontiguousarray(train, dtype=np.float32).reshape(train.shape[0], -1).astype(np.float64)\n    test  = np.ascontiguousarray(test, dtype=np.float32).reshape(test.shape[0], -1).astype(np.float64)\n\n    n_train = train.shape[0]\n    d       = train.shape[1]\n\n    # Zero mean every feature\n    train = train - np.mean(train, axis=1)[:,np.newaxis]\n    test  =  test - np.mean(test, axis=1)[:,np.newaxis]\n\n    # Normalize\n    train_norms = np.linalg.norm(train, axis=1)\n    test_norms  = np.linalg.norm(test, axis=1)\n\n    # Make features unit norm\n    train = train/train_norms[:,np.newaxis]\n    test  = test/test_norms[:,np.newaxis]\n    \n    print(train[0])\n    \n    print('calculating svd...')\n    \n    _, S, V = randomized_svd(train, n_components=n_components)\n    print('svd calculated. applying svd matricies.')\n    S = (S ** 2) / n_train + zca_bias\n    inv_sqrt_zca_eigs = np.diag(np.power(S, -1))\n\n    train = (train).dot(V.T).dot(inv_sqrt_zca_eigs).dot(V)\n    test  =  (test).dot(V.T).dot(inv_sqrt_zca_eigs).dot(V)\n    \n    print('faster zca done.')\n\n    return (train.reshape(orig_train_shape).astype(np.float64), test.reshape(orig_test_shape).astype(np.float64))\n","metadata":{"cellId":"w4mr7oqllibs9trq7wip8","trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#!g1.1\n\ndef get_tiny_imagenet_zca(train_dir, test_dir):\n    print('getting tiny-imagenet zca:')\n    np.random.seed(0)\n    random.seed(0)\n    torch.manual_seed(0)\n    \n    print('loading datasets...')\n    \n    trainset = datasets.ImageFolder(train_dir, transform=transforms.ToTensor()) \n    testset  = datasets.ImageFolder(test_dir, transform=transforms.ToTensor())\n    \n    trainloader = utils.data.DataLoader(trainset, pin_memory=True, shuffle=True, batch_size=100000)\n    testloader  = utils.data.DataLoader(testset,  pin_memory=True, shuffle=False, batch_size=10000)\n    \n    _, (X_train, y_train)  = next(enumerate(trainloader))\n    _, (X_test,  y_test)   = next(enumerate(testloader))\n    \n    print('datasets loaded.')\n    \n    X_train = X_train.numpy().astype(np.float64)\n    X_test  = X_test.numpy().astype(np.float64)\n    \n    print('calculating zca...')\n    X_train, X_test = to_zca_faster(X_train, X_test, n_components=3000)\n    print('zca_calulated.')\n    return torch.tensor(X_train), y_train, torch.tensor(X_test), y_test","metadata":{"cellId":"6pp5g5j4y96ayfzbq1nc1q","trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#!g1.1\n\nX_train_full, labels_train_full, X_test_full, labels_test_full = get_tiny_imagenet_zca(TRAIN_DIR, TEST_DIR)","metadata":{"cellId":"f51rkoug4pg96r5r3ldl","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"getting tiny-imagenet zca:\nloading datasets...\ndatasets loaded.\ncalculating zca...\nfaster zca\n[-0.00336678 -0.00447899 -0.00429362 ... -0.01170834 -0.01263518\n -0.01393276]\ncalculating svd...\ngetting tiny-imagenet zca:\nloading datasets...\ndatasets loaded.\ncalculating zca...\nfaster zca\n[-0.00336678 -0.00447899 -0.00429362 ... -0.01170834 -0.01263518\n -0.01393276]\ncalculating svd...\nsvd calculated. applying svd matricies.\nfaster zca done.\nzca_calulated.\n"}],"execution_count":5},{"cell_type":"code","source":"#!g1.1\n\nfrom linearized_nns.pytorch_impl.nns.primitives import *\n\nclass Myrtle9(nn.Module):\n    def __init__(self, num_classes=1, input_filters=3, num_filters=1, groups=1):\n        super(Myrtle9, self).__init__()\n        filters = num_filters\n\n        def Activation():\n            return ReLU2()\n\n        self.layers = nn.Sequential(\n            Conv(input_filters, filters * groups), Activation(),\n            Conv(filters, filters * 2, groups),    Activation(),\n            nn.AvgPool2d(kernel_size=2, stride=2),\n\n            Conv(filters * 2, filters * 4, groups), Activation(),\n            Conv(filters * 4, filters * 8, groups), Activation(),\n            nn.AvgPool2d(kernel_size=2, stride=2),\n\n            Conv(filters *  8, filters * 16, groups), Activation(),\n            Conv(filters * 16, filters * 32, groups), Activation(),\n            nn.AvgPool2d(kernel_size=2, stride=2),\n            \n            Conv(filters *  32, filters * 32, groups), Activation(),\n            Conv(filters *  32, filters * 32, groups), Activation(),\n            nn.AvgPool2d(kernel_size=8, stride=8),\n\n            Flatten(),\n            Normalize(filters * 32)\n        )\n        self.classifier = nn.Linear(filters * 32 * groups, num_classes, bias=True)\n\n    def readout(self, x):\n        return self.layers(x)\n\n    def forward(self, x):\n        x = self.readout(x)\n        return self.classifier(x)","metadata":{"cellId":"dcidpf19wbvxuzg9ggqu","trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#!g1.1\n\nN_train = 1280 * 5\nN_test  = 1000\n\nX_train = X_train_full[:N_train].float()\nX_test  = X_test_full[:N_test].float()\n\nlabels_train = labels_train_full[:N_train] \nlabels_test  = labels_test_full[:N_test]\n\ny_train = to_one_hot(labels_train, NUM_CLASSES).to(DEVICE)\ny_test  = to_one_hot(labels_test,  NUM_CLASSES).to(DEVICE)","metadata":{"cellId":"p9frfn1ynsm6akbntshf5i","trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"#!g1.1\nnp.random.seed(0)\nrandom.seed(0)\ntorch.manual_seed(0)\n\nn_models = 50\nmodels = [Myrtle9(num_filters=1, groups=10) for _ in range(n_models)]\n\ndef to_rf(X, models):\n    X_rf = []\n    X = X.to(DEVICE)\n\n    for model_i, model in enumerate(models):\n        with torch.no_grad():\n            torch.cuda.empty_cache() \n            if model_i & (model_i - 1) == 0:\n                print(f\"{model_i} models done.\")\n            model = model.to(DEVICE)\n\n            features = model.readout(X).cpu()\n            X_rf.append(features)\n            \n    return torch.cat(X_rf, dim=1)\n\nX_train_rf = to_rf(X_train, models)\nX_test_rf  = to_rf(X_test, models)","metadata":{"cellId":"e48je85xcaci8j0wg5fnz","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"}],"execution_count":19},{"cell_type":"code","source":"#!g1.1\ntrain_kernel = torch.mm(X_train_rf, X_train_rf.T)","metadata":{"cellId":"mdmtdkipoqnunmwz6t8rp","trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"#!g1.1\nn = len(X_train_rf)\n\nU, D, Ut = randomized_svd(train_kernel.cpu().numpy(), n_components=n)\nprint(U.shape, D.shape, Ut.shape)","metadata":{"cellId":"ynvzm44djzhgsuptzi8li","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"(6400, 6400) (6400,) (6400, 6400)\n"}],"execution_count":21},{"cell_type":"code","source":"#!g1.1\nU = torch.tensor(U)","metadata":{"cellId":"7tqo8e1zaslzmq4pdqffn9","trusted":true},"outputs":[],"execution_count":22},{"cell_type":"code","source":"#!g1.1\n\nVT = torch.mm(U.T, X_train_rf)\nVT.shape","metadata":{"cellId":"qa5l14di9qjlx9ch87in","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"torch.Size([6400, 160000])"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"#!g1.1\neps = 0.01\n\nVT /= VT.norm(dim=1, keepdim=True)\nV = VT.T","metadata":{"cellId":"yuo99o0dk5a3agsxi7kzai","trusted":true},"outputs":[],"execution_count":62},{"cell_type":"code","source":"#!g1.1\n\nV.shape","metadata":{"cellId":"u2he4tohukfxhax3y2ect","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"torch.Size([160000, 6400])"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"#!g1.1\nN = len(X_train_full)\n\ndef to_pca(X, V_pca, models, batch_size = 1000):\n    N = len(X)\n    batch_size = 1000\n    X_pca = []\n    for l in tqdm.tqdm(range(0, N, batch_size)):\n        r = min(N, l + batch_size)\n        X_batch = X[l:r]\n        X_batch_rf = to_rf(X_batch.float(), models)\n        X_batch_pca = torch.mm(X_batch_rf, V_pca)\n        print(X_batch_pca.shape)\n        X_pca.append(X_batch_pca)\n    return torch.cat(X_pca, dim=0)\n\nX_train_full_pca = to_pca(X_train_full, V, models)\nX_test_full_pca  = to_pca(X_test_full, V, models)\nX_train_full_pca.shape, X_test_full_pca.shape","metadata":{"cellId":"9ehm2iyds7awidqmay7hkl","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":" 88%|████████▊ | 88/100 [34:10<04:38, 23.20s/it]"},{"output_type":"stream","name":"stdout","text":"0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 89%|████████▉ | 89/100 [34:33<04:15, 23.23s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 90%|█████████ | 90/100 [34:56<03:52, 23.26s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 91%|█████████ | 91/100 [35:20<03:29, 23.32s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 92%|█████████▏| 92/100 [35:43<03:06, 23.27s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 93%|█████████▎| 93/100 [36:06<02:42, 23.26s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 94%|█████████▍| 94/100 [36:29<02:19, 23.22s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 95%|█████████▌| 95/100 [36:53<01:57, 23.44s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 96%|█████████▌| 96/100 [37:16<01:33, 23.36s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 97%|█████████▋| 97/100 [37:40<01:10, 23.36s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 98%|█████████▊| 98/100 [38:03<00:46, 23.37s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 99%|█████████▉| 99/100 [38:26<00:23, 23.35s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 100/100 [38:50<00:00, 23.30s/it]\n  0%|          | 0/10 [00:00<?, ?it/s]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 10%|█         | 1/10 [00:23<03:28, 23.20s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 20%|██        | 2/10 [00:46<03:05, 23.25s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 30%|███       | 3/10 [01:09<02:42, 23.22s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 40%|████      | 4/10 [01:33<02:19, 23.25s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 50%|█████     | 5/10 [01:56<01:56, 23.30s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 60%|██████    | 6/10 [02:20<01:34, 23.54s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 70%|███████   | 7/10 [02:43<01:10, 23.47s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 80%|████████  | 8/10 [03:07<00:46, 23.44s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\n"},{"output_type":"stream","name":"stderr","text":" 90%|█████████ | 9/10 [03:30<00:23, 23.39s/it]"},{"output_type":"stream","name":"stdout","text":"torch.Size([1000, 6400])\n0 models done.\n1 models done.\n2 models done.\n4 models done.\n8 models done.\n16 models done.\n32 models done.\n64 models done.\n128 models done.\n256 models done.\ntorch.Size([1000, 6400])\n"},{"output_type":"stream","name":"stderr","text":"100%|██████████| 10/10 [03:53<00:00, 23.39s/it]\n"},{"output_type":"display_data","data":{"text/plain":"(torch.Size([100000, 6400]), torch.Size([10000, 6400]))"},"metadata":{}}],"execution_count":119},{"cell_type":"code","source":"#!g1.1\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier\n\nfor alpha in [1.,   1e-1, 1e-2, \n              1e-3, 1e-4, 1e-5, \n              1e-6, 1e-7, 1e-8]:\n    classifier = RidgeClassifier(alpha=alpha)\n    classifier.fit(X_train_full_pca.numpy(), labels_train_full.numpy())\n    y_pred = classifier.predict(X_test_full_pca.numpy())\n    acc = np.average(abs(y_pred - labels_test_full.numpy()) == 0)\n    print(f'alpha={alpha} test acc: {acc}')","metadata":{"cellId":"g7wleash1sa9dw2oov2hqi","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"alpha=1.0 test acc: 0.3707\nalpha=0.1 test acc: 0.3716\nalpha=0.01 test acc: 0.3717\nalpha=0.001 test acc: 0.3717\nalpha=0.0001 test acc: 0.3717\nalpha=1e-05 test acc: 0.3718\nalpha=1e-06 test acc: 0.3718\nalpha=1e-07 test acc: 0.3718\nalpha=1e-08 test acc: 0.3718\n"}],"execution_count":122}]}