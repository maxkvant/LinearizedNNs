{"nbformat":4,"nbformat_minor":5,"metadata":{"notebookId":"b8082abf-5b6e-4525-8cb3-16c5983002a2","language_info":{"nbconvert_exporter":"python","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","version":"3.7.7","file_extension":".py","pygments_lexer":"ipython3"},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"}},"cells":[{"cell_type":"code","source":"#!L\nimport time\nimport numpy as np\nimport seaborn as sns\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms, datasets\nfrom torchvision.datasets import FashionMNIST\n\nfrom linearized_nns.estimator import Estimator\nfrom linearized_nns.pytorch_impl.estimators import SgdEstimator\nfrom linearized_nns.pytorch_impl.nns import Myrtle5, Myrtle7, Myrtle10\nfrom linearized_nns.pytorch_impl import ClassifierTraining\nfrom linearized_nns.pytorch_impl.matrix_exp import matrix_exp, compute_exp_term\nfrom linearized_nns.pytorch_impl.nns.utils import to_one_hot, print_sizes\nfrom linearized_nns.from_neural_kernels import to_zca, CustomTensorDataset, get_cifar_zca","metadata":{"cellId":"9gdfwbcbht60h6xa9y9zaef","trusted":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":"#!L\ndevice = torch.device('cuda:0') if (torch.cuda.is_available()) else torch.device('cpu')\ndevice","metadata":{"cellId":"jwxl7dczidh226jzlb7x8l","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"#!L\nclass GpEstimator(Estimator):\n    def __init__(self, models, n_classes, learning_rate, x_example, device, groups=1):\n        super(GpEstimator, self).__init__()\n        self.models    = [model.to(device) for model in models]\n        self.lr        = learning_rate\n        self.n_classes = n_classes\n        self.device    = device\n        \n        n = len(models)\n        X = torch.stack([x_example]).to(device)\n        \n        model = models[0].to(device)\n        readout_size = model.readout(X).size()[1]\n    \n        # TODO: Assert that models have the same readout size\n        \n        self.w      = torch.zeros([n, readout_size, n_classes]).to(device)\n        self.w_size = n * groups\n        \n    def get_w_update(self, X, right_vector):\n        with torch.no_grad():\n            assert len(X) == len(right_vector)\n\n            X            = X.to(self.device)\n            right_vector = right_vector.to(self.device)\n\n            n = len(X)\n            w_updates = []\n            \n            for model in self.models:\n                features = self.to_model_features(X, model)\n                update = torch.matmul(features.T, right_vector)\n                w_updates.append(update)\n            return torch.stack(w_updates)\n                                  \n    def to_model_features(self, X, model):\n        with torch.no_grad():\n            model = model.to(device)\n            return model.readout(X) * (1. / np.sqrt(self.w_size))\n        \n    def calc_kernel(self, X):\n        with torch.no_grad():\n            X = X.to(device)\n            \n            res = torch.zeros([len(X), len(X)]).to(device).double()\n            for model in self.models:\n                features_x = self.to_model_features(X, model)\n                \n                res += torch.matmul(features_x, features_x.T).double()\n            return res.float()\n        \n    def calc_kernel_pred(self, X):\n        with torch.no_grad():\n            X = X.to(device)\n            \n            n = len(X)\n            y_pred = torch.zeros([n, self.n_classes]).to(device).double()\n            kernel = torch.zeros([len(X), len(X)]).to(device).double()\n            \n            for model, w in zip(self.models, self.w):\n                features = self.to_model_features(X, model)\n                \n                kernel += torch.matmul(features, features.T).double()\n                y_pred += torch.matmul(features, w).double()\n            return kernel, y_pred.float()\n        \n    def calc_kernels(self, X_train, X_test):\n        with torch.no_grad():\n            X_train = X_train.to(device)\n            X_test  = X_test.to(device)\n            \n            res_train = torch.zeros([len(X_train), len(X_train)]).to(device)\n            res_test  = torch.zeros([len(X_test),  len(X_train)]).to(device)\n            for model in self.models:\n                features_train = self.to_model_features(X_train, model)\n                features_test  = self.to_model_features(X_test,  model)\n                \n                res_train += torch.matmul(features_train, features_train.T)\n                res_test  += torch.matmul(features_test,  features_train.T)\n            return res_train, res_test\n            \n    def predict(self, X, cur_w=None):\n        X = X.to(self.device)\n        if cur_w is None:\n            cur_w = self.w\n         \n        with torch.no_grad():\n            n = len(X)\n            res = torch.zeros([n, self.n_classes]).double().to(device)\n\n            for model, w in zip(self.models, cur_w):\n                features = self.to_model_features(X, model)\n                res += torch.matmul(features, w).double()\n            return res.float()","metadata":{"cellId":"w11l0n6tlrb996f9nn35f","trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#!L\ndef calc_right_vector(kernel, y, learning_rate=1e5, reg_param=0):\n    with torch.no_grad():\n        y      = y.to(device)\n        kernel = kernel.to(device)\n        \n        n      = len(kernel)\n        reg = torch.eye(n).to(device) * reg_param\n        \n        exp_term = - learning_rate * compute_exp_term(- learning_rate * (kernel + reg), device)\n        right_vector = torch.matmul(exp_term, - y)\n        return right_vector","metadata":{"cellId":"jxcgesj948e83i8yottsd","trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#!L\n%%time\n\nX_train, labels_train, X_test, labels_test = get_cifar_zca()\n\nN_train = 50000\nN_test  = 1000\n\nX_train      = torch.tensor(X_train[:N_train]).float()\nlabels_train = torch.tensor(labels_train[:N_train], dtype=torch.long)\n\nX_test       = torch.tensor(X_test[:N_test]).float()\nlabels_test  = torch.tensor(labels_test[:N_test],  dtype=torch.long)\n\nnum_classes = 10\n\ny_train = to_one_hot(labels_train, num_classes).to(device)\ny_test  = to_one_hot(labels_test,  num_classes).to(device)","metadata":{"cellId":"ov3qe0z82lfc7tdhbpltru","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\nCPU times: user 3min 12s, sys: 1min 26s, total: 4min 39s\nWall time: 51.2 s\n"}],"execution_count":37},{"cell_type":"code","source":"#!L\ncifar_train = CustomTensorDataset(torch.tensor(X_train), torch.tensor(y_train).float(), transform='flips')\ncifar_test  = CustomTensorDataset(torch.tensor(X_test),  torch.tensor(labels_test, dtype=torch.long))","metadata":{"cellId":"d51nfw6jkipwaub9sovrv","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\n/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\n/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n"}],"execution_count":38},{"cell_type":"code","source":"#!L\ndef boosting(estimator, train_loader, test_loader, learning_rate=1e5, beta=1., n_iter=10):\n    output_kernel = False\n    \n    with torch.no_grad():\n        batches_num = 0\n        for _ in enumerate(train_loader):\n            batches_num += 1\n        n_batches = (batches_num * 2) // 3 + 1\n        \n        test_size = 0\n        for _, (X, _) in enumerate(test_loader):\n            test_size += len(X)\n            \n        for iter_num  in range(n_iter):\n            print(f\"iter {iter_num} ==========================\")\n            \n            w_update = 0\n            iter_start = time.time()\n            \n            for batch_i, (X, y) in enumerate(train_loader):\n                if batch_i >= n_batches:\n                    break\n                \n                X = X.to(device)\n                y = y.to(device)\n                \n                kernel, y_pred = estimator.calc_kernel_pred(X)\n                if output_kernel:\n                    print(f\"kernel\\n{kernel[:5,:5]}\")\n                \n                y_residual = y_pred - y\n                \n                train_acc = (y_pred.argmax(dim=1) == y.argmax(dim=1)).float().mean().item()\n                train_mse = (y_residual ** 2).mean().item()\n                print(f\"batch {batch_i}: train_acc {train_acc:.4f}, train_mse {train_mse:.6f}\")\n                \n                right_vector = calc_right_vector(kernel, y_residual, learning_rate=learning_rate)\n                \n                w_update += estimator.get_w_update(X, right_vector).double()\n                \n                pred_change = torch.matmul(kernel, right_vector.double())\n                \n\n            w_update = (w_update / n_batches).float()\n            \n            _, (X, y) = next(enumerate(train_loader))\n            \n            y_pred      = estimator.predict(X)\n            pred_change = estimator.predict(X, w_update)\n            \n            y_residual = y_pred - y\n                \n            estimator.w -= w_update * beta \n            \n            test_acc = 0\n            for _, (X_test, labels) in enumerate(test_loader):\n                y_pred = estimator.predict(X_test) \n                test_acc += (y_pred.argmax(dim=1) == labels.to(device)).float().sum().item() / test_size\n                \n            print(f\"iter {iter_num} done. took {time.time() - iter_start:.0f}s. beta {beta:.3f}, test_acc {test_acc:.4f}\")\n            print()","metadata":{"cellId":"2fgwcfjbqlrf8s2vveda3c","trusted":true},"outputs":[],"execution_count":43},{"cell_type":"code","source":"#!L\ncifar_train = CustomTensorDataset(torch.tensor(X_train), torch.tensor(y_train).float(), transform='flips')\ncifar_test  = CustomTensorDataset(torch.tensor(X_test),  torch.tensor(labels_test, dtype=torch.long))\n\ntrain_loader = torch.utils.data.DataLoader(cifar_train, batch_size=1280 * 2)\ntest_loader  = torch.utils.data.DataLoader(cifar_test, batch_size=1000)","metadata":{"cellId":"o8cf8z2qf1vyb06t1u2w","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\n/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\n/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n"}],"execution_count":40},{"cell_type":"code","source":"#!L\n%state_exclude models\nn_models = 500\n\n# 500 * 50 * 32  = 800k\n\nmodels = [Myrtle7(num_filters=1, groups=50) for _ in range(n_models)]\nn_models\n\nestimator = GpEstimator(models, num_classes, 0.2, X_train[0], device, groups=50)","metadata":{"cellId":"l6s3ltygiilsbjucgqyj","trusted":true},"outputs":[],"execution_count":27},{"cell_type":"code","source":"#!L\nboosting(estimator, train_loader, test_loader, learning_rate=1e6, n_iter=30)","metadata":{"cellId":"8tpafnbdgvnyq4hb27wap","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"iter 0 ==========================\nbatch 0: train_acc 0.1008, train_mse 1.000000\nbatch 1: train_acc 0.0945, train_mse 1.000000\nbatch 2: train_acc 0.1059, train_mse 1.000000\nbatch 3: train_acc 0.1016, train_mse 1.000000\niter 0 done. took 361s. beta -1.046, test_acc 0.7520\n\niter 1 ==========================\nbatch 0: train_acc 0.9000, train_mse 0.142131\nbatch 1: train_acc 0.8918, train_mse 0.143286\nbatch 2: train_acc 0.8859, train_mse 0.145053\nbatch 3: train_acc 0.8977, train_mse 0.142880\niter 1 done. took 361s. beta -2.028, test_acc 0.7710\n\niter 2 ==========================\nbatch 0: train_acc 0.9555, train_mse 0.091109\nbatch 1: train_acc 0.9535, train_mse 0.092889\nbatch 2: train_acc 0.9543, train_mse 0.091222\nbatch 3: train_acc 0.9547, train_mse 0.093278\niter 2 done. took 361s. beta -1.610, test_acc 0.7900\n\niter 3 ==========================\nbatch 0: train_acc 0.9832, train_mse 0.064314\nbatch 1: train_acc 0.9805, train_mse 0.066563\nbatch 2: train_acc 0.9820, train_mse 0.063889\nbatch 3: train_acc 0.9789, train_mse 0.065481\niter 3 done. took 361s. beta -1.669, test_acc 0.7990\n\niter 4 ==========================\nbatch 0: train_acc 0.9883, train_mse 0.049136\nbatch 1: train_acc 0.9918, train_mse 0.048880\nbatch 2: train_acc 0.9902, train_mse 0.050236\nbatch 3: train_acc 0.9918, train_mse 0.050057\niter 4 done. took 361s. beta -1.709, test_acc 0.8030\n\niter 5 ==========================\nbatch 0: train_acc 0.9934, train_mse 0.038736\nbatch 1: train_acc 0.9953, train_mse 0.039082\nbatch 2: train_acc 0.9957, train_mse 0.038923\nbatch 3: train_acc 0.9957, train_mse 0.038540\niter 5 done. took 361s. beta -1.642, test_acc 0.8060\n\niter 6 ==========================\nbatch 0: train_acc 0.9980, train_mse 0.030335\nbatch 1: train_acc 0.9965, train_mse 0.031341\nbatch 2: train_acc 0.9977, train_mse 0.031062\nbatch 3: train_acc 0.9977, train_mse 0.030540\niter 6 done. took 361s. beta -1.697, test_acc 0.8040\n\niter 7 ==========================\nbatch 0: train_acc 0.9992, train_mse 0.024406\nbatch 1: train_acc 0.9980, train_mse 0.024854\nbatch 2: train_acc 0.9973, train_mse 0.024937\nbatch 3: train_acc 0.9977, train_mse 0.024710\niter 7 done. took 361s. beta -1.599, test_acc 0.8050\n\niter 8 ==========================\nbatch 0: train_acc 0.9984, train_mse 0.020854\nbatch 1: train_acc 1.0000, train_mse 0.021391\nbatch 2: train_acc 0.9992, train_mse 0.019875\nbatch 3: train_acc 0.9988, train_mse 0.020837\niter 8 done. took 361s. beta -1.752, test_acc 0.8100\n\niter 9 ==========================\nbatch 0: train_acc 0.9996, train_mse 0.016891\nbatch 1: train_acc 1.0000, train_mse 0.017511\nbatch 2: train_acc 0.9996, train_mse 0.017380\nbatch 3: train_acc 0.9996, train_mse 0.017487\niter 9 done. took 361s. beta -1.472, test_acc 0.8030\n\niter 10 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.014280\nbatch 1: train_acc 0.9992, train_mse 0.014705\nbatch 2: train_acc 1.0000, train_mse 0.014607\nbatch 3: train_acc 0.9992, train_mse 0.014764\niter 10 done. took 361s. beta -1.736, test_acc 0.8120\n\niter 11 ==========================\nbatch 0: train_acc 0.9996, train_mse 0.012161\nbatch 1: train_acc 1.0000, train_mse 0.012746\nbatch 2: train_acc 1.0000, train_mse 0.012547\nbatch 3: train_acc 1.0000, train_mse 0.012640\niter 11 done. took 361s. beta -1.482, test_acc 0.8110\n\niter 12 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.010912\nbatch 1: train_acc 1.0000, train_mse 0.011009\nbatch 2: train_acc 1.0000, train_mse 0.010787\nbatch 3: train_acc 1.0000, train_mse 0.010708\niter 12 done. took 361s. beta -1.752, test_acc 0.8090\n\niter 13 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.009416\nbatch 1: train_acc 1.0000, train_mse 0.009784\nbatch 2: train_acc 0.9996, train_mse 0.009680\nbatch 3: train_acc 1.0000, train_mse 0.009796\niter 13 done. took 361s. beta -1.468, test_acc 0.8130\n\niter 14 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.008538\nbatch 1: train_acc 1.0000, train_mse 0.008559\nbatch 2: train_acc 1.0000, train_mse 0.008559\nbatch 3: train_acc 1.0000, train_mse 0.008574\niter 14 done. took 361s. beta -1.957, test_acc 0.8120\n\niter 15 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.007399\nbatch 1: train_acc 1.0000, train_mse 0.007953\nbatch 2: train_acc 1.0000, train_mse 0.007491\nbatch 3: train_acc 1.0000, train_mse 0.007746\niter 15 done. took 361s. beta -1.546, test_acc 0.8130\n\niter 16 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.006668\nbatch 1: train_acc 1.0000, train_mse 0.006779\nbatch 2: train_acc 1.0000, train_mse 0.006705\nbatch 3: train_acc 1.0000, train_mse 0.006990\niter 16 done. took 361s. beta -1.845, test_acc 0.8130\n\niter 17 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.005998\nbatch 1: train_acc 1.0000, train_mse 0.006352\nbatch 2: train_acc 1.0000, train_mse 0.006005\nbatch 3: train_acc 1.0000, train_mse 0.006313\niter 17 done. took 361s. beta -1.591, test_acc 0.8160\n\niter 18 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.005448\nbatch 1: train_acc 1.0000, train_mse 0.005643\nbatch 2: train_acc 1.0000, train_mse 0.005453\nbatch 3: train_acc 1.0000, train_mse 0.005573\niter 18 done. took 361s. beta -1.894, test_acc 0.8100\n\niter 19 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.005027\nbatch 1: train_acc 1.0000, train_mse 0.005250\nbatch 2: train_acc 1.0000, train_mse 0.005118\nbatch 3: train_acc 1.0000, train_mse 0.005172\niter 19 done. took 361s. beta -1.647, test_acc 0.8160\n\niter 20 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.004651\nbatch 1: train_acc 1.0000, train_mse 0.004804\nbatch 2: train_acc 1.0000, train_mse 0.004526\nbatch 3: train_acc 1.0000, train_mse 0.004822\niter 20 done. took 361s. beta -1.924, test_acc 0.8150\n\niter 21 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.004262\nbatch 1: train_acc 1.0000, train_mse 0.004505\nbatch 2: train_acc 1.0000, train_mse 0.004191\nbatch 3: train_acc 1.0000, train_mse 0.004464\niter 21 done. took 361s. beta -1.676, test_acc 0.8140\n\niter 22 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.003957\nbatch 1: train_acc 1.0000, train_mse 0.004123\nbatch 2: train_acc 1.0000, train_mse 0.003926\nbatch 3: train_acc 1.0000, train_mse 0.004169\niter 22 done. took 361s. beta -1.962, test_acc 0.8150\n\niter 23 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.003741\nbatch 1: train_acc 1.0000, train_mse 0.003831\nbatch 2: train_acc 1.0000, train_mse 0.003726\nbatch 3: train_acc 1.0000, train_mse 0.003938\niter 23 done. took 361s. beta -1.701, test_acc 0.8140\n\niter 24 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.003514\nbatch 1: train_acc 1.0000, train_mse 0.003648\nbatch 2: train_acc 1.0000, train_mse 0.003480\nbatch 3: train_acc 1.0000, train_mse 0.003635\niter 24 done. took 361s. beta -2.132, test_acc 0.8170\n\niter 25 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.003266\nbatch 1: train_acc 1.0000, train_mse 0.003417\nbatch 2: train_acc 1.0000, train_mse 0.003270\nbatch 3: train_acc 1.0000, train_mse 0.003489\niter 25 done. took 361s. beta -1.454, test_acc 0.8120\n\niter 26 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.003112\nbatch 1: train_acc 1.0000, train_mse 0.003245\nbatch 2: train_acc 1.0000, train_mse 0.003072\nbatch 3: train_acc 1.0000, train_mse 0.003273\niter 26 done. took 361s. beta -2.221, test_acc 0.8170\n\niter 27 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.002937\nbatch 1: train_acc 1.0000, train_mse 0.003067\nbatch 2: train_acc 1.0000, train_mse 0.002986\nbatch 3: train_acc 1.0000, train_mse 0.003166\niter 27 done. took 361s. beta -1.589, test_acc 0.8160\n\niter 28 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.002799\nbatch 1: train_acc 1.0000, train_mse 0.002922\nbatch 2: train_acc 1.0000, train_mse 0.002792\nbatch 3: train_acc 1.0000, train_mse 0.002943\niter 28 done. took 361s. beta -2.336, test_acc 0.8170\n\niter 29 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.002637\nbatch 1: train_acc 1.0000, train_mse 0.002767\nbatch 2: train_acc 1.0000, train_mse 0.002670\nbatch 3: train_acc 1.0000, train_mse 0.002871\niter 29 done. took 361s. beta -1.435, test_acc 0.8130\n\n"}],"execution_count":28},{"cell_type":"code","source":"#!L\n%whos","metadata":{"cellId":"imr4cgmb4lplz4edn1mn8f","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Variable              Type                   Data/Info\n------------------------------------------------------\nClassifierTraining    LazyVariable           Lazy variable\nCustomTensorDataset   type                   <class 'linearized_nns.fr<...>set.CustomTensorDataset'>\nEstimator             LazyVariable           Lazy variable\nF                     LazyVariable           Lazy variable\nFashionMNIST          LazyVariable           Lazy variable\nGpEstimator           LazyVariable           Lazy variable\nImage                 LazyVariable           Lazy variable\nMyrtle10              LazyVariable           Lazy variable\nMyrtle5               LazyVariable           Lazy variable\nMyrtle7               LazyVariable           Lazy variable\nN_test                LazyVariable           Lazy variable of type int\nN_train               LazyVariable           Lazy variable of type int\nSgdEstimator          LazyVariable           Lazy variable\nX_test                Tensor                 tensor([[[[ 2.5525e-01,  <...>323e-01,  3.5044e-01]]]])\nX_train               Tensor                 tensor([[[[-4.9317e-01, -<...>778e-01,  2.1166e-01]]]])\nboosting              function               <function boosting at 0x7fbe8b2dd3b0>\ncalc_right_vector     LazyVariable           Lazy variable\ncifar_test            CustomTensorDataset    <linearized_nns.from_neur<...>object at 0x7fbe992fde50>\ncifar_train           CustomTensorDataset    <linearized_nns.from_neur<...>object at 0x7fbe8943cfd0>\ncompute_exp_term      LazyVariable           Lazy variable\ndatasets              LazyVariable           Lazy variable\ndevice                LazyVariable           Lazy variable\nestimator             LazyVariable           Lazy variable\nget_cifar_zca         LazyVariable           Lazy variable\nlabels_test           Tensor                 tensor([3, 8, 8, 0, 6, 6,<...> 8, 4, 6, 3, 8, 1, 3, 8])\nlabels_train          LazyVariable           Lazy variable\nmatrix_exp            LazyVariable           Lazy variable\nn_models              LazyVariable           Lazy variable of type int\nnn                    LazyVariable           Lazy variable\nnp                    LazyVariable           Lazy variable\nnum_classes           LazyVariable           Lazy variable of type int\nplt                   LazyVariable           Lazy variable\nprint_sizes           LazyVariable           Lazy variable\nsns                   LazyVariable           Lazy variable\ntest_loader           DataLoader             <torch.utils.data.dataloa<...>object at 0x7fbe99193510>\ntime                  LazyVariable           Lazy variable\nto_one_hot            LazyVariable           Lazy variable\nto_zca                LazyVariable           Lazy variable\ntorch                 module                 <module 'torch' from '/us<...>kages/torch/__init__.py'>\ntrain_loader          DataLoader             <torch.utils.data.dataloa<...>object at 0x7fbe75cf6190>\ntransforms            LazyVariable           Lazy variable\ny_test                LazyVariable           Lazy variable\ny_train               Tensor                 tensor([[-1., -1., -1.,  <...>, -1.]], device='cuda:0')\n"}],"execution_count":34},{"cell_type":"code","source":"#!L\n%state_exclude models\n%state_exclude estimator\n%state_exclude myrtle10_estimator\n\ntorch.manual_seed(0)\nnp.random.seed(0)\n\nn_models = 500\n\n# 500 * 50 * 32  = 800k\n\nmodels = [Myrtle10(num_filters=1, groups=50) for _ in range(n_models)]\nn_models\n\nmyrtle10_estimator = GpEstimator(models, num_classes, 0.2, X_train[0], device, groups=50)","metadata":{"cellId":"pr4xbuo5saf1hb871i52ne","trusted":true},"outputs":[],"execution_count":35},{"cell_type":"code","source":"#!L\n\nboosting(myrtle10_estimator, train_loader, test_loader, learning_rate=1e5, n_iter=100)","metadata":{"cellId":"dcwu3kw2vomsnd0ycum7fo","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"iter 0 ==========================\nbatch 0: train_acc 0.1008, train_mse 1.000000\nbatch 1: train_acc 0.0945, train_mse 1.000000\nbatch 2: train_acc 0.1059, train_mse 1.000000\nbatch 3: train_acc 0.1016, train_mse 1.000000\niter 0 done. took 1231s. beta -1.046, test_acc 0.7600\n\niter 1 ==========================\nbatch 0: train_acc 0.8922, train_mse 0.140524\nbatch 1: train_acc 0.8930, train_mse 0.142831\nbatch 2: train_acc 0.8898, train_mse 0.143399\nbatch 3: train_acc 0.8824, train_mse 0.141551\niter 1 done. took 1230s. beta -2.035, test_acc 0.7860\n\niter 2 ==========================\nbatch 0: train_acc 0.9598, train_mse 0.088664\nbatch 1: train_acc 0.9574, train_mse 0.090821\nbatch 2: train_acc 0.9570, train_mse 0.090587\nbatch 3: train_acc 0.9520, train_mse 0.092746\niter 2 done. took 1230s. beta -1.618, test_acc 0.7990\n\niter 3 ==========================\nbatch 0: train_acc 0.9777, train_mse 0.065684\nbatch 1: train_acc 0.9805, train_mse 0.065301\nbatch 2: train_acc 0.9816, train_mse 0.064903\nbatch 3: train_acc 0.9770, train_mse 0.064836\niter 3 done. took 1231s. beta -1.674, test_acc 0.8070\n\niter 4 ==========================\nbatch 0: train_acc 0.9906, train_mse 0.049935\nbatch 1: train_acc 0.9918, train_mse 0.050204\nbatch 2: train_acc 0.9898, train_mse 0.049125\nbatch 3: train_acc 0.9895, train_mse 0.051216\niter 4 done. took 1231s. beta -1.700, test_acc 0.8150\n\niter 5 ==========================\nbatch 0: train_acc 0.9926, train_mse 0.038647\nbatch 1: train_acc 0.9953, train_mse 0.038702\nbatch 2: train_acc 0.9910, train_mse 0.040501\nbatch 3: train_acc 0.9965, train_mse 0.038019\niter 5 done. took 1230s. beta -1.583, test_acc 0.8140\n\niter 6 ==========================\nbatch 0: train_acc 0.9957, train_mse 0.031086\nbatch 1: train_acc 0.9988, train_mse 0.031069\nbatch 2: train_acc 0.9969, train_mse 0.031267\nbatch 3: train_acc 0.9965, train_mse 0.031423\niter 6 done. took 1230s. beta -1.755, test_acc 0.8140\n\niter 7 ==========================\nbatch 0: train_acc 0.9969, train_mse 0.024962\nbatch 1: train_acc 0.9980, train_mse 0.025706\nbatch 2: train_acc 0.9988, train_mse 0.024490\nbatch 3: train_acc 0.9992, train_mse 0.025457\niter 7 done. took 1230s. beta -1.627, test_acc 0.8140\n\niter 8 ==========================\nbatch 0: train_acc 0.9992, train_mse 0.020092\nbatch 1: train_acc 0.9996, train_mse 0.020258\nbatch 2: train_acc 0.9996, train_mse 0.020742\nbatch 3: train_acc 0.9988, train_mse 0.020459\niter 8 done. took 1230s. beta -1.630, test_acc 0.8170\n\niter 9 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.017170\nbatch 1: train_acc 0.9992, train_mse 0.017599\nbatch 2: train_acc 0.9996, train_mse 0.016501\nbatch 3: train_acc 1.0000, train_mse 0.017485\niter 9 done. took 1231s. beta -1.575, test_acc 0.8210\n\niter 10 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.013815\nbatch 1: train_acc 0.9996, train_mse 0.014736\nbatch 2: train_acc 1.0000, train_mse 0.014536\nbatch 3: train_acc 0.9996, train_mse 0.014750\niter 10 done. took 1230s. beta -1.620, test_acc 0.8230\n\niter 11 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.012482\nbatch 1: train_acc 1.0000, train_mse 0.012751\nbatch 2: train_acc 1.0000, train_mse 0.012277\nbatch 3: train_acc 1.0000, train_mse 0.012489\niter 11 done. took 1231s. beta -1.803, test_acc 0.8220\n\niter 12 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.010598\nbatch 1: train_acc 0.9996, train_mse 0.010922\nbatch 2: train_acc 1.0000, train_mse 0.010713\nbatch 3: train_acc 1.0000, train_mse 0.011036\niter 12 done. took 1230s. beta -1.509, test_acc 0.8190\n\niter 13 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.009340\nbatch 1: train_acc 0.9996, train_mse 0.009402\nbatch 2: train_acc 0.9996, train_mse 0.009521\nbatch 3: train_acc 1.0000, train_mse 0.009210\niter 13 done. took 1230s. beta -1.748, test_acc 0.8190\n\niter 14 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.008232\nbatch 1: train_acc 1.0000, train_mse 0.008392\nbatch 2: train_acc 1.0000, train_mse 0.008276\nbatch 3: train_acc 1.0000, train_mse 0.008348\niter 14 done. took 1231s. beta -1.523, test_acc 0.8200\n\niter 15 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.007351\nbatch 1: train_acc 1.0000, train_mse 0.007399\nbatch 2: train_acc 1.0000, train_mse 0.007534\nbatch 3: train_acc 1.0000, train_mse 0.007366\niter 15 done. took 1230s. beta -1.770, test_acc 0.8210\n\niter 16 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.006686\nbatch 1: train_acc 1.0000, train_mse 0.006671\nbatch 2: train_acc 1.0000, train_mse 0.006480\nbatch 3: train_acc 1.0000, train_mse 0.006745\niter 16 done. took 1231s. beta -1.680, test_acc 0.8200\n\niter 17 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.005939\nbatch 1: train_acc 1.0000, train_mse 0.005970\nbatch 2: train_acc 1.0000, train_mse 0.006035\nbatch 3: train_acc 1.0000, train_mse 0.006034\niter 17 done. took 1230s. beta -1.658, test_acc 0.8230\n\niter 18 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.005349\nbatch 1: train_acc 1.0000, train_mse 0.005486\nbatch 2: train_acc 1.0000, train_mse 0.005228\nbatch 3: train_acc 1.0000, train_mse 0.005577\niter 18 done. took 1230s. beta -1.681, test_acc 0.8220\n\niter 19 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.004916\nbatch 1: train_acc 1.0000, train_mse 0.005042\nbatch 2: train_acc 1.0000, train_mse 0.004839\nbatch 3: train_acc 1.0000, train_mse 0.005027\niter 19 done. took 1231s. beta -1.868, test_acc 0.8180\n\niter 20 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.004460\nbatch 1: train_acc 1.0000, train_mse 0.004642\nbatch 2: train_acc 1.0000, train_mse 0.004500\nbatch 3: train_acc 1.0000, train_mse 0.004667\niter 20 done. took 1230s. beta -1.661, test_acc 0.8190\n\niter 21 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.004071\nbatch 1: train_acc 1.0000, train_mse 0.004202\nbatch 2: train_acc 1.0000, train_mse 0.004074\nbatch 3: train_acc 1.0000, train_mse 0.004283\niter 21 done. took 1231s. beta -1.775, test_acc 0.8190\n\niter 22 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.003912\nbatch 1: train_acc 1.0000, train_mse 0.003935\nbatch 2: train_acc 1.0000, train_mse 0.003849\nbatch 3: train_acc 1.0000, train_mse 0.003994\niter 22 done. took 1230s. beta -1.869, test_acc 0.8240\n\niter 23 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.003606\nbatch 1: train_acc 1.0000, train_mse 0.003803\nbatch 2: train_acc 1.0000, train_mse 0.003611\nbatch 3: train_acc 1.0000, train_mse 0.003739\niter 23 done. took 1230s. beta -1.614, test_acc 0.8200\n\niter 24 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.003374\nbatch 1: train_acc 1.0000, train_mse 0.003443\nbatch 2: train_acc 1.0000, train_mse 0.003350\nbatch 3: train_acc 1.0000, train_mse 0.003518\niter 24 done. took 1230s. beta -1.838, test_acc 0.8230\n\niter 25 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.003236\nbatch 1: train_acc 1.0000, train_mse 0.003299\nbatch 2: train_acc 1.0000, train_mse 0.003134\nbatch 3: train_acc 1.0000, train_mse 0.003266\niter 25 done. took 1230s. beta -1.897, test_acc 0.8180\n\niter 26 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.003043\nbatch 1: train_acc 1.0000, train_mse 0.003046\nbatch 2: train_acc 1.0000, train_mse 0.002949\nbatch 3: train_acc 1.0000, train_mse 0.003186\niter 26 done. took 1230s. beta -1.931, test_acc 0.8220\n\niter 27 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.002822\nbatch 1: train_acc 1.0000, train_mse 0.002958\nbatch 2: train_acc 1.0000, train_mse 0.002842\nbatch 3: train_acc 1.0000, train_mse 0.002923\niter 27 done. took 1230s. beta -1.567, test_acc 0.8210\n\niter 28 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.002739\nbatch 1: train_acc 1.0000, train_mse 0.002777\nbatch 2: train_acc 1.0000, train_mse 0.002660\nbatch 3: train_acc 1.0000, train_mse 0.002844\niter 28 done. took 1230s. beta -2.453, test_acc 0.8170\n\niter 29 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.002594\nbatch 1: train_acc 1.0000, train_mse 0.002699\nbatch 2: train_acc 1.0000, train_mse 0.002578\nbatch 3: train_acc 1.0000, train_mse 0.002667\niter 29 done. took 1231s. beta -1.519, test_acc 0.8190\n\niter 30 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.002440\nbatch 1: train_acc 1.0000, train_mse 0.002536\nbatch 2: train_acc 1.0000, train_mse 0.002448\nbatch 3: train_acc 1.0000, train_mse 0.002581\niter 30 done. took 1231s. beta -2.126, test_acc 0.8210\n\niter 31 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.002376\nbatch 1: train_acc 1.0000, train_mse 0.002410\nbatch 2: train_acc 1.0000, train_mse 0.002339\nbatch 3: train_acc 1.0000, train_mse 0.002435\niter 31 done. took 1231s. beta -2.302, test_acc 0.8200\n\niter 32 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.002233\nbatch 1: train_acc 1.0000, train_mse 0.002361\nbatch 2: train_acc 1.0000, train_mse 0.002227\nbatch 3: train_acc 1.0000, train_mse 0.002382\niter 32 done. took 1230s. beta -1.319, test_acc 0.8200\n\niter 33 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.002177\nbatch 1: train_acc 1.0000, train_mse 0.002261\nbatch 2: train_acc 1.0000, train_mse 0.002134\nbatch 3: train_acc 1.0000, train_mse 0.002278\niter 33 done. took 1231s. beta -2.899, test_acc 0.8180\n\niter 34 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.002081\nbatch 1: train_acc 1.0000, train_mse 0.002169\nbatch 2: train_acc 1.0000, train_mse 0.002075\nbatch 3: train_acc 1.0000, train_mse 0.002184\niter 34 done. took 1231s. beta -1.635, test_acc 0.8200\n\niter 35 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.002006\nbatch 1: train_acc 1.0000, train_mse 0.002086\nbatch 2: train_acc 1.0000, train_mse 0.001969\nbatch 3: train_acc 1.0000, train_mse 0.002106\niter 35 done. took 1230s. beta -2.400, test_acc 0.8210\n\niter 36 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001929\nbatch 1: train_acc 1.0000, train_mse 0.002023\nbatch 2: train_acc 1.0000, train_mse 0.001923\nbatch 3: train_acc 1.0000, train_mse 0.002028\niter 36 done. took 1231s. beta -1.566, test_acc 0.8220\n\niter 37 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001885\nbatch 1: train_acc 1.0000, train_mse 0.001951\nbatch 2: train_acc 1.0000, train_mse 0.001842\nbatch 3: train_acc 1.0000, train_mse 0.001965\niter 37 done. took 1230s. beta -2.754, test_acc 0.8200\n\niter 38 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001798\nbatch 1: train_acc 1.0000, train_mse 0.001893\nbatch 2: train_acc 1.0000, train_mse 0.001804\nbatch 3: train_acc 1.0000, train_mse 0.001910\niter 38 done. took 1230s. beta -1.419, test_acc 0.8200\n\niter 39 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001759\nbatch 1: train_acc 1.0000, train_mse 0.001831\nbatch 2: train_acc 1.0000, train_mse 0.001744\nbatch 3: train_acc 1.0000, train_mse 0.001848\niter 39 done. took 1230s. beta -3.256, test_acc 0.8210\n\niter 40 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001695\nbatch 1: train_acc 1.0000, train_mse 0.001783\nbatch 2: train_acc 1.0000, train_mse 0.001691\nbatch 3: train_acc 1.0000, train_mse 0.001800\niter 40 done. took 1230s. beta -1.500, test_acc 0.8220\n\niter 41 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001647\nbatch 1: train_acc 1.0000, train_mse 0.001729\nbatch 2: train_acc 1.0000, train_mse 0.001629\nbatch 3: train_acc 1.0000, train_mse 0.001722\niter 41 done. took 1231s. beta -2.849, test_acc 0.8190\n\niter 42 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001591\nbatch 1: train_acc 1.0000, train_mse 0.001669\nbatch 2: train_acc 1.0000, train_mse 0.001589\nbatch 3: train_acc 1.0000, train_mse 0.001701\niter 42 done. took 1230s. beta -1.441, test_acc 0.8220\n\niter 43 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001555\nbatch 1: train_acc 1.0000, train_mse 0.001642\nbatch 2: train_acc 1.0000, train_mse 0.001540\nbatch 3: train_acc 1.0000, train_mse 0.001626\niter 43 done. took 1231s. beta -3.169, test_acc 0.8180\n\niter 44 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001498\nbatch 1: train_acc 1.0000, train_mse 0.001580\nbatch 2: train_acc 1.0000, train_mse 0.001511\nbatch 3: train_acc 1.0000, train_mse 0.001633\niter 44 done. took 1231s. beta -1.335, test_acc 0.8220\n\niter 45 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001473\nbatch 1: train_acc 1.0000, train_mse 0.001561\nbatch 2: train_acc 1.0000, train_mse 0.001453\nbatch 3: train_acc 1.0000, train_mse 0.001551\niter 45 done. took 1231s. beta -3.907, test_acc 0.8190\n\niter 46 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001422\nbatch 1: train_acc 1.0000, train_mse 0.001494\nbatch 2: train_acc 1.0000, train_mse 0.001423\nbatch 3: train_acc 1.0000, train_mse 0.001528\niter 46 done. took 1231s. beta -1.352, test_acc 0.8210\n\niter 47 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001388\nbatch 1: train_acc 1.0000, train_mse 0.001475\nbatch 2: train_acc 1.0000, train_mse 0.001377\nbatch 3: train_acc 1.0000, train_mse 0.001458\niter 47 done. took 1230s. beta -3.840, test_acc 0.8190\n\niter 48 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001340\nbatch 1: train_acc 1.0000, train_mse 0.001420\nbatch 2: train_acc 1.0000, train_mse 0.001347\nbatch 3: train_acc 1.0000, train_mse 0.001445\niter 48 done. took 1230s. beta -1.297, test_acc 0.8210\n\niter 49 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001316\nbatch 1: train_acc 1.0000, train_mse 0.001404\nbatch 2: train_acc 1.0000, train_mse 0.001305\nbatch 3: train_acc 1.0000, train_mse 0.001385\niter 49 done. took 1230s. beta -3.940, test_acc 0.8170\n\niter 50 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001271\nbatch 1: train_acc 1.0000, train_mse 0.001351\nbatch 2: train_acc 1.0000, train_mse 0.001278\nbatch 3: train_acc 1.0000, train_mse 0.001366\niter 50 done. took 1230s. beta -1.367, test_acc 0.8200\n\niter 51 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001245\nbatch 1: train_acc 1.0000, train_mse 0.001338\nbatch 2: train_acc 1.0000, train_mse 0.001235\nbatch 3: train_acc 1.0000, train_mse 0.001321\niter 51 done. took 1231s. beta -3.950, test_acc 0.8170\n\niter 52 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001213\nbatch 1: train_acc 1.0000, train_mse 0.001296\nbatch 2: train_acc 1.0000, train_mse 0.001218\nbatch 3: train_acc 1.0000, train_mse 0.001308\niter 52 done. took 1230s. beta -1.194, test_acc 0.8200\n\niter 53 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001184\nbatch 1: train_acc 1.0000, train_mse 0.001276\nbatch 2: train_acc 1.0000, train_mse 0.001187\nbatch 3: train_acc 1.0000, train_mse 0.001263\niter 53 done. took 1231s. beta -5.791, test_acc 0.8170\n\niter 54 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001142\nbatch 1: train_acc 1.0000, train_mse 0.001232\nbatch 2: train_acc 1.0000, train_mse 0.001153\nbatch 3: train_acc 1.0000, train_mse 0.001253\niter 54 done. took 1231s. beta -1.156, test_acc 0.8190\n\niter 55 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001117\nbatch 1: train_acc 1.0000, train_mse 0.001210\nbatch 2: train_acc 1.0000, train_mse 0.001116\nbatch 3: train_acc 1.0000, train_mse 0.001187\niter 55 done. took 1231s. beta -5.039, test_acc 0.8190\n\niter 56 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001086\nbatch 1: train_acc 1.0000, train_mse 0.001160\nbatch 2: train_acc 1.0000, train_mse 0.001091\nbatch 3: train_acc 1.0000, train_mse 0.001189\niter 56 done. took 1231s. beta -1.314, test_acc 0.8200\n\niter 57 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001061\nbatch 1: train_acc 1.0000, train_mse 0.001158\nbatch 2: train_acc 1.0000, train_mse 0.001064\nbatch 3: train_acc 1.0000, train_mse 0.001129\niter 57 done. took 1230s. beta -3.573, test_acc 0.8200\n\niter 58 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001039\nbatch 1: train_acc 1.0000, train_mse 0.001119\nbatch 2: train_acc 1.0000, train_mse 0.001041\nbatch 3: train_acc 1.0000, train_mse 0.001132\niter 58 done. took 1231s. beta -1.388, test_acc 0.8200\n\niter 59 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.001019\nbatch 1: train_acc 1.0000, train_mse 0.001117\nbatch 2: train_acc 1.0000, train_mse 0.001023\nbatch 3: train_acc 1.0000, train_mse 0.001091\niter 59 done. took 1231s. beta -3.442, test_acc 0.8180\n\niter 60 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000999\nbatch 1: train_acc 1.0000, train_mse 0.001083\nbatch 2: train_acc 1.0000, train_mse 0.001005\nbatch 3: train_acc 1.0000, train_mse 0.001086\niter 60 done. took 1231s. beta -1.562, test_acc 0.8190\n\niter 61 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000982\nbatch 1: train_acc 1.0000, train_mse 0.001084\nbatch 2: train_acc 1.0000, train_mse 0.000988\nbatch 3: train_acc 1.0000, train_mse 0.001051\niter 61 done. took 1231s. beta -1.834, test_acc 0.8190\n\niter 62 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000974\nbatch 1: train_acc 1.0000, train_mse 0.001058\nbatch 2: train_acc 1.0000, train_mse 0.000972\nbatch 3: train_acc 1.0000, train_mse 0.001051\niter 62 done. took 1231s. beta -3.081, test_acc 0.8200\n\niter 63 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000952\nbatch 1: train_acc 1.0000, train_mse 0.001065\nbatch 2: train_acc 1.0000, train_mse 0.000961\nbatch 3: train_acc 1.0000, train_mse 0.001017\niter 63 done. took 1231s. beta -1.142, test_acc 0.8190\n\niter 64 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000942\nbatch 1: train_acc 1.0000, train_mse 0.001031\nbatch 2: train_acc 1.0000, train_mse 0.000946\nbatch 3: train_acc 1.0000, train_mse 0.001018\niter 64 done. took 1231s. beta -8.548, test_acc 0.8210\n\niter 65 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000907\nbatch 1: train_acc 1.0000, train_mse 0.001037\nbatch 2: train_acc 1.0000, train_mse 0.000922\nbatch 3: train_acc 1.0000, train_mse 0.000966\niter 65 done. took 1231s. beta -0.890, test_acc 0.8190\n\niter 66 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000889\nbatch 1: train_acc 1.0000, train_mse 0.000982\nbatch 2: train_acc 1.0000, train_mse 0.000891\nbatch 3: train_acc 1.0000, train_mse 0.000960\niter 66 done. took 1231s. beta -3.461, test_acc 0.8190\n\niter 67 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000871\nbatch 1: train_acc 1.0000, train_mse 0.000969\nbatch 2: train_acc 1.0000, train_mse 0.000874\nbatch 3: train_acc 1.0000, train_mse 0.000946\niter 67 done. took 1231s. beta -1.686, test_acc 0.8190\n\niter 68 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000856\nbatch 1: train_acc 1.0000, train_mse 0.000951\nbatch 2: train_acc 1.0000, train_mse 0.000864\nbatch 3: train_acc 1.0000, train_mse 0.000925\niter 68 done. took 1231s. beta -3.789, test_acc 0.8190\n\niter 69 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000839\nbatch 1: train_acc 1.0000, train_mse 0.000940\nbatch 2: train_acc 1.0000, train_mse 0.000849\nbatch 3: train_acc 1.0000, train_mse 0.000922\niter 69 done. took 1231s. beta -1.086, test_acc 0.8190\n\niter 70 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000828\nbatch 1: train_acc 1.0000, train_mse 0.000925\nbatch 2: train_acc 1.0000, train_mse 0.000832\nbatch 3: train_acc 1.0000, train_mse 0.000903\niter 70 done. took 1231s. beta -10.116, test_acc 0.8210\n\niter 71 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000793\nbatch 1: train_acc 1.0000, train_mse 0.000922\nbatch 2: train_acc 1.0000, train_mse 0.000811\nbatch 3: train_acc 1.0000, train_mse 0.000871\niter 71 done. took 1231s. beta -0.957, test_acc 0.8200\n\niter 72 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000783\nbatch 1: train_acc 1.0000, train_mse 0.000880\nbatch 2: train_acc 1.0000, train_mse 0.000787\nbatch 3: train_acc 1.0000, train_mse 0.000853\niter 72 done. took 1231s. beta -3.033, test_acc 0.8190\n\niter 73 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000772\nbatch 1: train_acc 1.0000, train_mse 0.000866\nbatch 2: train_acc 1.0000, train_mse 0.000771\nbatch 3: train_acc 1.0000, train_mse 0.000837\niter 73 done. took 1230s. beta -3.251, test_acc 0.8200\n\niter 74 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000752\nbatch 1: train_acc 1.0000, train_mse 0.000860\nbatch 2: train_acc 1.0000, train_mse 0.000765\nbatch 3: train_acc 1.0000, train_mse 0.000831\niter 74 done. took 1231s. beta -0.876, test_acc 0.8200\n\niter 75 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000748\nbatch 1: train_acc 1.0000, train_mse 0.000845\nbatch 2: train_acc 1.0000, train_mse 0.000754\nbatch 3: train_acc 1.0000, train_mse 0.000817\niter 75 done. took 1231s. beta -4.549, test_acc 0.8200\n\niter 76 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000739\nbatch 1: train_acc 1.0000, train_mse 0.000838\nbatch 2: train_acc 1.0000, train_mse 0.000740\nbatch 3: train_acc 1.0000, train_mse 0.000796\niter 76 done. took 1231s. beta -1.610, test_acc 0.8200\n\niter 77 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000729\nbatch 1: train_acc 1.0000, train_mse 0.000820\nbatch 2: train_acc 1.0000, train_mse 0.000732\nbatch 3: train_acc 1.0000, train_mse 0.000793\niter 77 done. took 1231s. beta -3.505, test_acc 0.8200\n\niter 78 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000719\nbatch 1: train_acc 1.0000, train_mse 0.000822\nbatch 2: train_acc 1.0000, train_mse 0.000728\nbatch 3: train_acc 1.0000, train_mse 0.000785\niter 78 done. took 1231s. beta -0.994, test_acc 0.8200\n\niter 79 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000709\nbatch 1: train_acc 1.0000, train_mse 0.000803\nbatch 2: train_acc 1.0000, train_mse 0.000715\nbatch 3: train_acc 1.0000, train_mse 0.000778\niter 79 done. took 1231s. beta -12.263, test_acc 0.8200\n\niter 80 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000680\nbatch 1: train_acc 1.0000, train_mse 0.000809\nbatch 2: train_acc 1.0000, train_mse 0.000690\nbatch 3: train_acc 1.0000, train_mse 0.000738\niter 80 done. took 1231s. beta -0.968, test_acc 0.8200\n\niter 81 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000671\nbatch 1: train_acc 1.0000, train_mse 0.000770\nbatch 2: train_acc 1.0000, train_mse 0.000675\nbatch 3: train_acc 1.0000, train_mse 0.000729\niter 81 done. took 1231s. beta -3.348, test_acc 0.8200\n\niter 82 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000660\nbatch 1: train_acc 1.0000, train_mse 0.000754\nbatch 2: train_acc 1.0000, train_mse 0.000659\nbatch 3: train_acc 1.0000, train_mse 0.000734\niter 82 done. took 1231s. beta -1.463, test_acc 0.8200\n\niter 83 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000655\nbatch 1: train_acc 1.0000, train_mse 0.000753\nbatch 2: train_acc 1.0000, train_mse 0.000656\nbatch 3: train_acc 1.0000, train_mse 0.000713\niter 83 done. took 1231s. beta -6.105, test_acc 0.8200\n\niter 84 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000640\nbatch 1: train_acc 1.0000, train_mse 0.000744\nbatch 2: train_acc 1.0000, train_mse 0.000643\nbatch 3: train_acc 1.0000, train_mse 0.000722\niter 84 done. took 1231s. beta -0.945, test_acc 0.8200\n\niter 85 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000631\nbatch 1: train_acc 1.0000, train_mse 0.000728\nbatch 2: train_acc 1.0000, train_mse 0.000637\nbatch 3: train_acc 1.0000, train_mse 0.000697\niter 85 done. took 1231s. beta -4.073, test_acc 0.8200\n\niter 86 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.000626\nbatch 1: train_acc 1.0000, train_mse 0.000726\nbatch 2: train_acc 1.0000, train_mse 0.000626\nbatch 3: train_acc 1.0000, train_mse 0.000683\n"},{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/ignored_keyboard_interrupt.py:16: UserWarning: State committing stage cannot be interrupted. Please wait.\n  warnings.warn(self._warn_message)\n"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)","\u001B[0;32m<ipython-input-6-a3db0af33ba1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mboosting\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmyrtle10_estimator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearning_rate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1e5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_iter\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;31m#488e5c91-0e26-4efa-87eb-0acede3d66eb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m<ipython-input-1-184c435bbba8>\u001B[0m in \u001B[0;36mboosting\u001B[0;34m(estimator, train_loader, test_loader, learning_rate, n_iter)\u001B[0m\n\u001B[1;32m     49\u001B[0m             \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m             \u001B[0my_pred\u001B[0m      \u001B[0;34m=\u001B[0m \u001B[0mestimator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m             \u001B[0mpred_change\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mestimator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mw_update\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m<ipython-input-3-faebb4b1b4f3>\u001B[0m in \u001B[0;36mpredict\u001B[0;34m(self, X, cur_w)\u001B[0m\n","\u001B[0;31mKeyboardInterrupt\u001B[0m: "]}],"execution_count":36},{"cell_type":"code","source":"#!L\n%state_exclude models\n%state_exclude estimator\n%state_exclude myrtle10_estimator\n\ntorch.manual_seed(0)\nnp.random.seed(0)\n\nn_models = 10\n\n# 500 * 50 * 32  = 800k\n\nmodels = [Myrtle10(num_filters=1, groups=50) for _ in range(n_models)]\nn_models\n\nmyrtle10_estimator = GpEstimator(models, num_classes, 0.2, X_train[0], device, groups=50)","metadata":{"cellId":"e948ekthgl9a3wtszzmei4","trusted":true},"outputs":[],"execution_count":46},{"cell_type":"code","source":"#!L\nboosting(myrtle10_estimator, train_loader, test_loader, learning_rate=1e5, beta=1., n_iter=100)","metadata":{"execution_id":"a263f624-dd3b-442b-8516-79f92bacb8c5","cellId":"xopq5drc7185zug9mxkhrj","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"iter 0 ==========================\nbatch 0: train_acc 0.1008, train_mse 1.000000\nbatch 1: train_acc 0.0945, train_mse 1.000000\nbatch 2: train_acc 0.1059, train_mse 1.000000\nbatch 3: train_acc 0.1016, train_mse 1.000000\nbatch 4: train_acc 0.0977, train_mse 1.000000\nbatch 5: train_acc 0.1086, train_mse 1.000000\nbatch 6: train_acc 0.0988, train_mse 1.000000\nbatch 7: train_acc 0.1023, train_mse 1.000000\nbatch 8: train_acc 0.1000, train_mse 1.000000\nbatch 9: train_acc 0.1031, train_mse 1.000000\nbatch 10: train_acc 0.1008, train_mse 1.000000\nbatch 11: train_acc 0.1012, train_mse 1.000000\nbatch 12: train_acc 0.0973, train_mse 1.000000\nbatch 13: train_acc 0.0957, train_mse 1.000000\niter 0 done. took 3602s. beta 1.000, test_acc 0.7740\n\niter 1 ==========================\nbatch 0: train_acc 0.8445, train_mse 0.167174\nbatch 1: train_acc 0.8371, train_mse 0.168976\nbatch 2: train_acc 0.8289, train_mse 0.168668\nbatch 3: train_acc 0.8316, train_mse 0.168418\nbatch 4: train_acc 0.8301, train_mse 0.169411\nbatch 5: train_acc 0.8281, train_mse 0.170728\nbatch 6: train_acc 0.8484, train_mse 0.168303\nbatch 7: train_acc 0.8258, train_mse 0.171544\nbatch 8: train_acc 0.8352, train_mse 0.169011\nbatch 9: train_acc 0.8320, train_mse 0.167137\nbatch 10: train_acc 0.8438, train_mse 0.167967\nbatch 11: train_acc 0.8418, train_mse 0.167008\nbatch 12: train_acc 0.8203, train_mse 0.170754\nbatch 13: train_acc 0.8313, train_mse 0.171892\niter 1 done. took 3602s. beta 1.000, test_acc 0.8130\n\niter 2 ==========================\nbatch 0: train_acc 0.8961, train_mse 0.141693\nbatch 1: train_acc 0.8887, train_mse 0.143681\nbatch 2: train_acc 0.8727, train_mse 0.144050\nbatch 3: train_acc 0.8855, train_mse 0.142838\nbatch 4: train_acc 0.8758, train_mse 0.144081\nbatch 5: train_acc 0.8832, train_mse 0.146032\nbatch 6: train_acc 0.8852, train_mse 0.143631\nbatch 7: train_acc 0.8801, train_mse 0.146184\nbatch 8: train_acc 0.8848, train_mse 0.143857\nbatch 9: train_acc 0.8762, train_mse 0.141927\nbatch 10: train_acc 0.8922, train_mse 0.141887\nbatch 11: train_acc 0.8832, train_mse 0.141567\nbatch 12: train_acc 0.8781, train_mse 0.144496\nbatch 13: train_acc 0.8801, train_mse 0.146558\niter 2 done. took 3602s. beta 1.000, test_acc 0.8310\n\niter 3 ==========================\nbatch 0: train_acc 0.9199, train_mse 0.126875\nbatch 1: train_acc 0.9117, train_mse 0.128516\nbatch 2: train_acc 0.9008, train_mse 0.129449\nbatch 3: train_acc 0.9133, train_mse 0.128264\nbatch 4: train_acc 0.9027, train_mse 0.129612\nbatch 5: train_acc 0.9141, train_mse 0.129802\nbatch 6: train_acc 0.9145, train_mse 0.128210\nbatch 7: train_acc 0.9105, train_mse 0.130791\nbatch 8: train_acc 0.9070, train_mse 0.129565\nbatch 9: train_acc 0.9094, train_mse 0.127086\nbatch 10: train_acc 0.9180, train_mse 0.127645\nbatch 11: train_acc 0.9043, train_mse 0.127183\nbatch 12: train_acc 0.9098, train_mse 0.130181\nbatch 13: train_acc 0.9066, train_mse 0.131694\niter 3 done. took 3602s. beta 1.000, test_acc 0.8340\n\niter 4 ==========================\nbatch 0: train_acc 0.9371, train_mse 0.116665\nbatch 1: train_acc 0.9348, train_mse 0.117465\nbatch 2: train_acc 0.9281, train_mse 0.118385\nbatch 3: train_acc 0.9297, train_mse 0.117323\nbatch 4: train_acc 0.9234, train_mse 0.118399\nbatch 5: train_acc 0.9285, train_mse 0.119091\nbatch 6: train_acc 0.9293, train_mse 0.118199\nbatch 7: train_acc 0.9289, train_mse 0.120132\nbatch 8: train_acc 0.9242, train_mse 0.118703\nbatch 9: train_acc 0.9277, train_mse 0.116978\nbatch 10: train_acc 0.9375, train_mse 0.116224\nbatch 11: train_acc 0.9289, train_mse 0.116276\nbatch 12: train_acc 0.9230, train_mse 0.119073\nbatch 13: train_acc 0.9301, train_mse 0.121639\niter 4 done. took 3602s. beta 1.000, test_acc 0.8380\n\niter 5 ==========================\nbatch 0: train_acc 0.9492, train_mse 0.108408\nbatch 1: train_acc 0.9512, train_mse 0.108602\nbatch 2: train_acc 0.9410, train_mse 0.110157\nbatch 3: train_acc 0.9445, train_mse 0.108552\nbatch 4: train_acc 0.9395, train_mse 0.110307\nbatch 5: train_acc 0.9426, train_mse 0.110604\nbatch 6: train_acc 0.9418, train_mse 0.109313\nbatch 7: train_acc 0.9438, train_mse 0.111298\nbatch 8: train_acc 0.9406, train_mse 0.111013\nbatch 9: train_acc 0.9441, train_mse 0.108046\nbatch 10: train_acc 0.9516, train_mse 0.108950\nbatch 11: train_acc 0.9465, train_mse 0.107934\nbatch 12: train_acc 0.9383, train_mse 0.110971\nbatch 13: train_acc 0.9480, train_mse 0.112900\niter 5 done. took 3602s. beta 1.000, test_acc 0.8430\n\niter 6 ==========================\nbatch 0: train_acc 0.9563, train_mse 0.101443\nbatch 1: train_acc 0.9602, train_mse 0.101844\nbatch 2: train_acc 0.9477, train_mse 0.103040\nbatch 3: train_acc 0.9563, train_mse 0.101732\nbatch 4: train_acc 0.9566, train_mse 0.102686\nbatch 5: train_acc 0.9520, train_mse 0.104198\nbatch 6: train_acc 0.9574, train_mse 0.102633\nbatch 7: train_acc 0.9598, train_mse 0.103411\nbatch 8: train_acc 0.9527, train_mse 0.104406\nbatch 9: train_acc 0.9555, train_mse 0.100861\nbatch 10: train_acc 0.9598, train_mse 0.101765\nbatch 11: train_acc 0.9551, train_mse 0.100400\nbatch 12: train_acc 0.9535, train_mse 0.104087\nbatch 13: train_acc 0.9547, train_mse 0.105550\niter 6 done. took 3602s. beta 1.000, test_acc 0.8450\n\niter 7 ==========================\nbatch 0: train_acc 0.9672, train_mse 0.094719\nbatch 1: train_acc 0.9656, train_mse 0.095727\nbatch 2: train_acc 0.9590, train_mse 0.097214\nbatch 3: train_acc 0.9621, train_mse 0.095698\nbatch 4: train_acc 0.9586, train_mse 0.097402\nbatch 5: train_acc 0.9605, train_mse 0.097461\nbatch 6: train_acc 0.9578, train_mse 0.096635\nbatch 7: train_acc 0.9613, train_mse 0.097285\nbatch 8: train_acc 0.9617, train_mse 0.098298\nbatch 9: train_acc 0.9605, train_mse 0.095758\nbatch 10: train_acc 0.9676, train_mse 0.095350\nbatch 11: train_acc 0.9645, train_mse 0.094826\nbatch 12: train_acc 0.9570, train_mse 0.098189\nbatch 13: train_acc 0.9699, train_mse 0.098463\niter 7 done. took 3602s. beta 1.000, test_acc 0.8480\n\niter 8 ==========================\nbatch 0: train_acc 0.9691, train_mse 0.089643\nbatch 1: train_acc 0.9707, train_mse 0.090269\nbatch 2: train_acc 0.9668, train_mse 0.091471\nbatch 3: train_acc 0.9699, train_mse 0.090562\nbatch 4: train_acc 0.9727, train_mse 0.091821\nbatch 5: train_acc 0.9680, train_mse 0.092305\nbatch 6: train_acc 0.9613, train_mse 0.091450\nbatch 7: train_acc 0.9727, train_mse 0.092314\nbatch 8: train_acc 0.9684, train_mse 0.092099\nbatch 9: train_acc 0.9699, train_mse 0.089858\nbatch 10: train_acc 0.9738, train_mse 0.090303\nbatch 11: train_acc 0.9660, train_mse 0.089608\nbatch 12: train_acc 0.9691, train_mse 0.091949\nbatch 13: train_acc 0.9715, train_mse 0.093539\niter 8 done. took 3602s. beta 1.000, test_acc 0.8560\n\niter 9 ==========================\nbatch 0: train_acc 0.9773, train_mse 0.086020\nbatch 1: train_acc 0.9770, train_mse 0.086077\nbatch 2: train_acc 0.9750, train_mse 0.086527\nbatch 3: train_acc 0.9730, train_mse 0.085763\nbatch 4: train_acc 0.9789, train_mse 0.086495\nbatch 5: train_acc 0.9719, train_mse 0.087288\nbatch 6: train_acc 0.9695, train_mse 0.087250\nbatch 7: train_acc 0.9727, train_mse 0.088247\nbatch 8: train_acc 0.9746, train_mse 0.087579\nbatch 9: train_acc 0.9777, train_mse 0.084347\nbatch 10: train_acc 0.9793, train_mse 0.085365\nbatch 11: train_acc 0.9750, train_mse 0.084600\nbatch 12: train_acc 0.9711, train_mse 0.087409\nbatch 13: train_acc 0.9797, train_mse 0.088220\niter 9 done. took 3602s. beta 1.000, test_acc 0.8520\n\niter 10 ==========================\nbatch 0: train_acc 0.9824, train_mse 0.081143\nbatch 1: train_acc 0.9832, train_mse 0.081460\nbatch 2: train_acc 0.9801, train_mse 0.083014\nbatch 3: train_acc 0.9805, train_mse 0.082236\nbatch 4: train_acc 0.9738, train_mse 0.083443\nbatch 5: train_acc 0.9805, train_mse 0.082730\nbatch 6: train_acc 0.9781, train_mse 0.082433\nbatch 7: train_acc 0.9781, train_mse 0.083472\nbatch 8: train_acc 0.9805, train_mse 0.083065\nbatch 9: train_acc 0.9789, train_mse 0.080343\nbatch 10: train_acc 0.9797, train_mse 0.081186\nbatch 11: train_acc 0.9805, train_mse 0.081114\nbatch 12: train_acc 0.9793, train_mse 0.082866\nbatch 13: train_acc 0.9848, train_mse 0.084204\niter 10 done. took 3602s. beta 1.000, test_acc 0.8580\n\niter 11 ==========================\nbatch 0: train_acc 0.9852, train_mse 0.077153\nbatch 1: train_acc 0.9898, train_mse 0.077245\nbatch 2: train_acc 0.9812, train_mse 0.078510\nbatch 3: train_acc 0.9852, train_mse 0.077976\nbatch 4: train_acc 0.9844, train_mse 0.078408\nbatch 5: train_acc 0.9824, train_mse 0.079624\nbatch 6: train_acc 0.9816, train_mse 0.078307\nbatch 7: train_acc 0.9855, train_mse 0.079345\nbatch 8: train_acc 0.9832, train_mse 0.078754\nbatch 9: train_acc 0.9824, train_mse 0.077313\nbatch 10: train_acc 0.9855, train_mse 0.077025\nbatch 11: train_acc 0.9828, train_mse 0.076815\nbatch 12: train_acc 0.9836, train_mse 0.079027\nbatch 13: train_acc 0.9844, train_mse 0.080514\niter 11 done. took 3603s. beta 1.000, test_acc 0.8560\n\niter 12 ==========================\nbatch 0: train_acc 0.9883, train_mse 0.073994\nbatch 1: train_acc 0.9891, train_mse 0.074609\nbatch 2: train_acc 0.9875, train_mse 0.074676\nbatch 3: train_acc 0.9863, train_mse 0.073803\nbatch 4: train_acc 0.9848, train_mse 0.075983\nbatch 5: train_acc 0.9855, train_mse 0.075924\nbatch 6: train_acc 0.9844, train_mse 0.075266\nbatch 7: train_acc 0.9867, train_mse 0.075355\nbatch 8: train_acc 0.9836, train_mse 0.075755\nbatch 9: train_acc 0.9844, train_mse 0.073742\nbatch 10: train_acc 0.9867, train_mse 0.074442\nbatch 11: train_acc 0.9867, train_mse 0.073484\nbatch 12: train_acc 0.9867, train_mse 0.075801\nbatch 13: train_acc 0.9879, train_mse 0.076687\niter 12 done. took 3602s. beta 1.000, test_acc 0.8590\n\niter 13 ==========================\nbatch 0: train_acc 0.9926, train_mse 0.070656\nbatch 1: train_acc 0.9918, train_mse 0.071159\nbatch 2: train_acc 0.9895, train_mse 0.072136\nbatch 3: train_acc 0.9883, train_mse 0.070853\nbatch 4: train_acc 0.9879, train_mse 0.072014\nbatch 5: train_acc 0.9891, train_mse 0.072637\nbatch 6: train_acc 0.9906, train_mse 0.071501\nbatch 7: train_acc 0.9887, train_mse 0.072407\nbatch 8: train_acc 0.9867, train_mse 0.072296\nbatch 9: train_acc 0.9852, train_mse 0.071179\nbatch 10: train_acc 0.9902, train_mse 0.071413\nbatch 11: train_acc 0.9902, train_mse 0.070091\nbatch 12: train_acc 0.9883, train_mse 0.072021\nbatch 13: train_acc 0.9891, train_mse 0.073894\niter 13 done. took 3602s. beta 1.000, test_acc 0.8600\n\niter 14 ==========================\nbatch 0: train_acc 0.9922, train_mse 0.067221\nbatch 1: train_acc 0.9926, train_mse 0.068694\nbatch 2: train_acc 0.9934, train_mse 0.068848\nbatch 3: train_acc 0.9930, train_mse 0.067375\nbatch 4: train_acc 0.9918, train_mse 0.068994\nbatch 5: train_acc 0.9895, train_mse 0.069345\nbatch 6: train_acc 0.9910, train_mse 0.068922\nbatch 7: train_acc 0.9887, train_mse 0.069150\nbatch 8: train_acc 0.9910, train_mse 0.069070\nbatch 9: train_acc 0.9902, train_mse 0.067131\nbatch 10: train_acc 0.9941, train_mse 0.068131\nbatch 11: train_acc 0.9902, train_mse 0.067236\nbatch 12: train_acc 0.9875, train_mse 0.069424\nbatch 13: train_acc 0.9918, train_mse 0.070681\niter 14 done. took 3602s. beta 1.000, test_acc 0.8560\n\niter 15 ==========================\nbatch 0: train_acc 0.9922, train_mse 0.064910\nbatch 1: train_acc 0.9957, train_mse 0.065071\nbatch 2: train_acc 0.9906, train_mse 0.065796\nbatch 3: train_acc 0.9926, train_mse 0.065288\nbatch 4: train_acc 0.9938, train_mse 0.066251\nbatch 5: train_acc 0.9926, train_mse 0.067425\nbatch 6: train_acc 0.9926, train_mse 0.066783\nbatch 7: train_acc 0.9926, train_mse 0.066041\nbatch 8: train_acc 0.9926, train_mse 0.065982\nbatch 9: train_acc 0.9902, train_mse 0.064921\nbatch 10: train_acc 0.9938, train_mse 0.065752\nbatch 11: train_acc 0.9918, train_mse 0.064391\nbatch 12: train_acc 0.9922, train_mse 0.066658\nbatch 13: train_acc 0.9930, train_mse 0.067362\niter 15 done. took 3602s. beta 1.000, test_acc 0.8610\n\niter 16 ==========================\nbatch 0: train_acc 0.9953, train_mse 0.062424\nbatch 1: train_acc 0.9977, train_mse 0.062237\nbatch 2: train_acc 0.9934, train_mse 0.064079\nbatch 3: train_acc 0.9941, train_mse 0.062588\nbatch 4: train_acc 0.9926, train_mse 0.063527\nbatch 5: train_acc 0.9938, train_mse 0.064070\nbatch 6: train_acc 0.9934, train_mse 0.063540\nbatch 7: train_acc 0.9941, train_mse 0.064142\nbatch 8: train_acc 0.9922, train_mse 0.063916\nbatch 9: train_acc 0.9898, train_mse 0.062537\nbatch 10: train_acc 0.9926, train_mse 0.063251\nbatch 11: train_acc 0.9938, train_mse 0.061976\nbatch 12: train_acc 0.9926, train_mse 0.063395\nbatch 13: train_acc 0.9965, train_mse 0.064105\niter 16 done. took 3602s. beta 1.000, test_acc 0.8610\n\niter 17 ==========================\nbatch 0: train_acc 0.9961, train_mse 0.060137\nbatch 1: train_acc 0.9969, train_mse 0.060379\nbatch 2: train_acc 0.9938, train_mse 0.060891\nbatch 3: train_acc 0.9941, train_mse 0.060566\nbatch 4: train_acc 0.9965, train_mse 0.060974\nbatch 5: train_acc 0.9973, train_mse 0.061393\nbatch 6: train_acc 0.9938, train_mse 0.061245\nbatch 7: train_acc 0.9934, train_mse 0.062210\nbatch 8: train_acc 0.9953, train_mse 0.061496\nbatch 9: train_acc 0.9953, train_mse 0.059414\nbatch 10: train_acc 0.9918, train_mse 0.061172\nbatch 11: train_acc 0.9965, train_mse 0.060002\nbatch 12: train_acc 0.9930, train_mse 0.062039\nbatch 13: train_acc 0.9977, train_mse 0.061481\niter 17 done. took 3602s. beta 1.000, test_acc 0.8590\n\niter 18 ==========================\nbatch 0: train_acc 0.9977, train_mse 0.057817\nbatch 1: train_acc 0.9988, train_mse 0.057694\nbatch 2: train_acc 0.9953, train_mse 0.058786\nbatch 3: train_acc 0.9961, train_mse 0.057755\nbatch 4: train_acc 0.9965, train_mse 0.058670\nbatch 5: train_acc 0.9961, train_mse 0.059255\nbatch 6: train_acc 0.9949, train_mse 0.059236\nbatch 7: train_acc 0.9973, train_mse 0.058959\nbatch 8: train_acc 0.9949, train_mse 0.059464\nbatch 9: train_acc 0.9941, train_mse 0.057740\nbatch 10: train_acc 0.9961, train_mse 0.057579\nbatch 11: train_acc 0.9957, train_mse 0.058034\nbatch 12: train_acc 0.9941, train_mse 0.059885\nbatch 13: train_acc 0.9969, train_mse 0.060070\niter 18 done. took 3602s. beta 1.000, test_acc 0.8620\n\niter 19 ==========================\nbatch 0: train_acc 0.9984, train_mse 0.055803\nbatch 1: train_acc 0.9996, train_mse 0.056135\nbatch 2: train_acc 0.9969, train_mse 0.056911\nbatch 3: train_acc 0.9969, train_mse 0.056246\nbatch 4: train_acc 0.9965, train_mse 0.056533\nbatch 5: train_acc 0.9973, train_mse 0.056926\nbatch 6: train_acc 0.9957, train_mse 0.057314\nbatch 7: train_acc 0.9969, train_mse 0.057202\nbatch 8: train_acc 0.9961, train_mse 0.057048\nbatch 9: train_acc 0.9953, train_mse 0.055800\nbatch 10: train_acc 0.9973, train_mse 0.056320\nbatch 11: train_acc 0.9945, train_mse 0.055697\nbatch 12: train_acc 0.9980, train_mse 0.057178\nbatch 13: train_acc 0.9973, train_mse 0.057644\niter 19 done. took 3602s. beta 1.000, test_acc 0.8610\n\niter 20 ==========================\nbatch 0: train_acc 0.9969, train_mse 0.053885\nbatch 1: train_acc 0.9992, train_mse 0.054177\nbatch 2: train_acc 0.9973, train_mse 0.054659\nbatch 3: train_acc 0.9973, train_mse 0.053698\nbatch 4: train_acc 0.9973, train_mse 0.053784\nbatch 5: train_acc 0.9980, train_mse 0.055451\nbatch 6: train_acc 0.9977, train_mse 0.055144\nbatch 7: train_acc 0.9973, train_mse 0.054928\nbatch 8: train_acc 0.9957, train_mse 0.055667\nbatch 9: train_acc 0.9949, train_mse 0.053313\nbatch 10: train_acc 0.9977, train_mse 0.054022\nbatch 11: train_acc 0.9961, train_mse 0.053822\nbatch 12: train_acc 0.9965, train_mse 0.055367\nbatch 13: train_acc 0.9988, train_mse 0.055189\niter 20 done. took 3601s. beta 1.000, test_acc 0.8630\n\niter 21 ==========================\nbatch 0: train_acc 0.9984, train_mse 0.052175\nbatch 1: train_acc 0.9996, train_mse 0.052026\nbatch 2: train_acc 0.9977, train_mse 0.052242\nbatch 3: train_acc 0.9965, train_mse 0.052356\nbatch 4: train_acc 0.9965, train_mse 0.053064\nbatch 5: train_acc 0.9984, train_mse 0.053339\nbatch 6: train_acc 0.9969, train_mse 0.052337\nbatch 7: train_acc 0.9965, train_mse 0.052965\nbatch 8: train_acc 0.9973, train_mse 0.053493\nbatch 9: train_acc 0.9957, train_mse 0.051537\nbatch 10: train_acc 0.9973, train_mse 0.052232\nbatch 11: train_acc 0.9992, train_mse 0.051415\nbatch 12: train_acc 0.9977, train_mse 0.053708\nbatch 13: train_acc 0.9992, train_mse 0.053072\niter 21 done. took 3602s. beta 1.000, test_acc 0.8660\n\niter 22 ==========================\nbatch 0: train_acc 0.9980, train_mse 0.050858\nbatch 1: train_acc 1.0000, train_mse 0.050706\nbatch 2: train_acc 0.9977, train_mse 0.051293\nbatch 3: train_acc 0.9969, train_mse 0.050563\nbatch 4: train_acc 0.9980, train_mse 0.051259\nbatch 5: train_acc 0.9980, train_mse 0.051368\nbatch 6: train_acc 0.9961, train_mse 0.051435\nbatch 7: train_acc 0.9969, train_mse 0.051370\nbatch 8: train_acc 0.9988, train_mse 0.051833\nbatch 9: train_acc 0.9965, train_mse 0.050224\nbatch 10: train_acc 0.9980, train_mse 0.050507\nbatch 11: train_acc 0.9977, train_mse 0.049939\nbatch 12: train_acc 0.9969, train_mse 0.052231\nbatch 13: train_acc 0.9984, train_mse 0.052303\niter 22 done. took 3601s. beta 1.000, test_acc 0.8610\n\niter 23 ==========================\nbatch 0: train_acc 0.9992, train_mse 0.048343\nbatch 1: train_acc 0.9992, train_mse 0.048911\nbatch 2: train_acc 0.9977, train_mse 0.049867\nbatch 3: train_acc 0.9973, train_mse 0.048673\nbatch 4: train_acc 0.9980, train_mse 0.049072\nbatch 5: train_acc 0.9988, train_mse 0.050089\nbatch 6: train_acc 0.9977, train_mse 0.049702\nbatch 7: train_acc 0.9980, train_mse 0.049546\nbatch 8: train_acc 0.9992, train_mse 0.049212\nbatch 9: train_acc 0.9973, train_mse 0.048584\nbatch 10: train_acc 0.9984, train_mse 0.048768\nbatch 11: train_acc 0.9984, train_mse 0.047768\nbatch 12: train_acc 0.9992, train_mse 0.049749\nbatch 13: train_acc 0.9988, train_mse 0.049921\niter 23 done. took 3601s. beta 1.000, test_acc 0.8640\n\niter 24 ==========================\nbatch 0: train_acc 0.9996, train_mse 0.046560\nbatch 1: train_acc 1.0000, train_mse 0.047202\nbatch 2: train_acc 0.9984, train_mse 0.048024\nbatch 3: train_acc 0.9980, train_mse 0.046796\nbatch 4: train_acc 0.9984, train_mse 0.047782\nbatch 5: train_acc 0.9988, train_mse 0.048410\nbatch 6: train_acc 0.9973, train_mse 0.048050\nbatch 7: train_acc 0.9980, train_mse 0.048421\nbatch 8: train_acc 0.9988, train_mse 0.047901\nbatch 9: train_acc 0.9977, train_mse 0.046781\nbatch 10: train_acc 0.9980, train_mse 0.047153\nbatch 11: train_acc 0.9992, train_mse 0.046356\nbatch 12: train_acc 0.9996, train_mse 0.048570\nbatch 13: train_acc 0.9992, train_mse 0.048816\niter 24 done. took 3601s. beta 1.000, test_acc 0.8610\n\niter 25 ==========================\nbatch 0: train_acc 0.9996, train_mse 0.045813\nbatch 1: train_acc 0.9992, train_mse 0.045908\nbatch 2: train_acc 0.9988, train_mse 0.046563\nbatch 3: train_acc 0.9984, train_mse 0.045546\nbatch 4: train_acc 0.9984, train_mse 0.045706\nbatch 5: train_acc 0.9980, train_mse 0.046894\nbatch 6: train_acc 0.9980, train_mse 0.046452\nbatch 7: train_acc 0.9988, train_mse 0.046676\nbatch 8: train_acc 0.9988, train_mse 0.046746\nbatch 9: train_acc 0.9992, train_mse 0.044984\nbatch 10: train_acc 0.9984, train_mse 0.046875\nbatch 11: train_acc 0.9992, train_mse 0.045392\nbatch 12: train_acc 0.9996, train_mse 0.047066\nbatch 13: train_acc 0.9988, train_mse 0.046997\niter 25 done. took 3601s. beta 1.000, test_acc 0.8610\n\niter 26 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.044388\nbatch 1: train_acc 1.0000, train_mse 0.044621\nbatch 2: train_acc 0.9988, train_mse 0.044749\nbatch 3: train_acc 0.9977, train_mse 0.044251\nbatch 4: train_acc 0.9996, train_mse 0.044657\nbatch 5: train_acc 0.9988, train_mse 0.045646\nbatch 6: train_acc 0.9992, train_mse 0.045113\nbatch 7: train_acc 0.9988, train_mse 0.045292\nbatch 8: train_acc 0.9992, train_mse 0.045053\nbatch 9: train_acc 0.9984, train_mse 0.043782\nbatch 10: train_acc 0.9977, train_mse 0.044527\nbatch 11: train_acc 0.9984, train_mse 0.044013\nbatch 12: train_acc 0.9992, train_mse 0.045785\nbatch 13: train_acc 0.9992, train_mse 0.045680\niter 26 done. took 3601s. beta 1.000, test_acc 0.8620\n\niter 27 ==========================\nbatch 0: train_acc 0.9996, train_mse 0.043369\nbatch 1: train_acc 1.0000, train_mse 0.043307\nbatch 2: train_acc 0.9988, train_mse 0.043642\nbatch 3: train_acc 0.9988, train_mse 0.043076\nbatch 4: train_acc 0.9984, train_mse 0.043339\nbatch 5: train_acc 0.9996, train_mse 0.044120\nbatch 6: train_acc 0.9996, train_mse 0.044077\nbatch 7: train_acc 0.9992, train_mse 0.043764\nbatch 8: train_acc 0.9988, train_mse 0.043994\nbatch 9: train_acc 0.9988, train_mse 0.042501\nbatch 10: train_acc 0.9988, train_mse 0.043148\nbatch 11: train_acc 0.9988, train_mse 0.042823\nbatch 12: train_acc 0.9988, train_mse 0.044317\nbatch 13: train_acc 0.9992, train_mse 0.044142\niter 27 done. took 3601s. beta 1.000, test_acc 0.8650\n\niter 28 ==========================\nbatch 0: train_acc 0.9996, train_mse 0.041314\nbatch 1: train_acc 1.0000, train_mse 0.041586\nbatch 2: train_acc 0.9992, train_mse 0.042057\nbatch 3: train_acc 0.9996, train_mse 0.041345\nbatch 4: train_acc 0.9992, train_mse 0.042141\nbatch 5: train_acc 0.9996, train_mse 0.042326\nbatch 6: train_acc 0.9988, train_mse 0.042544\nbatch 7: train_acc 0.9992, train_mse 0.042610\nbatch 8: train_acc 0.9992, train_mse 0.042556\nbatch 9: train_acc 0.9996, train_mse 0.041511\nbatch 10: train_acc 0.9980, train_mse 0.041885\nbatch 11: train_acc 0.9996, train_mse 0.041449\nbatch 12: train_acc 0.9996, train_mse 0.042713\nbatch 13: train_acc 0.9992, train_mse 0.043181\niter 28 done. took 3602s. beta 1.000, test_acc 0.8640\n\niter 29 ==========================\nbatch 0: train_acc 0.9996, train_mse 0.039869\nbatch 1: train_acc 1.0000, train_mse 0.040654\nbatch 2: train_acc 0.9992, train_mse 0.041062\nbatch 3: train_acc 0.9996, train_mse 0.040959\nbatch 4: train_acc 0.9992, train_mse 0.040549\nbatch 5: train_acc 0.9992, train_mse 0.041592\nbatch 6: train_acc 1.0000, train_mse 0.041719\nbatch 7: train_acc 0.9996, train_mse 0.041418\nbatch 8: train_acc 1.0000, train_mse 0.041173\nbatch 9: train_acc 1.0000, train_mse 0.040076\nbatch 10: train_acc 0.9984, train_mse 0.040595\nbatch 11: train_acc 0.9992, train_mse 0.040648\nbatch 12: train_acc 0.9996, train_mse 0.041333\nbatch 13: train_acc 0.9996, train_mse 0.041726\niter 29 done. took 3602s. beta 1.000, test_acc 0.8660\n\niter 30 ==========================\nbatch 0: train_acc 0.9992, train_mse 0.039366\nbatch 1: train_acc 1.0000, train_mse 0.039350\nbatch 2: train_acc 0.9992, train_mse 0.039805\nbatch 3: train_acc 0.9996, train_mse 0.038859\nbatch 4: train_acc 0.9992, train_mse 0.039892\nbatch 5: train_acc 0.9996, train_mse 0.040265\nbatch 6: train_acc 1.0000, train_mse 0.040029\nbatch 7: train_acc 0.9996, train_mse 0.040182\nbatch 8: train_acc 0.9996, train_mse 0.040383\nbatch 9: train_acc 0.9992, train_mse 0.039104\nbatch 10: train_acc 0.9988, train_mse 0.039870\nbatch 11: train_acc 0.9984, train_mse 0.039013\nbatch 12: train_acc 1.0000, train_mse 0.040922\nbatch 13: train_acc 0.9988, train_mse 0.040447\niter 30 done. took 3601s. beta 1.000, test_acc 0.8590\n\niter 31 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.038313\nbatch 1: train_acc 1.0000, train_mse 0.038588\nbatch 2: train_acc 0.9996, train_mse 0.038603\nbatch 3: train_acc 0.9988, train_mse 0.038015\nbatch 4: train_acc 0.9992, train_mse 0.039001\nbatch 5: train_acc 0.9996, train_mse 0.039190\nbatch 6: train_acc 0.9996, train_mse 0.039017\nbatch 7: train_acc 0.9996, train_mse 0.039390\nbatch 8: train_acc 1.0000, train_mse 0.038687\nbatch 9: train_acc 0.9996, train_mse 0.037764\nbatch 10: train_acc 0.9996, train_mse 0.038501\nbatch 11: train_acc 0.9996, train_mse 0.037829\nbatch 12: train_acc 1.0000, train_mse 0.039451\nbatch 13: train_acc 0.9984, train_mse 0.039312\niter 31 done. took 3602s. beta 1.000, test_acc 0.8680\n\niter 32 ==========================\nbatch 0: train_acc 0.9992, train_mse 0.037060\nbatch 1: train_acc 1.0000, train_mse 0.037260\nbatch 2: train_acc 0.9996, train_mse 0.037654\nbatch 3: train_acc 0.9996, train_mse 0.037310\nbatch 4: train_acc 0.9996, train_mse 0.037245\nbatch 5: train_acc 1.0000, train_mse 0.038036\nbatch 6: train_acc 1.0000, train_mse 0.038122\nbatch 7: train_acc 1.0000, train_mse 0.038315\nbatch 8: train_acc 0.9996, train_mse 0.038406\nbatch 9: train_acc 1.0000, train_mse 0.036676\nbatch 10: train_acc 0.9984, train_mse 0.037497\nbatch 11: train_acc 0.9992, train_mse 0.036807\nbatch 12: train_acc 1.0000, train_mse 0.038254\nbatch 13: train_acc 1.0000, train_mse 0.037927\niter 32 done. took 3602s. beta 1.000, test_acc 0.8630\n\niter 33 ==========================\nbatch 0: train_acc 0.9996, train_mse 0.036125\nbatch 1: train_acc 1.0000, train_mse 0.036006\nbatch 2: train_acc 0.9996, train_mse 0.036443\nbatch 3: train_acc 1.0000, train_mse 0.036072\nbatch 4: train_acc 0.9996, train_mse 0.036159\nbatch 5: train_acc 1.0000, train_mse 0.037035\nbatch 6: train_acc 0.9992, train_mse 0.037161\nbatch 7: train_acc 0.9996, train_mse 0.037289\nbatch 8: train_acc 0.9992, train_mse 0.037204\nbatch 9: train_acc 0.9996, train_mse 0.035708\nbatch 10: train_acc 0.9996, train_mse 0.036257\nbatch 11: train_acc 1.0000, train_mse 0.036052\nbatch 12: train_acc 1.0000, train_mse 0.036837\nbatch 13: train_acc 0.9996, train_mse 0.037300\niter 33 done. took 3601s. beta 1.000, test_acc 0.8640\n\niter 34 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.035163\nbatch 1: train_acc 1.0000, train_mse 0.035381\nbatch 2: train_acc 0.9996, train_mse 0.035622\nbatch 3: train_acc 1.0000, train_mse 0.035089\nbatch 4: train_acc 0.9996, train_mse 0.035716\nbatch 5: train_acc 1.0000, train_mse 0.035928\nbatch 6: train_acc 0.9996, train_mse 0.036042\nbatch 7: train_acc 0.9996, train_mse 0.035952\nbatch 8: train_acc 1.0000, train_mse 0.036226\nbatch 9: train_acc 1.0000, train_mse 0.034758\nbatch 10: train_acc 0.9988, train_mse 0.036045\nbatch 11: train_acc 0.9996, train_mse 0.035138\nbatch 12: train_acc 1.0000, train_mse 0.036169\nbatch 13: train_acc 1.0000, train_mse 0.036246\niter 34 done. took 3601s. beta 1.000, test_acc 0.8620\n\niter 35 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.033712\nbatch 1: train_acc 1.0000, train_mse 0.034935\nbatch 2: train_acc 0.9996, train_mse 0.034888\nbatch 3: train_acc 0.9992, train_mse 0.034159\nbatch 4: train_acc 0.9996, train_mse 0.034528\nbatch 5: train_acc 1.0000, train_mse 0.035247\nbatch 6: train_acc 0.9996, train_mse 0.035060\nbatch 7: train_acc 0.9996, train_mse 0.034723\nbatch 8: train_acc 1.0000, train_mse 0.035081\nbatch 9: train_acc 1.0000, train_mse 0.033683\nbatch 10: train_acc 0.9996, train_mse 0.034425\nbatch 11: train_acc 1.0000, train_mse 0.034088\nbatch 12: train_acc 0.9996, train_mse 0.035278\nbatch 13: train_acc 1.0000, train_mse 0.035122\niter 35 done. took 3602s. beta 1.000, test_acc 0.8620\n\niter 36 ==========================\nbatch 0: train_acc 0.9996, train_mse 0.033693\nbatch 1: train_acc 1.0000, train_mse 0.033627\nbatch 2: train_acc 0.9996, train_mse 0.033877\nbatch 3: train_acc 1.0000, train_mse 0.033280\nbatch 4: train_acc 0.9996, train_mse 0.033726\nbatch 5: train_acc 0.9996, train_mse 0.034381\nbatch 6: train_acc 1.0000, train_mse 0.034002\nbatch 7: train_acc 1.0000, train_mse 0.033975\nbatch 8: train_acc 1.0000, train_mse 0.034252\nbatch 9: train_acc 1.0000, train_mse 0.033196\nbatch 10: train_acc 0.9996, train_mse 0.033302\nbatch 11: train_acc 1.0000, train_mse 0.032985\nbatch 12: train_acc 0.9996, train_mse 0.034612\nbatch 13: train_acc 1.0000, train_mse 0.034169\niter 36 done. took 3601s. beta 1.000, test_acc 0.8650\n\niter 37 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.032543\nbatch 1: train_acc 1.0000, train_mse 0.032475\nbatch 2: train_acc 0.9992, train_mse 0.033236\nbatch 3: train_acc 1.0000, train_mse 0.032587\nbatch 4: train_acc 0.9996, train_mse 0.032470\nbatch 5: train_acc 1.0000, train_mse 0.033244\nbatch 6: train_acc 0.9996, train_mse 0.033111\nbatch 7: train_acc 1.0000, train_mse 0.033154\nbatch 8: train_acc 1.0000, train_mse 0.032962\nbatch 9: train_acc 1.0000, train_mse 0.031874\nbatch 10: train_acc 0.9996, train_mse 0.033144\nbatch 11: train_acc 0.9996, train_mse 0.032395\nbatch 12: train_acc 0.9996, train_mse 0.033439\nbatch 13: train_acc 1.0000, train_mse 0.033096\niter 37 done. took 3601s. beta 1.000, test_acc 0.8670\n\niter 38 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.031364\nbatch 1: train_acc 1.0000, train_mse 0.031862\nbatch 2: train_acc 0.9996, train_mse 0.032179\nbatch 3: train_acc 1.0000, train_mse 0.031727\nbatch 4: train_acc 0.9996, train_mse 0.031692\nbatch 5: train_acc 1.0000, train_mse 0.032199\nbatch 6: train_acc 1.0000, train_mse 0.032568\nbatch 7: train_acc 1.0000, train_mse 0.032248\nbatch 8: train_acc 1.0000, train_mse 0.032261\nbatch 9: train_acc 1.0000, train_mse 0.031602\nbatch 10: train_acc 1.0000, train_mse 0.031940\nbatch 11: train_acc 0.9996, train_mse 0.031325\nbatch 12: train_acc 1.0000, train_mse 0.032802\nbatch 13: train_acc 1.0000, train_mse 0.032269\niter 38 done. took 3601s. beta 1.000, test_acc 0.8630\n\niter 39 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.031085\nbatch 1: train_acc 1.0000, train_mse 0.031115\nbatch 2: train_acc 1.0000, train_mse 0.031130\nbatch 3: train_acc 1.0000, train_mse 0.030730\nbatch 4: train_acc 0.9996, train_mse 0.031075\nbatch 5: train_acc 1.0000, train_mse 0.031820\nbatch 6: train_acc 1.0000, train_mse 0.031871\nbatch 7: train_acc 1.0000, train_mse 0.031319\nbatch 8: train_acc 1.0000, train_mse 0.031433\nbatch 9: train_acc 1.0000, train_mse 0.030501\nbatch 10: train_acc 0.9996, train_mse 0.031009\nbatch 11: train_acc 1.0000, train_mse 0.030917\nbatch 12: train_acc 0.9996, train_mse 0.031968\nbatch 13: train_acc 0.9996, train_mse 0.031752\niter 39 done. took 3601s. beta 1.000, test_acc 0.8620\n\niter 40 ==========================\nbatch 0: train_acc 0.9996, train_mse 0.029866\nbatch 1: train_acc 1.0000, train_mse 0.030057\nbatch 2: train_acc 1.0000, train_mse 0.030537\nbatch 3: train_acc 1.0000, train_mse 0.030242\nbatch 4: train_acc 0.9996, train_mse 0.030397\nbatch 5: train_acc 1.0000, train_mse 0.031079\nbatch 6: train_acc 0.9996, train_mse 0.030956\nbatch 7: train_acc 1.0000, train_mse 0.030853\nbatch 8: train_acc 1.0000, train_mse 0.031004\nbatch 9: train_acc 1.0000, train_mse 0.029576\nbatch 10: train_acc 0.9996, train_mse 0.030499\nbatch 11: train_acc 1.0000, train_mse 0.030383\nbatch 12: train_acc 0.9996, train_mse 0.031132\nbatch 13: train_acc 1.0000, train_mse 0.031214\niter 40 done. took 3601s. beta 1.000, test_acc 0.8630\n\niter 41 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.029611\nbatch 1: train_acc 1.0000, train_mse 0.029532\nbatch 2: train_acc 1.0000, train_mse 0.029906\nbatch 3: train_acc 1.0000, train_mse 0.028960\nbatch 4: train_acc 0.9996, train_mse 0.029358\nbatch 5: train_acc 1.0000, train_mse 0.030158\nbatch 6: train_acc 1.0000, train_mse 0.030054\nbatch 7: train_acc 1.0000, train_mse 0.029802\nbatch 8: train_acc 1.0000, train_mse 0.030132\nbatch 9: train_acc 1.0000, train_mse 0.029135\nbatch 10: train_acc 0.9996, train_mse 0.029515\nbatch 11: train_acc 1.0000, train_mse 0.029649\nbatch 12: train_acc 0.9996, train_mse 0.029999\nbatch 13: train_acc 1.0000, train_mse 0.030317\niter 41 done. took 3601s. beta 1.000, test_acc 0.8630\n\niter 42 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.028805\nbatch 1: train_acc 1.0000, train_mse 0.028805\nbatch 2: train_acc 1.0000, train_mse 0.028896\nbatch 3: train_acc 1.0000, train_mse 0.028844\nbatch 4: train_acc 0.9996, train_mse 0.029043\nbatch 5: train_acc 1.0000, train_mse 0.029677\nbatch 6: train_acc 1.0000, train_mse 0.029664\nbatch 7: train_acc 1.0000, train_mse 0.029463\nbatch 8: train_acc 1.0000, train_mse 0.029168\nbatch 9: train_acc 1.0000, train_mse 0.028361\nbatch 10: train_acc 0.9992, train_mse 0.029138\nbatch 11: train_acc 1.0000, train_mse 0.028263\nbatch 12: train_acc 1.0000, train_mse 0.029881\nbatch 13: train_acc 1.0000, train_mse 0.029226\niter 42 done. took 3601s. beta 1.000, test_acc 0.8640\n\niter 43 ==========================\nbatch 0: train_acc 0.9996, train_mse 0.027904\nbatch 1: train_acc 1.0000, train_mse 0.028368\nbatch 2: train_acc 1.0000, train_mse 0.028245\nbatch 3: train_acc 1.0000, train_mse 0.027795\nbatch 4: train_acc 0.9996, train_mse 0.028530\nbatch 5: train_acc 1.0000, train_mse 0.028900\nbatch 6: train_acc 1.0000, train_mse 0.028839\nbatch 7: train_acc 1.0000, train_mse 0.028716\nbatch 8: train_acc 1.0000, train_mse 0.028521\nbatch 9: train_acc 1.0000, train_mse 0.027787\nbatch 10: train_acc 0.9996, train_mse 0.028531\nbatch 11: train_acc 0.9996, train_mse 0.028070\nbatch 12: train_acc 0.9996, train_mse 0.028963\nbatch 13: train_acc 1.0000, train_mse 0.028441\niter 43 done. took 3601s. beta 1.000, test_acc 0.8620\n\niter 44 ==========================\nbatch 0: train_acc 1.0000, train_mse 0.027540\nbatch 1: train_acc 1.0000, train_mse 0.027882\nbatch 2: train_acc 1.0000, train_mse 0.027709\nbatch 3: train_acc 1.0000, train_mse 0.027354\nbatch 4: train_acc 0.9996, train_mse 0.027442\nbatch 5: train_acc 1.0000, train_mse 0.028164\n"}],"execution_count":null},{"cell_type":"code","source":"#!L\n","metadata":{"cellId":"16ylfnzf7y5iabwupij82"},"outputs":[],"execution_count":null}]}