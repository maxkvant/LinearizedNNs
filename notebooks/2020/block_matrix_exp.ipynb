{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import urllib.request\n",
    "\n",
    "def download_repo(url, save_to):\n",
    "    zip_filename = save_to + '.zip'\n",
    "    urllib.request.urlretrieve(url, zip_filename)\n",
    "    \n",
    "    if os.path.exists(save_to):\n",
    "        shutil.rmtree(save_to)\n",
    "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "    del zip_ref\n",
    "    assert os.path.exists(save_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_PATH = 'LinearizedNNs-master'\n",
    "\n",
    "download_repo(url='https://github.com/maxkvant/LinearizedNNs/archive/master.zip',\n",
    "              save_to=REPO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(f\"{REPO_PATH}/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "\n",
    "from pytorch_impl.estimators import SgdEstimator\n",
    "from pytorch_impl.nns import Myrtle5, Myrtle7, Myrtle10\n",
    "from pytorch_impl import ClassifierTraining\n",
    "from pytorch_impl.matrix_exp import matrix_exp, compute_exp_term\n",
    "from pytorch_impl.nns.utils import to_one_hot, print_sizes\n",
    "from pytorch_impl.nns.primitives import Conv, Flatten, Normalize, ReLU2\n",
    "from from_neural_kernels import to_zca, CustomTensorDataset, get_cifar_zca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if (torch.cuda.is_available()) else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_via_torch(a, b, device, step=2560):\n",
    "    n,  m = a.shape \n",
    "    m2, k = b.shape\n",
    "    assert m == m2\n",
    "    res = np.zeros([n, k], dtype=np.float32)\n",
    "    \n",
    "    for li in range(0, n, step):\n",
    "        for lj in range(0, k, step):\n",
    "            ri = min(n, li + step)\n",
    "            rj = min(k, lj + step)\n",
    "            \n",
    "            a_row = torch.from_numpy(a[li: ri, :]).to(device)\n",
    "            b_col = torch.from_numpy(b[:, lj: rj]).to(device)\n",
    "            \n",
    "            res[li: ri, lj: rj] = torch.matmul(a_row, b_col).cpu().numpy() \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm([[1, 1], [1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_exp_term_numpy(M, device, n_iter=3):\n",
    "    with torch.no_grad():\n",
    "        n, _ = M.shape\n",
    "        norm = np.sqrt(np.sum(M ** 2))\n",
    "        steps = 0\n",
    "        while norm > 1e-6:\n",
    "            M /= 2.\n",
    "            norm /= 2.\n",
    "            steps += 1\n",
    "\n",
    "        series_sum = np.zeros([n, n])\n",
    "        prod       = np.eye(n)\n",
    "\n",
    "        # series_sum: E + M / 2 + M^2 / 6 + ...\n",
    "        for i in range(1, n_iter):\n",
    "            series_sum += prod\n",
    "            prod = matmul_via_torch(prod, M, device) / (i + 1)\n",
    "        del prod\n",
    "        \n",
    "        exp = matmul_via_torch(M, series_sum, device) + np.eye(n)\n",
    "        del M\n",
    "        for step in range(steps):\n",
    "            series_sum += matmul_via_torch(series_sum, exp, device)\n",
    "            series_sum /= 2.\n",
    "            exp = matmul_via_torch(exp, exp, device)\n",
    "            print(series_sum[:3,:3])\n",
    "            print(exp[:3, :3])\n",
    "            print()\n",
    "        return series_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_kernel', 'test_kernel', 'labels_train', 'labels_test']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernels = np.load('../data/myrtle7_kernels.npz')\n",
    "list(kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.eye(10)\n",
    "a[0,1] = 1\n",
    "b = np.eye(10)\n",
    "matmul_via_torch(a, b, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.99999999e-01, -9.31322575e-10],\n",
       "       [ 0.00000000e+00,  9.99999999e-01]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_exp_term_numpy(- a, device)[:2,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 16000\n",
    "train_kernel = kernels['train_kernel'][:N, :N]\n",
    "test_kernel  = kernels['test_kernel'][:, :N]\n",
    "\n",
    "labels_train = kernels['labels_train'][:N]\n",
    "labels_test  = kernels['labels_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 16000), (2000, 16000), (16000,), (2000,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_kernel.shape, test_kernel.shape, labels_train.shape, labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99999996, 0.99566936, 0.99371328, 0.99647623, 0.99540464],\n",
       "       [0.99566936, 1.        , 0.99317682, 0.99668258, 0.99447368],\n",
       "       [0.99371328, 0.99317682, 0.99999998, 0.99330106, 0.9941452 ],\n",
       "       [0.99647623, 0.99668258, 0.99330106, 0.99999994, 0.99457984],\n",
       "       [0.99540464, 0.99447368, 0.9941452 , 0.99457984, 1.        ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_kernel[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99999996, 0.99566936, 0.99371328, 0.99647623, 0.99540464],\n",
       "       [0.99566936, 1.        , 0.99317682, 0.99668258, 0.99447368],\n",
       "       [0.99371328, 0.99317682, 0.99999998, 0.99330106, 0.9941452 ],\n",
       "       [0.99647623, 0.99668258, 0.99330106, 0.99999994, 0.99457984],\n",
       "       [0.99540464, 0.99447368, 0.9941452 , 0.99457984, 1.        ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_kernel[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00 -4.42165864e-11 -4.41297191e-11]\n",
      " [-4.42165864e-11  1.00000000e+00 -4.41058955e-11]\n",
      " [-4.41297191e-11 -4.41058955e-11  1.00000000e+00]]\n",
      "[[ 1.00000000e+00 -8.84331417e-11 -8.82594070e-11]\n",
      " [-8.84331417e-11  1.00000000e+00 -8.82117599e-11]\n",
      " [-8.82594070e-11 -8.82117599e-11  1.00000000e+00]]\n",
      "\n",
      "[[ 1.00000000e+00 -8.84331261e-11 -8.82593915e-11]\n",
      " [-8.84331261e-11  1.00000000e+00 -8.82117443e-11]\n",
      " [-8.82593915e-11 -8.82117443e-11  1.00000000e+00]]\n",
      "[[ 1.00000000e+00 -1.76866159e-10 -1.76518689e-10]\n",
      " [-1.76866159e-10  1.00000000e+00 -1.76423395e-10]\n",
      " [-1.76518689e-10 -1.76423395e-10  1.00000000e+00]]\n",
      "\n",
      "[[ 1.00000000e+00 -1.76866081e-10 -1.76518612e-10]\n",
      " [-1.76866081e-10  1.00000000e+00 -1.76423317e-10]\n",
      " [-1.76518612e-10 -1.76423317e-10  1.00000000e+00]]\n",
      "[[ 1.00000000e+00 -3.53731818e-10 -3.53036880e-10]\n",
      " [-3.53731818e-10  1.00000000e+00 -3.52846292e-10]\n",
      " [-3.53036880e-10 -3.52846292e-10  1.00000000e+00]]\n",
      "\n",
      "[[ 1.00000000e+00 -3.53731490e-10 -3.53036553e-10]\n",
      " [-3.53731490e-10  1.00000000e+00 -3.52845965e-10]\n",
      " [-3.53036553e-10 -3.52845965e-10  1.00000000e+00]]\n",
      "[[ 9.99999999e-01 -7.07461639e-10 -7.06071766e-10]\n",
      " [-7.07461639e-10  9.99999999e-01 -7.05690590e-10]\n",
      " [-7.06071766e-10 -7.05690590e-10  9.99999999e-01]]\n",
      "\n",
      "[[ 9.99999999e-01 -7.07460313e-10 -7.06070441e-10]\n",
      " [-7.07460313e-10  9.99999999e-01 -7.05689266e-10]\n",
      " [-7.06070441e-10 -7.05689266e-10  9.99999999e-01]]\n",
      "[[ 9.99999999e-01 -1.41491529e-09 -1.41213555e-09]\n",
      " [-1.41491529e-09  9.99999999e-01 -1.41137321e-09]\n",
      " [-1.41213555e-09 -1.41137321e-09  9.99999999e-01]]\n",
      "\n",
      "[[ 9.99999999e-01 -1.41490997e-09 -1.41213024e-09]\n",
      " [-1.41490997e-09  9.99999999e-01 -1.41136789e-09]\n",
      " [-1.41213024e-09 -1.41136789e-09  9.99999999e-01]]\n",
      "[[ 9.99999997e-01 -2.82979864e-09 -2.82423919e-09]\n",
      " [-2.82979864e-09  9.99999997e-01 -2.82271451e-09]\n",
      " [-2.82423919e-09 -2.82271451e-09  9.99999997e-01]]\n",
      "\n",
      "[[ 9.99999997e-01 -2.82977735e-09 -2.82421792e-09]\n",
      " [-2.82977735e-09  9.99999997e-01 -2.82269325e-09]\n",
      " [-2.82421792e-09 -2.82269325e-09  9.99999997e-01]]\n",
      "[[ 9.99999994e-01 -5.65946949e-09 -5.64835073e-09]\n",
      " [-5.65946949e-09  9.99999994e-01 -5.64530143e-09]\n",
      " [-5.64835073e-09 -5.64530143e-09  9.99999994e-01]]\n",
      "\n",
      "[[ 9.99999994e-01 -5.65938432e-09 -5.64826564e-09]\n",
      " [-5.65938432e-09  9.99999994e-01 -5.64521638e-09]\n",
      " [-5.64826564e-09 -5.64521638e-09  9.99999994e-01]]\n",
      "[[ 9.99999989e-01 -1.13184279e-08 -1.12961909e-08]\n",
      " [-1.13184279e-08  9.99999989e-01 -1.12900925e-08]\n",
      " [-1.12961909e-08 -1.12900925e-08  9.99999989e-01]]\n",
      "\n",
      "[[ 9.99999989e-01 -1.13180872e-08 -1.12958505e-08]\n",
      " [-1.13180872e-08  9.99999989e-01 -1.12897523e-08]\n",
      " [-1.12958505e-08 -1.12897523e-08  9.99999989e-01]]\n",
      "[[ 9.99999977e-01 -2.26348115e-08 -2.25903396e-08]\n",
      " [-2.26348115e-08  9.99999977e-01 -2.25781438e-08]\n",
      " [-2.25903396e-08 -2.25781438e-08  9.99999977e-01]]\n",
      "\n",
      "[[ 9.99999977e-01 -2.26334490e-08 -2.25889784e-08]\n",
      " [-2.26334490e-08  9.99999977e-01 -2.25767833e-08]\n",
      " [-2.25889784e-08 -2.25767833e-08  9.99999977e-01]]\n",
      "[[ 9.99999955e-01 -4.52614477e-08 -4.51725119e-08]\n",
      " [-4.52614477e-08  9.99999955e-01 -4.51481244e-08]\n",
      " [-4.51725119e-08 -4.51481244e-08  9.99999955e-01]]\n",
      "\n",
      "[[ 9.99999955e-01 -4.52559994e-08 -4.51670691e-08]\n",
      " [-4.52559994e-08  9.99999955e-01 -4.51426841e-08]\n",
      " [-4.51670691e-08 -4.51426841e-08  9.99999955e-01]]\n",
      "[[ 9.99999909e-01 -9.04902055e-08 -9.03123669e-08]\n",
      " [-9.04902055e-08  9.99999909e-01 -9.02636073e-08]\n",
      " [-9.03123669e-08 -9.02636073e-08  9.99999909e-01]]\n",
      "\n",
      "[[ 9.99999909e-01 -9.04684280e-08 -9.02906112e-08]\n",
      " [-9.04684280e-08  9.99999909e-01 -9.02418621e-08]\n",
      " [-9.02906112e-08 -9.02418621e-08  9.99999909e-01]]\n",
      "[[ 9.99999818e-01 -1.80849746e-07 -1.80494200e-07]\n",
      " [-1.80849746e-07  9.99999818e-01 -1.80396743e-07]\n",
      " [-1.80494200e-07 -1.80396743e-07  9.99999818e-01]]\n",
      "\n",
      "[[ 9.99999818e-01 -1.80762762e-07 -1.80407303e-07]\n",
      " [-1.80762762e-07  9.99999818e-01 -1.80309888e-07]\n",
      " [-1.80407303e-07 -1.80309888e-07  9.99999818e-01]]\n",
      "[[ 9.99999637e-01 -3.61177586e-07 -3.60467019e-07]\n",
      " [-3.61177586e-07  9.99999637e-01 -3.60272354e-07]\n",
      " [-3.60467019e-07 -3.60272354e-07  9.99999637e-01]]\n",
      "\n",
      "[[ 9.99999638e-01 -3.60830653e-07 -3.60120434e-07]\n",
      " [-3.60830653e-07  9.99999638e-01 -3.59925934e-07]\n",
      " [-3.60120434e-07 -3.59925934e-07  9.99999638e-01]]\n",
      "[[ 9.99999277e-01 -7.20273571e-07 -7.18854527e-07]\n",
      " [-7.20273571e-07  9.99999277e-01 -7.18466189e-07]\n",
      " [-7.18854527e-07 -7.18466189e-07  9.99999276e-01]]\n",
      "\n",
      "[[ 9.99999278e-01 -7.18893831e-07 -7.17476173e-07]\n",
      " [-7.18893831e-07  9.99999278e-01 -7.17088492e-07]\n",
      " [-7.17476173e-07 -7.17088492e-07  9.99999278e-01]]\n",
      "[[ 9.99998561e-01 -1.43226866e-06 -1.42943889e-06]\n",
      " [-1.43226866e-06  9.99998561e-01 -1.42866616e-06]\n",
      " [-1.42943889e-06 -1.42866616e-06  9.99998561e-01]]\n",
      "\n",
      "[[ 9.99998567e-01 -1.42681304e-06 -1.42398874e-06]\n",
      " [-1.42681304e-06  9.99998567e-01 -1.42321861e-06]\n",
      " [-1.42398874e-06 -1.42321861e-06  9.99998567e-01]]\n",
      "[[ 9.99997155e-01 -2.83180297e-06 -2.82617631e-06]\n",
      " [-2.83180297e-06  9.99997155e-01 -2.82464644e-06]\n",
      " [-2.82617631e-06 -2.82464644e-06  9.99997155e-01]]\n",
      "\n",
      "[[ 9.99997177e-01 -2.81047757e-06 -2.80487233e-06]\n",
      " [-2.81047757e-06  9.99997177e-01 -2.80335262e-06]\n",
      " [-2.80487233e-06 -2.80335262e-06  9.99997176e-01]]\n",
      "[[ 9.99994439e-01 -5.53564440e-06 -5.52451963e-06]\n",
      " [-5.53564440e-06  9.99994438e-01 -5.52152085e-06]\n",
      " [-5.52451963e-06 -5.52152085e-06  9.99994438e-01]]\n",
      "\n",
      "[[ 9.99994520e-01 -5.45417178e-06 -5.44312886e-06]\n",
      " [-5.45417178e-06  9.99994520e-01 -5.44016889e-06]\n",
      " [-5.44312886e-06 -5.44016889e-06  9.99994519e-01]]\n",
      "[[ 9.99989367e-01 -1.05823137e-05 -1.05605554e-05]\n",
      " [-1.05823137e-05  9.99989366e-01 -1.05547908e-05]\n",
      " [-1.05605554e-05 -1.05547908e-05  9.99989364e-01]]\n",
      "\n",
      "[[ 9.99989664e-01 -1.02848326e-05 -1.02633732e-05]\n",
      " [-1.02848326e-05  9.99989663e-01 -1.02577504e-05]\n",
      " [-1.02633732e-05 -1.02577504e-05  9.99989660e-01]]\n",
      "[[ 9.99980521e-01 -1.93777053e-05 -1.93359842e-05]\n",
      " [-1.93777053e-05  9.99980517e-01 -1.93253062e-05]\n",
      " [-1.93359842e-05 -1.93253062e-05  9.99980510e-01]]\n",
      "\n",
      "[[ 9.99981516e-01 -1.83836542e-05 -1.83429321e-05]\n",
      " [-1.83836542e-05  9.99981511e-01 -1.83327278e-05]\n",
      " [-1.83429321e-05 -1.83327278e-05  9.99981501e-01]]\n",
      "[[ 9.99967037e-01 -3.27638993e-05 -3.26864786e-05]\n",
      " [-3.27638993e-05  9.99967024e-01 -3.26679772e-05]\n",
      " [-3.26864786e-05 -3.26679772e-05  9.99966996e-01]]\n",
      "\n",
      "[[ 9.99969841e-01 -2.99604050e-05 -2.98858037e-05]\n",
      " [-2.99604050e-05  9.99969826e-01 -2.98686380e-05]\n",
      " [-2.98858037e-05 -2.98686380e-05  9.99969793e-01]]\n",
      "[[ 9.99951209e-01 -4.84002404e-05 -4.82626228e-05]\n",
      " [-4.84002404e-05  9.99951167e-01 -4.82337802e-05]\n",
      " [-4.82626228e-05 -4.82337802e-05  9.99951078e-01]]\n",
      "\n",
      "[[ 9.99957019e-01 -4.25932809e-05 -4.24615147e-05]\n",
      " [-4.25932809e-05  9.99956971e-01 -4.24354390e-05]\n",
      " [-4.24615147e-05 -4.24354390e-05  9.99956870e-01]]\n",
      "[[ 9.99939807e-01 -5.94293066e-05 -5.91917181e-05]\n",
      " [-5.94293066e-05  9.99939687e-01 -5.91518397e-05]\n",
      " [-5.91917181e-05 -5.91518397e-05  9.99939434e-01]]\n",
      "\n",
      "[[ 9.99947118e-01 -5.21213787e-05 -5.18912200e-05]\n",
      " [-5.21213787e-05  9.99946991e-01 -5.18548259e-05]\n",
      " [-5.18912200e-05 -5.18548259e-05  9.99946724e-01]]\n",
      "[[ 9.99935965e-01 -6.25346496e-05 -6.21165715e-05]\n",
      " [-6.25346496e-05  9.99935671e-01 -6.20636637e-05]\n",
      " [-6.21165715e-05 -6.20636637e-05  9.99935053e-01]]\n",
      "\n",
      "[[ 9.99941091e-01 -5.74111490e-05 -5.69985966e-05]\n",
      " [-5.74111490e-05  9.99940793e-01 -5.69481412e-05]\n",
      " [-5.69985966e-05 -5.69481412e-05  9.99940164e-01]]\n",
      "[[ 9.99934273e-01 -6.27550014e-05 -6.19836829e-05]\n",
      " [-6.27550014e-05  9.99933629e-01 -6.19076225e-05]\n",
      " [-6.19836829e-05 -6.19076225e-05  9.99932268e-01]]\n",
      "\n",
      "[[ 9.99936921e-01 -6.01090096e-05 -5.93418762e-05]\n",
      " [-6.01090096e-05  9.99936275e-01 -5.92671229e-05]\n",
      " [-5.93418762e-05 -5.92671229e-05  9.99934909e-01]]\n",
      "[[ 9.99931229e-01 -6.28577602e-05 -6.13871740e-05]\n",
      " [-6.28577602e-05  9.99929886e-01 -6.12651785e-05]\n",
      " [-6.13871740e-05 -6.12651785e-05  9.99927042e-01]]\n",
      "\n",
      "[[ 9.99932555e-01 -6.15324420e-05 -6.00692507e-05]\n",
      " [-6.15324420e-05  9.99931215e-01 -5.99480685e-05]\n",
      " [-6.00692507e-05 -5.99480685e-05  9.99928370e-01]]\n",
      "[[ 9.99925154e-01 -6.30516143e-05 -6.02097158e-05]\n",
      " [-6.30516143e-05  9.99922432e-01 -5.99966676e-05]\n",
      " [-6.02097158e-05 -5.99966676e-05  9.99916629e-01]]\n",
      "\n",
      "[[ 9.99925826e-01 -6.23807571e-05 -5.95633643e-05]\n",
      " [-6.23807571e-05  9.99923120e-01 -5.93513280e-05]\n",
      " [-5.95633643e-05 -5.93513280e-05  9.99917321e-01]]\n",
      "[[ 9.99913049e-01 -6.33973294e-05 -5.79194589e-05]\n",
      " [-6.33973294e-05  9.99907641e-01 -5.75273887e-05]\n",
      " [-5.79194589e-05 -5.75273887e-05  9.99895949e-01]]\n",
      "\n",
      "[[ 9.99913421e-01 -6.30305576e-05 -5.76450612e-05]\n",
      " [-6.30305576e-05  9.99908073e-01 -5.72556639e-05]\n",
      " [-5.76450612e-05 -5.72556639e-05  9.99896407e-01]]\n",
      "[[ 9.99889023e-01 -6.39288491e-05 -5.35883223e-05]\n",
      " [-6.39288491e-05  9.99878511e-01 -5.28491297e-05]\n",
      " [-5.35883223e-05 -5.28491297e-05  9.99855161e-01]]\n",
      "\n",
      "[[ 9.99889342e-01 -6.36309426e-05 -5.36336234e-05]\n",
      " [-6.36309426e-05  9.99879056e-01 -5.29025730e-05]\n",
      " [-5.36336234e-05 -5.29025730e-05  9.99855811e-01]]\n",
      "[[ 9.99841650e-01 -6.44122314e-05 -4.58536671e-05]\n",
      " [-6.44122314e-05  9.99821924e-01 -4.44536712e-05]\n",
      " [-4.58536671e-05 -4.44536712e-05  9.99775730e-01]]\n",
      "\n",
      "[[ 9.99842285e-01 -6.38813664e-05 -4.65154979e-05]\n",
      " [-6.38813664e-05  9.99823347e-01 -4.51343567e-05]\n",
      " [-4.65154979e-05 -4.51343567e-05  9.99777557e-01]]\n",
      "[[ 9.99749301e-01 -6.34761301e-05 -3.35966332e-05]\n",
      " [-6.34761301e-05  9.99714530e-01 -3.09416024e-05]\n",
      " [-3.35966332e-05 -3.09416024e-05  9.99624438e-01]]\n",
      "\n",
      "[[ 9.99751136e-01 -6.21541121e-05 -3.58934463e-05]\n",
      " [-6.21541121e-05  9.99718782e-01 -3.32386679e-05]\n",
      " [-3.58934463e-05 -3.32386679e-05  9.99630152e-01]]\n",
      "[[ 9.99572122e-01 -5.65028671e-05 -1.87525495e-05]\n",
      " [-5.65028671e-05  9.99517180e-01 -1.34992489e-05]\n",
      " [-1.87525495e-05 -1.34992489e-05  9.99345637e-01]]\n",
      "\n",
      "[[ 9.99577067e-01 -5.39004603e-05 -2.45957550e-05]\n",
      " [-5.39004603e-05  9.99528048e-01 -1.90750798e-05]\n",
      " [-2.45957550e-05 -1.90750798e-05  9.99361136e-01]]\n",
      "[[ 9.99237231e-01 -3.38098729e-05 -1.12764207e-05]\n",
      " [-3.38098729e-05  9.99164269e-01  5.95210909e-07]\n",
      " [-1.12764207e-05  5.95210909e-07  9.98848973e-01]]\n",
      "\n",
      "[[ 9.99248007e-01 -3.17365309e-05 -2.10201775e-05]\n",
      " [-3.17365309e-05  9.99185311e-01 -8.10125916e-06]\n",
      " [-2.10201775e-05 -8.10125916e-06  9.98881609e-01]]\n",
      "[[ 9.98606729e-01  1.34825745e-05 -2.64721579e-05]\n",
      " [ 1.34825745e-05  9.98530805e-01  2.71559034e-06]\n",
      " [-2.64721579e-05  2.71559034e-06  9.97972314e-01]]\n",
      "\n",
      "[[ 9.98626828e-01  9.56886718e-06 -3.39994768e-05]\n",
      " [ 9.56886718e-06  9.98562487e-01 -5.02828715e-06]\n",
      " [-3.39994768e-05 -5.02828715e-06  9.98027858e-01]]\n",
      "[[ 9.97415799e-01  8.34809164e-05 -6.59058237e-05]\n",
      " [ 8.34809164e-05  9.97361999e-01 -7.69539816e-06]\n",
      " [-6.59058237e-05 -7.69539815e-06  9.96403769e-01]]\n",
      "\n",
      "[[ 9.97455283e-01  7.03821874e-05 -6.37592362e-05]\n",
      " [ 7.03821874e-05  9.97411088e-01 -1.38358965e-05]\n",
      " [-6.37592362e-05 -1.38358965e-05  9.96502418e-01]]\n",
      "[[ 9.95175747e-01  1.71579524e-04 -1.16449159e-04]\n",
      " [ 1.71579524e-04  9.95184124e-01 -3.84095606e-05]\n",
      " [-1.16449159e-04 -3.84095606e-05  9.93606512e-01]]\n",
      "\n",
      "[[ 9.95257409e-01  1.49313875e-04 -1.07132559e-04]\n",
      " [ 1.49313875e-04  9.95280815e-01 -3.95491616e-05]\n",
      " [-1.07132559e-04 -3.95491616e-05  9.93799683e-01]]\n",
      "[[ 9.90991731e-01  2.75684192e-04 -1.81925949e-04]\n",
      " [ 2.75684192e-04  9.91176947e-01 -8.66725806e-05]\n",
      " [-1.81925949e-04 -8.66725806e-05  9.88698743e-01]]\n",
      "\n",
      "[[ 9.91155331e-01  2.46016912e-04 -1.74338707e-04]\n",
      " [ 2.46016912e-04  9.91378166e-01 -7.09089568e-05]\n",
      " [-1.74338707e-04 -7.09089568e-05  9.89065258e-01]]\n",
      "[[ 9.83212190e-01  3.99337676e-04 -3.00178698e-04]\n",
      " [ 3.99337676e-04  9.83890445e-01 -1.06041725e-04]\n",
      " [-3.00178698e-04 -1.06041725e-04  9.80154118e-01]]\n",
      "\n",
      "[[ 9.83551168e-01  3.62060383e-04 -2.89176567e-04]\n",
      " [ 3.62060383e-04  9.84272441e-01 -7.99404885e-05]\n",
      " [-2.89176567e-04 -7.99404885e-05  9.80774046e-01]]\n",
      "[[ 9.68895203e-01  5.42276438e-04 -4.96718096e-04]\n",
      " [ 5.42276438e-04  9.70649926e-01 -7.06653906e-05]\n",
      " [-4.96718096e-04 -7.06653906e-05  9.65107860e-01]]\n",
      "\n",
      "[[ 9.69633612e-01  4.89814549e-04 -4.57902788e-04]\n",
      " [ 4.89814549e-04  9.71364610e-01 -6.83027066e-05]\n",
      " [-4.57902788e-04 -6.83027066e-05  9.66129488e-01]]\n",
      "[[ 9.43009527e-01  6.70167323e-04 -7.29727869e-04]\n",
      " [ 6.70167323e-04  9.46683895e-01 -5.63301382e-05]\n",
      " [-7.29727869e-04 -5.63301382e-05  9.38397223e-01]]\n",
      "\n",
      "[[ 9.44630813e-01  5.97938124e-04 -6.53976726e-04]\n",
      " [ 5.97938124e-04  9.48154653e-01 -7.59916724e-05]\n",
      " [-6.53976726e-04 -7.59916723e-05  9.40280084e-01]]\n",
      "[[ 8.97280270e-01  7.20118925e-04 -9.41721346e-04]\n",
      " [ 7.20118925e-04  9.04125590e-01 -1.11367956e-04]\n",
      " [-9.41721346e-04 -1.11367956e-04  8.91563699e-01]]\n",
      "\n",
      "[[ 9.00845899e-01  6.52713931e-04 -8.60250011e-04]\n",
      " [ 6.52713931e-04  9.07310421e-01 -1.09829896e-04]\n",
      " [-8.60250010e-04 -1.09829896e-04  8.95398106e-01]]\n",
      "[[ 8.19154006e-01  6.88285765e-04 -1.18109000e-03]\n",
      " [ 6.88285765e-04  8.30862025e-01 -1.66191918e-04]\n",
      " [-1.18109000e-03 -1.66191917e-04  8.11862405e-01]]\n",
      "\n",
      "[[ 8.27210910e-01  6.44528637e-04 -1.12452023e-03]\n",
      " [ 6.44528637e-04  8.38054299e-01 -1.54464287e-04]\n",
      " [-1.12452023e-03 -1.54464287e-04  8.20239383e-01]]\n",
      "[[ 6.93353928e-01  5.77800766e-04 -1.57864220e-03]\n",
      " [ 5.77800766e-04  7.11550600e-01 -2.30308125e-04]\n",
      " [-1.57864220e-03 -2.30308125e-04  6.83803840e-01]]\n",
      "\n",
      "[[ 7.11833008e-01  5.43699312e-04 -1.46657022e-03]\n",
      " [ 5.43699312e-04  7.28227288e-01 -2.08023300e-04]\n",
      " [-1.46657022e-03 -2.08023299e-04  7.02900961e-01]]\n",
      "[[ 5.11601509e-01  3.07905806e-04 -1.94178666e-03]\n",
      " [ 3.07905806e-04  5.36241686e-01 -2.69485828e-04]\n",
      " [-1.94178666e-03 -2.69485827e-04  4.99799729e-01]]\n",
      "\n",
      "[[ 5.51732431e-01  3.14649013e-04 -1.66027127e-03]\n",
      " [ 3.14649013e-04  5.72987082e-01 -2.12415609e-04]\n",
      " [-1.66027127e-03 -2.12415608e-04  5.41303465e-01]]\n",
      "[[ 2.95137628e-01 -9.58110690e-05 -1.65286931e-03]\n",
      " [-9.58110696e-05  3.21140002e-01 -1.53701360e-04]\n",
      " [-1.65286931e-03 -1.53701358e-04  2.83747231e-01]]\n",
      "\n",
      "[[ 3.68871548e-01  2.89338611e-05 -1.40553710e-03]\n",
      " [ 2.89338606e-05  3.90465001e-01 -1.37683701e-04]\n",
      " [-1.40553710e-03 -1.37683700e-04  3.59140484e-01]]\n",
      "[[ 1.10252559e-01 -3.26598820e-04 -7.22532786e-04]\n",
      " [-3.26598821e-04  1.27523628e-01 -1.75463577e-06]\n",
      " [-7.22532786e-04 -1.75463477e-06  1.03585862e-01]]\n",
      "\n",
      "[[ 2.10063199e-01 -1.15029048e-04 -8.63693792e-04]\n",
      " [-1.15029048e-04  2.25925301e-01 -5.46704745e-05]\n",
      " [-8.63693792e-04 -5.46704737e-05  2.03386275e-01]]\n",
      "[[ 1.92607143e-02 -1.67854612e-04 -1.04600943e-04]\n",
      " [-1.67854613e-04  2.43176356e-02  3.25232188e-05]\n",
      " [-1.04600943e-04  3.25232191e-05  1.76318892e-02]]\n",
      "\n",
      "[[ 1.07931116e-01 -9.09321136e-05 -4.45018996e-04]\n",
      " [-9.09321139e-05  1.16746359e-01 -1.99006573e-05]\n",
      " [-4.45018996e-04 -1.99006568e-05  1.04329448e-01]]\n",
      "[[ 8.84782778e-04 -1.58161307e-05 -2.07989500e-06]\n",
      " [-1.58161308e-05  1.23253805e-03  3.45374624e-06]\n",
      " [-2.07989500e-06  3.45374626e-06  7.96680002e-04]]\n",
      "\n",
      "[[ 5.40430832e-02 -4.69783075e-05 -2.22636473e-04]\n",
      " [-4.69783077e-05  5.84830349e-02 -9.69919621e-06]\n",
      " [-2.22636473e-04 -9.69919597e-06  5.22346870e-02]]\n",
      "[[ 3.79000401e-06 -5.39004519e-08 -1.56190985e-08]\n",
      " [-5.39004522e-08  5.55075814e-06 -2.34016860e-08]\n",
      " [-1.56190986e-08 -2.34016851e-08  3.73113644e-06]]\n",
      "\n",
      "[[ 2.70217306e-02 -2.34892122e-05 -1.11320959e-04]\n",
      " [-2.34892123e-05  2.92417943e-02 -4.85127364e-06]\n",
      " [-1.11320959e-04 -4.85127353e-06  2.61175593e-02]]\n",
      "[[ 6.44727961e-10  4.14043879e-10 -6.55872591e-10]\n",
      " [ 4.14043880e-10  1.38161436e-09  6.47200435e-11]\n",
      " [-6.55872596e-10  6.47200697e-11  1.04721273e-08]]\n",
      "\n",
      "[[ 1.35108653e-02 -1.17445836e-05 -5.56605274e-05]\n",
      " [-1.17445837e-05  1.46208972e-02 -2.42563372e-06]\n",
      " [-5.56605274e-05 -2.42563366e-06  1.30587804e-02]]\n",
      "[[ 6.67660794e-14  4.41555607e-14 -6.70588545e-13]\n",
      " [ 4.41555624e-14  9.11537557e-14 -6.17949261e-14]\n",
      " [-6.70588549e-13 -6.17949016e-14  9.21948072e-12]]\n",
      "\n",
      "[[ 6.75543266e-03 -5.87229182e-06 -2.78302637e-05]\n",
      " [-5.87229184e-06  7.31044861e-03 -1.21281686e-06]\n",
      " [-2.78302637e-05 -1.21281683e-06  6.52939019e-03]]\n",
      "[[ 4.38259532e-20  5.75747587e-21 -5.91405543e-19]\n",
      " [ 5.75747748e-21  1.46254303e-21 -7.32432859e-20]\n",
      " [-5.91405547e-19 -7.32432646e-20  8.00872629e-18]]\n",
      "\n",
      "CPU times: user 16min 41s, sys: 15min 5s, total: 31min 47s\n",
      "Wall time: 18min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "sz = 16000\n",
    "\n",
    "lr = 1e5\n",
    "\n",
    "exp_term = - lr * compute_exp_term_numpy(- lr * train_kernel[:sz, :sz], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.eye(10)[labels_train[:sz]] * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.],\n",
       "       [-1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.],\n",
       "       [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.75543266e+02,  5.87229182e-01,  2.78302637e+00,\n",
       "        -1.62493695e+00,  7.92699184e-02],\n",
       "       [ 5.87229184e-01, -7.31044861e+02,  1.21281686e-01,\n",
       "         2.73982328e+00, -6.05988130e-01],\n",
       "       [ 2.78302637e+00,  1.21281683e-01, -6.52939019e+02,\n",
       "         5.42324090e-02, -1.94434468e+00],\n",
       "       [-1.62493695e+00,  2.73982328e+00,  5.42324081e-02,\n",
       "        -7.50512061e+02,  1.44969441e+00],\n",
       "       [ 7.92699184e-02, -6.05988127e-01, -1.94434468e+00,\n",
       "         1.44969441e+00, -6.87920425e+02]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_term[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.814"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred       = np.dot(test_kernel[:, :sz], np.dot(exp_term, - y_train))\n",
    "np.average(y_pred.argmax(axis=1) == labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kernel = kernels['train_kernel']\n",
    "test_kernel  = kernels['test_kernel']\n",
    "labels_train = kernels['labels_train']\n",
    "labels_test  = kernels['labels_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 1024000000 bytes. Error code 12 (Cannot allocate memory)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-113-0553da994ec5>\u001b[0m in \u001b[0;36mcompute_exp_term_numpy\u001b[0;34m(M, device, n_iter)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mseries_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mprod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul_via_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-111-9d9abe2cc418>\u001b[0m in \u001b[0;36mmatmul_via_torch\u001b[0;34m(a, b, device, step)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0ma_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mb_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 1024000000 bytes. Error code 12 (Cannot allocate memory)\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "sz = 50000\n",
    "\n",
    "lr = 1e5\n",
    "\n",
    "exp_term = - lr * compute_exp_term_numpy(- lr * train_kernel[:sz, :sz], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2000,50000) and (16000,10) not aligned: 50000 (dim 1) != 16000 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-53c4e8c32982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_kernel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2000,50000) and (16000,10) not aligned: 50000 (dim 1) != 16000 (dim 0)"
     ]
    }
   ],
   "source": [
    "y_pred       = np.dot(test_kernel[:, :sz], np.dot(exp_term, - y_train))\n",
    "np.average(y_pred.argmax(axis=1) == labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
