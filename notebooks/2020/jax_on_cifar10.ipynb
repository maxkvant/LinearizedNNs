{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jax_on_cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f026ddbf726f4d75a5403369c26af682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cce8225eaf5149a6b05bd7733d1c2dda",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e5336a900f9a427ca2f16c0016f12d42",
              "IPY_MODEL_8cbf5e90878b45769b626b8f35e7ae10"
            ]
          }
        },
        "cce8225eaf5149a6b05bd7733d1c2dda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5336a900f9a427ca2f16c0016f12d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_74c523f79076496ebd2751de28632e58",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1fce878106f24b339ce486be43335d61"
          }
        },
        "8cbf5e90878b45769b626b8f35e7ae10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c56c47facb4a4befb30f4c1e8d4aed90",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:06&lt;00:00, 25008317.16it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_413909e648964b3d9a458077159ca27d"
          }
        },
        "74c523f79076496ebd2751de28632e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1fce878106f24b339ce486be43335d61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c56c47facb4a4befb30f4c1e8d4aed90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "413909e648964b3d9a458077159ca27d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fb0rfDrH4nQ",
        "colab_type": "code",
        "outputId": "2ef75a7c-a9c0-42c0-8c9c-2896d454d484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "source": [
        "!pip install neural-tangents"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting neural-tangents\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/e3/c191dd23f6a15199902157557b3ac59427673c1f5f0bc06580dca8003fe5/neural_tangents-0.1.9-py2.py3-none-any.whl (77kB)\n",
            "\r\u001b[K     |████▏                           | 10kB 19.3MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from neural-tangents) (0.7)\n",
            "Requirement already satisfied: jax>=0.1.58 in /usr/local/lib/python3.6/dist-packages (from neural-tangents) (0.1.62)\n",
            "Collecting frozendict\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/55/a12ded2c426a4d2bee73f88304c9c08ebbdbadb82569ebdd6a0c007cfd08/frozendict-1.2.tar.gz\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.6/dist-packages (from jax>=0.1.58->neural-tangents) (3.2.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from jax>=0.1.58->neural-tangents) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from jax>=0.1.58->neural-tangents) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py->jax>=0.1.58->neural-tangents) (1.12.0)\n",
            "Building wheels for collected packages: frozendict\n",
            "  Building wheel for frozendict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for frozendict: filename=frozendict-1.2-cp36-none-any.whl size=3149 sha256=71aab260a5c79f912a0fc684b89233c85a3f4379d8d1f7255afa8cb8df37a092\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/6c/e9/534386165bd12cf1885582c75eb6d0ffcb321b65c23fe0f834\n",
            "Successfully built frozendict\n",
            "Installing collected packages: frozendict, neural-tangents\n",
            "Successfully installed frozendict-1.2 neural-tangents-0.1.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIYVjUNJyZl-",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbuYAvktiDw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import itertools\n",
        "\n",
        "import numpy.random as npr\n",
        "\n",
        "import jax.numpy as np\n",
        "from jax.config import config\n",
        "from jax import jit, grad, random\n",
        "from  jax.nn import log_softmax\n",
        "\n",
        "from jax.experimental import optimizers\n",
        "import jax.experimental.stax as jax_stax\n",
        "import neural_tangents.stax as nt_stax\n",
        "\n",
        "import neural_tangents\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.datasets import FashionMNIST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al_eETI_iMnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_to_numpy(dataloader):\n",
        "    X = []\n",
        "    y = []\n",
        "    for batch_id, (cur_X, cur_y) in enumerate(dataloader):\n",
        "        X.extend(cur_X.numpy())\n",
        "        y.extend(cur_y.numpy())\n",
        "    X = np.asarray(X)\n",
        "    y = np.asarray(y)\n",
        "    return X, y\n",
        "\n",
        "def _one_hot(x, k, dtype=np.float32):\n",
        "  \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
        "  return np.array(x[:, None] == np.arange(k), dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxobG2mUlVkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cifar_10():\n",
        "  torch.manual_seed(0)\n",
        "\n",
        "  D = 32\n",
        "  num_classes = 10\n",
        "\n",
        "  torch.manual_seed(0)\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "      device = torch.device('cuda:0')\n",
        "  else:\n",
        "      device = torch.device('cpu')\n",
        "\n",
        "  cifar10_stats = {\n",
        "      \"mean\" : (0.4914, 0.4822, 0.4465),\n",
        "      \"std\"  : (0.24705882352941178, 0.24352941176470588, 0.2615686274509804),\n",
        "  }\n",
        "\n",
        "  simple_transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(cifar10_stats['mean'], cifar10_stats['std']),\n",
        "  ])\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "                    datasets.CIFAR10(root='./data', train=True, download=True, transform=simple_transform),\n",
        "                batch_size=2048, shuffle=True, pin_memory=True)\n",
        "\n",
        "  test_loader  = torch.utils.data.DataLoader(\n",
        "                    datasets.CIFAR10(root='./data', train=False, download=True, transform=simple_transform),\n",
        "                batch_size=2048, shuffle=True, pin_memory=True)\n",
        "  \n",
        "  train_images, train_labels = data_to_numpy(train_loader)\n",
        "  test_images,  test_labels  = data_to_numpy(test_loader)\n",
        "\n",
        "  train_images = np.transpose(train_images, (0, 2, 3, 1))\n",
        "  test_images  = np.transpose(test_images , (0, 2, 3, 1))\n",
        "\n",
        "  train_labels = _one_hot(train_labels, num_classes)\n",
        "  test_labels  = _one_hot(test_labels,  num_classes)\n",
        "  return train_images, train_labels, test_images, test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po4zTFUOlqc_",
        "colab_type": "code",
        "outputId": "dad86e6c-dbd5-4cde-a066-c375b0d6d659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "f026ddbf726f4d75a5403369c26af682",
            "cce8225eaf5149a6b05bd7733d1c2dda",
            "e5336a900f9a427ca2f16c0016f12d42",
            "8cbf5e90878b45769b626b8f35e7ae10",
            "74c523f79076496ebd2751de28632e58",
            "1fce878106f24b339ce486be43335d61",
            "c56c47facb4a4befb30f4c1e8d4aed90",
            "413909e648964b3d9a458077159ca27d"
          ]
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "train_images, train_labels, test_images, test_labels = cifar_10()\n",
        "train_images.shape, train_labels.shape, test_images.shape, test_labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f026ddbf726f4d75a5403369c26af682",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "\n",
            "CPU times: user 1min 22s, sys: 26.3 s, total: 1min 48s\n",
            "Wall time: 1min 31s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPdVuVLYoXBg",
        "colab_type": "code",
        "outputId": "1c7dccbe-d0b2-4703-e958-c3c32dfdf9d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_images.shape, train_labels.shape, test_images.shape, test_labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 10), (10000, 32, 32, 3), (10000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHqvbQrHxldR",
        "colab_type": "text"
      },
      "source": [
        "## Define training primitives\n",
        "\n",
        "Note: The training code is based on the following example: https://github.com/google/jax/blob/master/examples/mnist_classifier.py."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfZ3JeDRonFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(params, batch):\n",
        "  inputs, targets = batch\n",
        "  preds = predict(params, inputs)\n",
        "  return -np.mean(np.sum(log_softmax(preds, axis=1) * targets, axis=1))\n",
        "\n",
        "def accuracy(params, batch):\n",
        "  inputs, targets = batch\n",
        "  target_class = np.argmax(targets, axis=1)\n",
        "  predicted_class = np.argmax(predict(params, inputs), axis=1)\n",
        "  return np.mean(predicted_class == target_class)\n",
        "\n",
        "@jit\n",
        "def update(i, opt_state, batch):\n",
        "  params = get_params(opt_state)\n",
        "  return opt_update(i, grad(loss)(params, batch), opt_state)\n",
        "\n",
        "rng_state = npr.RandomState(0)\n",
        "\n",
        "def data_stream_of(images, labels, batch_size=500, batch_limit=None):\n",
        "  assert len(images) == len(labels)\n",
        "  rng = npr.RandomState(0)\n",
        "\n",
        "  n = len(images)\n",
        "  perm = rng.permutation(n)\n",
        "  for i in range(n // batch_size):\n",
        "    if (batch_limit is not None) and i >= batch_limit:\n",
        "      break\n",
        "    batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
        "    yield images[batch_idx], labels[batch_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cee5VLeZxzVG",
        "colab_type": "text"
      },
      "source": [
        "## Train a small CNN in JAX with NTK parameterization\n",
        "\n",
        "Here I do a few epochs to make sure that my training code works.\n",
        "\n",
        "I do mix `jax.stax` with `neural_tangents.stax` because I want to use both BatchNorm and NTK parameterizaton. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw_2zOQ1JHa-",
        "colab_type": "code",
        "outputId": "6f95166a-b5a1-49e8-e314-b88678e0bbbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "channels = 32\n",
        "num_classes = 10\n",
        "\n",
        "init_random_params, predict = jax_stax.serial(\n",
        "      nt_stax.Conv(channels, (3, 3), padding='SAME'),                jax_stax.BatchNorm(), nt_stax.Relu(),\n",
        "      nt_stax.Conv(channels, (3, 3), strides=(2,2), padding='SAME'), jax_stax.BatchNorm(), nt_stax.Relu(),\n",
        "      nt_stax.Conv(channels, (3, 3), strides=(2,2), padding='SAME'), jax_stax.BatchNorm(), nt_stax.Relu(),\n",
        "      nt_stax.Conv(channels, (3, 3), strides=(2,2), padding='SAME'), jax_stax.BatchNorm(), nt_stax.Relu(),\n",
        "      nt_stax.AvgPool((1, 1)),   nt_stax.Flatten(), \n",
        "      nt_stax.Dense(num_classes), jax_stax.Identity,\n",
        ")\n",
        "rng = random.PRNGKey(0)\n",
        "\n",
        "step_size = 10.\n",
        "num_epochs = 10\n",
        "batch_size = 500\n",
        "momentum_mass = 0.9\n",
        "\n",
        "opt_init, opt_update, get_params = optimizers.momentum(step_size, mass=momentum_mass)\n",
        "\n",
        "_, init_params = init_random_params(rng, (batch_size, 32, 32, 3))\n",
        "opt_state = opt_init(init_params)\n",
        "itercount = itertools.count()\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "\n",
        "  for batch in data_stream_of(train_images, train_labels):\n",
        "    opt_state = update(next(itercount), opt_state, batch)\n",
        "  params = get_params(opt_state)\n",
        "\n",
        "  train_accs = [accuracy(params, batch) for batch in data_stream_of(train_images, train_labels)]  \n",
        "  train_acc  = np.average(train_accs)\n",
        "  test_accs  = [accuracy(params, batch) for batch in data_stream_of(test_images, test_labels)]  \n",
        "  test_acc   = np.average(test_accs)\n",
        "  \n",
        "  epoch_time = time.time() - start_time\n",
        "\n",
        "  print(f\"Epoch {epoch} in {epoch_time:0.2f} sec\")\n",
        "  print(f\"Training set accuracy {train_acc}\")\n",
        "  print(f\"Test set accuracy {test_acc}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training...\n",
            "Epoch 0 in 13.36 sec\n",
            "Training set accuracy 0.4674600064754486\n",
            "Test set accuracy 0.46229997277259827\n",
            "Epoch 1 in 11.62 sec\n",
            "Training set accuracy 0.5352200269699097\n",
            "Test set accuracy 0.5210000872612\n",
            "Epoch 2 in 11.41 sec\n",
            "Training set accuracy 0.5723000168800354\n",
            "Test set accuracy 0.5527001023292542\n",
            "Epoch 3 in 11.30 sec\n",
            "Training set accuracy 0.5975600481033325\n",
            "Test set accuracy 0.57340008020401\n",
            "Epoch 4 in 11.43 sec\n",
            "Training set accuracy 0.6060200333595276\n",
            "Test set accuracy 0.5822001099586487\n",
            "Epoch 5 in 11.45 sec\n",
            "Training set accuracy 0.6427800059318542\n",
            "Test set accuracy 0.607900083065033\n",
            "Epoch 6 in 11.58 sec\n",
            "Training set accuracy 0.648140013217926\n",
            "Test set accuracy 0.6154000759124756\n",
            "Epoch 7 in 11.45 sec\n",
            "Training set accuracy 0.6545000076293945\n",
            "Test set accuracy 0.6219999194145203\n",
            "Epoch 8 in 11.48 sec\n",
            "Training set accuracy 0.6666399836540222\n",
            "Test set accuracy 0.6288000345230103\n",
            "Epoch 9 in 11.50 sec\n",
            "Training set accuracy 0.6705000400543213\n",
            "Test set accuracy 0.6308000087738037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8lAFJbPxdkX",
        "colab_type": "text"
      },
      "source": [
        "## Train a ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7-fX58nnWdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10\n",
        "\n",
        "def WideResnetBlock(channels, strides=(1, 1), channel_mismatch=False):\n",
        "  Main = jax_stax.serial(\n",
        "      nt_stax.Conv(channels, (3, 3), strides, padding='SAME'), jax_stax.BatchNorm(), nt_stax.Relu(), \n",
        "      nt_stax.Conv(channels, (3, 3), padding='SAME'),          jax_stax.BatchNorm(), nt_stax.Relu(), \n",
        "      jax_stax.Identity\n",
        "  )\n",
        "  Shortcut = nt_stax.Identity() if not channel_mismatch else nt_stax.Conv(channels, (3, 3), strides, padding='SAME')\n",
        "  return jax_stax.serial(jax_stax.FanOut(2),\n",
        "                         jax_stax.parallel(Main, Shortcut),\n",
        "                         jax_stax.FanInSum,\n",
        "                         jax_stax.Identity)\n",
        "\n",
        "def WideResnetGroup(n, channels, strides=(1, 1)):\n",
        "  blocks = []\n",
        "  blocks += [WideResnetBlock(channels, strides, channel_mismatch=True)]\n",
        "  for _ in range(n - 1):\n",
        "    blocks += [WideResnetBlock(channels, (1, 1))]\n",
        "  return jax_stax.serial(*blocks)\n",
        "\n",
        "def WideResnet(num_classes, num_channels=32, block_size=1):\n",
        "  return jax_stax.serial(\n",
        "      nt_stax.Conv(num_channels, (3, 3), padding='SAME'), jax_stax.BatchNorm(), nt_stax.Relu(),\n",
        "      WideResnetGroup(block_size, num_channels),\n",
        "      WideResnetGroup(block_size, num_channels, (2, 2)),\n",
        "      WideResnetGroup(block_size, num_channels, (2, 2)),\n",
        "      nt_stax.AvgPool((1, 1)),\n",
        "      nt_stax.Flatten(),\n",
        "      nt_stax.Dense(num_classes),\n",
        "      jax_stax.Identity\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z46NcGJd3HxL",
        "colab_type": "code",
        "outputId": "a8421e1b-6cc8-4c18-ce5d-01f22c8b5d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "init_random_params, predict = WideResnet(num_classes)\n",
        "\n",
        "rng = random.PRNGKey(0)\n",
        "\n",
        "step_size = 10.\n",
        "num_epochs = 10\n",
        "momentum_mass = 0.9\n",
        "\n",
        "opt_init, opt_update, get_params = optimizers.momentum(step_size, mass=momentum_mass)\n",
        "\n",
        "_, init_params = init_random_params(rng, (batch_size, 32, 32, 3))\n",
        "opt_state = opt_init(init_params)\n",
        "itercount = itertools.count()\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "\n",
        "  for batch in data_stream_of(train_images, train_labels):\n",
        "    opt_state = update(next(itercount), opt_state, batch)\n",
        "  params = get_params(opt_state)\n",
        "\n",
        "  train_accs = [accuracy(params, batch) for batch in data_stream_of(train_images, train_labels, batch_limit=4)]  \n",
        "  train_acc  = np.average(train_accs)\n",
        "  test_accs  = [accuracy(params, batch) for batch in data_stream_of(test_images, test_labels, batch_limit=4)]  \n",
        "  test_acc   = np.average(test_accs)\n",
        "  \n",
        "  epoch_time = time.time() - start_time\n",
        "\n",
        "  print(f\"Epoch {epoch} in {epoch_time:0.2f} sec\")\n",
        "  print(f\"Training set accuracy {train_acc}\")\n",
        "  print(f\"Test set accuracy {test_acc}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training...\n",
            "Epoch 0 in 10.01 sec\n",
            "Training set accuracy 0.4259999990463257\n",
            "Test set accuracy 0.44600000977516174\n",
            "Epoch 1 in 5.16 sec\n",
            "Training set accuracy 0.44450002908706665\n",
            "Test set accuracy 0.4360000193119049\n",
            "Epoch 2 in 5.13 sec\n",
            "Training set accuracy 0.5074999928474426\n",
            "Test set accuracy 0.5080000162124634\n",
            "Epoch 3 in 5.18 sec\n",
            "Training set accuracy 0.5400000214576721\n",
            "Test set accuracy 0.5275000333786011\n",
            "Epoch 4 in 5.23 sec\n",
            "Training set accuracy 0.5705000162124634\n",
            "Test set accuracy 0.5400000214576721\n",
            "Epoch 5 in 5.19 sec\n",
            "Training set accuracy 0.5830000042915344\n",
            "Test set accuracy 0.5649999976158142\n",
            "Epoch 6 in 5.16 sec\n",
            "Training set accuracy 0.6200000047683716\n",
            "Test set accuracy 0.5915000438690186\n",
            "Epoch 7 in 5.16 sec\n",
            "Training set accuracy 0.6640000343322754\n",
            "Test set accuracy 0.6075000762939453\n",
            "Epoch 8 in 5.14 sec\n",
            "Training set accuracy 0.655500054359436\n",
            "Test set accuracy 0.6155000329017639\n",
            "Epoch 9 in 5.18 sec\n",
            "Training set accuracy 0.6620000004768372\n",
            "Test set accuracy 0.6234999895095825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqghpbVIwomC",
        "colab_type": "text"
      },
      "source": [
        "## Train a linearization of ResNet\n",
        "\n",
        "Note: I have removed BatchNorm layers because with them training didn't work. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQIdS3uzktGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "from jax.tree_util import tree_multimap\n",
        "from jax.api import jvp\n",
        "from jax.api import vjp\n",
        "\n",
        "# copied from \n",
        "def linearize(f, params):\n",
        "  \"\"\"Returns a function `f_lin`, the first order taylor approximation to `f`.\n",
        "  Example:\n",
        "    >>> # Compute the MSE of the first order Taylor series of a function.\n",
        "    >>> f_lin = linearize(f, params)\n",
        "    >>> mse = np.mean((f(new_params, x) - f_lin(new_params, x)) ** 2)\n",
        "  \"\"\"\n",
        "  @jit\n",
        "  def f_lin(p, *args, **kwargs):\n",
        "    dparams = tree_multimap(lambda x, y: x - y, p, params)\n",
        "    f_params_x, proj = jvp(lambda param: f(param, *args, **kwargs),\n",
        "                           (params,), (dparams,))\n",
        "    return f_params_x + proj\n",
        "  return f_lin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bzk2t2JUqh7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def WideResnetBlock(channels, strides=(1, 1), channel_mismatch=False):\n",
        "  Main = jax_stax.serial(\n",
        "      nt_stax.Conv(channels, (3, 3), strides, padding='SAME'), nt_stax.Relu(), \n",
        "      nt_stax.Conv(channels, (3, 3), padding='SAME'),          nt_stax.Relu(), \n",
        "      jax_stax.Identity\n",
        "  )\n",
        "  Shortcut = nt_stax.Identity() if not channel_mismatch else nt_stax.Conv(channels, (3, 3), strides, padding='SAME')\n",
        "  return jax_stax.serial(jax_stax.FanOut(2),\n",
        "                         jax_stax.parallel(Main, Shortcut),\n",
        "                         jax_stax.FanInSum,\n",
        "                         jax_stax.Identity)\n",
        "\n",
        "def WideResnetGroup(n, channels, strides=(1, 1)):\n",
        "  blocks = []\n",
        "  blocks += [WideResnetBlock(channels, strides, channel_mismatch=True)]\n",
        "  for _ in range(n - 1):\n",
        "    blocks += [WideResnetBlock(channels, (1, 1))]\n",
        "  return jax_stax.serial(*blocks)\n",
        "\n",
        "def WideResnet(num_classes, num_channels=32, block_size=1):\n",
        "  return jax_stax.serial(\n",
        "      nt_stax.Conv(num_channels, (3, 3), padding='SAME'), nt_stax.Relu(),\n",
        "      WideResnetGroup(block_size, num_channels),\n",
        "      WideResnetGroup(block_size, num_channels, (2, 2)),\n",
        "      WideResnetGroup(block_size, num_channels, (2, 2)),\n",
        "      nt_stax.AvgPool((1, 1)),\n",
        "      nt_stax.Flatten(),\n",
        "      nt_stax.Dense(num_classes),\n",
        "      jax_stax.Identity\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tlTPH4ckoF5",
        "colab_type": "code",
        "outputId": "b94994d0-6bc4-45c5-8edd-939dd4adb48d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_classes = 10\n",
        "\n",
        "init_random_params, predict = WideResnet(num_classes, num_channels=512)\n",
        "\n",
        "rng = random.PRNGKey(0)\n",
        "\n",
        "step_size = 1.\n",
        "num_epochs = 100\n",
        "momentum_mass = 0.9\n",
        "\n",
        "opt_init, opt_update, get_params = optimizers.momentum(step_size, mass=momentum_mass)\n",
        "\n",
        "_, init_params = init_random_params(rng, (batch_size, 32, 32, 3))\n",
        "opt_state = opt_init(init_params)\n",
        "itercount = itertools.count()\n",
        "\n",
        "predict = linearize(predict, init_params) # !important: linearization\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "\n",
        "  for batch in data_stream_of(train_images, train_labels, batch_size=100):\n",
        "    opt_state = update(next(itercount), opt_state, batch)\n",
        "  params = get_params(opt_state)\n",
        "\n",
        "  train_accs = [accuracy(params, batch) for batch in data_stream_of(train_images, train_labels, batch_size=100, batch_limit=20)]  \n",
        "  train_acc  = np.average(train_accs)\n",
        "  test_accs  = [accuracy(params, batch) for batch in data_stream_of(test_images, test_labels, batch_size=100, batch_limit=20)]  \n",
        "  test_acc   = np.average(test_accs)\n",
        "  \n",
        "  epoch_time = time.time() - start_time\n",
        "\n",
        "  print(f\"Epoch {epoch} in {epoch_time:0.2f} sec\")\n",
        "  print(f\"Training set accuracy {train_acc}\")\n",
        "  print(f\"Test set accuracy {test_acc}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training...\n",
            "Epoch 0 in 297.33 sec\n",
            "Training set accuracy 0.46000003814697266\n",
            "Test set accuracy 0.40749993920326233\n",
            "Epoch 1 in 293.79 sec\n",
            "Training set accuracy 0.4874999523162842\n",
            "Test set accuracy 0.4374999701976776\n",
            "Epoch 2 in 293.76 sec\n",
            "Training set accuracy 0.5044999718666077\n",
            "Test set accuracy 0.4364999234676361\n",
            "Epoch 3 in 293.63 sec\n",
            "Training set accuracy 0.5345000624656677\n",
            "Test set accuracy 0.4519999623298645\n",
            "Epoch 4 in 293.60 sec\n",
            "Training set accuracy 0.578000009059906\n",
            "Test set accuracy 0.4830000102519989\n",
            "Epoch 5 in 293.71 sec\n",
            "Training set accuracy 0.593500018119812\n",
            "Test set accuracy 0.4700000286102295\n",
            "Epoch 6 in 293.54 sec\n",
            "Training set accuracy 0.5855000615119934\n",
            "Test set accuracy 0.4819999635219574\n",
            "Epoch 7 in 293.47 sec\n",
            "Training set accuracy 0.5919999480247498\n",
            "Test set accuracy 0.4714999794960022\n",
            "Epoch 8 in 293.67 sec\n",
            "Training set accuracy 0.5975000262260437\n",
            "Test set accuracy 0.4784999489784241\n",
            "Epoch 9 in 293.60 sec\n",
            "Training set accuracy 0.6184999346733093\n",
            "Test set accuracy 0.48799997568130493\n",
            "Epoch 10 in 293.69 sec\n",
            "Training set accuracy 0.6040000319480896\n",
            "Test set accuracy 0.4715000092983246\n",
            "Epoch 11 in 293.20 sec\n",
            "Training set accuracy 0.6169999837875366\n",
            "Test set accuracy 0.48700007796287537\n",
            "Epoch 12 in 293.23 sec\n",
            "Training set accuracy 0.6305000185966492\n",
            "Test set accuracy 0.49199995398521423\n",
            "Epoch 13 in 293.37 sec\n",
            "Training set accuracy 0.5895000100135803\n",
            "Test set accuracy 0.46599993109703064\n",
            "Epoch 14 in 293.69 sec\n",
            "Training set accuracy 0.6190000176429749\n",
            "Test set accuracy 0.47749996185302734\n",
            "Epoch 15 in 293.64 sec\n",
            "Training set accuracy 0.6284999251365662\n",
            "Test set accuracy 0.47849997878074646\n",
            "Epoch 16 in 293.49 sec\n",
            "Training set accuracy 0.6380000114440918\n",
            "Test set accuracy 0.4729999005794525\n",
            "Epoch 17 in 293.67 sec\n",
            "Training set accuracy 0.6509999632835388\n",
            "Test set accuracy 0.46699997782707214\n",
            "Epoch 18 in 293.64 sec\n",
            "Training set accuracy 0.6464999914169312\n",
            "Test set accuracy 0.46999993920326233\n",
            "Epoch 19 in 293.70 sec\n",
            "Training set accuracy 0.6980000138282776\n",
            "Test set accuracy 0.492000013589859\n",
            "Epoch 20 in 293.74 sec\n",
            "Training set accuracy 0.703499972820282\n",
            "Test set accuracy 0.5020000338554382\n",
            "Epoch 21 in 293.64 sec\n",
            "Training set accuracy 0.7064999938011169\n",
            "Test set accuracy 0.49449998140335083\n",
            "Epoch 22 in 293.68 sec\n",
            "Training set accuracy 0.6639999747276306\n",
            "Test set accuracy 0.47499990463256836\n",
            "Epoch 23 in 293.68 sec\n",
            "Training set accuracy 0.5734999775886536\n",
            "Test set accuracy 0.445499986410141\n",
            "Epoch 24 in 293.79 sec\n",
            "Training set accuracy 0.5609999895095825\n",
            "Test set accuracy 0.4314999580383301\n",
            "Epoch 25 in 293.71 sec\n",
            "Training set accuracy 0.6280000805854797\n",
            "Test set accuracy 0.4634999930858612\n",
            "Epoch 26 in 293.73 sec\n",
            "Training set accuracy 0.6094999313354492\n",
            "Test set accuracy 0.4574999511241913\n",
            "Epoch 27 in 293.77 sec\n",
            "Training set accuracy 0.6640000343322754\n",
            "Test set accuracy 0.47300001978874207\n",
            "Epoch 28 in 293.82 sec\n",
            "Training set accuracy 0.6644999980926514\n",
            "Test set accuracy 0.4700000286102295\n",
            "Epoch 29 in 293.80 sec\n",
            "Training set accuracy 0.6439999938011169\n",
            "Test set accuracy 0.45649996399879456\n",
            "Epoch 30 in 293.83 sec\n",
            "Training set accuracy 0.6470000147819519\n",
            "Test set accuracy 0.4544999599456787\n",
            "Epoch 31 in 293.86 sec\n",
            "Training set accuracy 0.6794999837875366\n",
            "Test set accuracy 0.4714999198913574\n",
            "Epoch 32 in 293.93 sec\n",
            "Training set accuracy 0.6649999618530273\n",
            "Test set accuracy 0.4514999985694885\n",
            "Epoch 33 in 293.95 sec\n",
            "Training set accuracy 0.6899999976158142\n",
            "Test set accuracy 0.46000000834465027\n",
            "Epoch 34 in 293.74 sec\n",
            "Training set accuracy 0.6659999489784241\n",
            "Test set accuracy 0.46849989891052246\n",
            "Epoch 35 in 293.75 sec\n",
            "Training set accuracy 0.6634999513626099\n",
            "Test set accuracy 0.4624999463558197\n",
            "Epoch 36 in 293.76 sec\n",
            "Training set accuracy 0.6864999532699585\n",
            "Test set accuracy 0.47099995613098145\n",
            "Epoch 37 in 293.74 sec\n",
            "Training set accuracy 0.7144998908042908\n",
            "Test set accuracy 0.48600003123283386\n",
            "Epoch 38 in 293.68 sec\n",
            "Training set accuracy 0.7320000529289246\n",
            "Test set accuracy 0.4894999563694\n",
            "Epoch 39 in 293.68 sec\n",
            "Training set accuracy 0.7990000247955322\n",
            "Test set accuracy 0.5139999389648438\n",
            "Epoch 40 in 293.70 sec\n",
            "Training set accuracy 0.8264999389648438\n",
            "Test set accuracy 0.5224999785423279\n",
            "Epoch 41 in 293.72 sec\n",
            "Training set accuracy 0.7915000319480896\n",
            "Test set accuracy 0.5115000009536743\n",
            "Epoch 42 in 293.67 sec\n",
            "Training set accuracy 0.7774999141693115\n",
            "Test set accuracy 0.5015000104904175\n",
            "Epoch 43 in 293.77 sec\n",
            "Training set accuracy 0.7644999027252197\n",
            "Test set accuracy 0.5045000314712524\n",
            "Epoch 44 in 293.71 sec\n",
            "Training set accuracy 0.7885000109672546\n",
            "Test set accuracy 0.5005000233650208\n",
            "Epoch 45 in 293.71 sec\n",
            "Training set accuracy 0.8145000338554382\n",
            "Test set accuracy 0.5015000104904175\n",
            "Epoch 46 in 293.66 sec\n",
            "Training set accuracy 0.7924998998641968\n",
            "Test set accuracy 0.49049997329711914\n",
            "Epoch 47 in 293.49 sec\n",
            "Training set accuracy 0.8080000281333923\n",
            "Test set accuracy 0.5029999613761902\n",
            "Epoch 48 in 293.46 sec\n",
            "Training set accuracy 0.8095000386238098\n",
            "Test set accuracy 0.515500009059906\n",
            "Epoch 49 in 293.48 sec\n",
            "Training set accuracy 0.8105000853538513\n",
            "Test set accuracy 0.5289999842643738\n",
            "Epoch 50 in 293.48 sec\n",
            "Training set accuracy 0.8040000200271606\n",
            "Test set accuracy 0.5199999213218689\n",
            "Epoch 51 in 293.32 sec\n",
            "Training set accuracy 0.7775000333786011\n",
            "Test set accuracy 0.5020000338554382\n",
            "Epoch 52 in 293.36 sec\n",
            "Training set accuracy 0.7850000262260437\n",
            "Test set accuracy 0.510499894618988\n",
            "Epoch 53 in 293.45 sec\n",
            "Training set accuracy 0.8200001120567322\n",
            "Test set accuracy 0.5324999690055847\n",
            "Epoch 54 in 293.58 sec\n",
            "Training set accuracy 0.8390000462532043\n",
            "Test set accuracy 0.533000111579895\n",
            "Epoch 55 in 293.62 sec\n",
            "Training set accuracy 0.843000054359436\n",
            "Test set accuracy 0.5375000834465027\n",
            "Epoch 56 in 293.58 sec\n",
            "Training set accuracy 0.8109999895095825\n",
            "Test set accuracy 0.5139999389648438\n",
            "Epoch 57 in 293.58 sec\n",
            "Training set accuracy 0.7574999928474426\n",
            "Test set accuracy 0.49449998140335083\n",
            "Epoch 58 in 293.52 sec\n",
            "Training set accuracy 0.7409999966621399\n",
            "Test set accuracy 0.4949999451637268\n",
            "Epoch 59 in 293.45 sec\n",
            "Training set accuracy 0.777999997138977\n",
            "Test set accuracy 0.5059999823570251\n",
            "Epoch 60 in 293.40 sec\n",
            "Training set accuracy 0.786500096321106\n",
            "Test set accuracy 0.49400001764297485\n",
            "Epoch 61 in 293.39 sec\n",
            "Training set accuracy 0.8400000929832458\n",
            "Test set accuracy 0.5169999599456787\n",
            "Epoch 62 in 293.53 sec\n",
            "Training set accuracy 0.8515000343322754\n",
            "Test set accuracy 0.5304999351501465\n",
            "Epoch 63 in 293.48 sec\n",
            "Training set accuracy 0.8355000615119934\n",
            "Test set accuracy 0.5099999308586121\n",
            "Epoch 64 in 293.47 sec\n",
            "Training set accuracy 0.8585000038146973\n",
            "Test set accuracy 0.5215000510215759\n",
            "Epoch 65 in 293.50 sec\n",
            "Training set accuracy 0.8620001077651978\n",
            "Test set accuracy 0.5180000066757202\n",
            "Epoch 66 in 293.55 sec\n",
            "Training set accuracy 0.8514999747276306\n",
            "Test set accuracy 0.5304999947547913\n",
            "Epoch 67 in 293.48 sec\n",
            "Training set accuracy 0.8375000357627869\n",
            "Test set accuracy 0.5144999623298645\n",
            "Epoch 68 in 293.26 sec\n",
            "Training set accuracy 0.8504999279975891\n",
            "Test set accuracy 0.5265000462532043\n",
            "Epoch 69 in 293.51 sec\n",
            "Training set accuracy 0.8665000200271606\n",
            "Test set accuracy 0.5435000658035278\n",
            "Epoch 70 in 293.26 sec\n",
            "Training set accuracy 0.8899999856948853\n",
            "Test set accuracy 0.5389999747276306\n",
            "Epoch 71 in 293.04 sec\n",
            "Training set accuracy 0.8890000581741333\n",
            "Test set accuracy 0.5380000472068787\n",
            "Epoch 72 in 293.09 sec\n",
            "Training set accuracy 0.8944999575614929\n",
            "Test set accuracy 0.5405000448226929\n",
            "Epoch 73 in 292.94 sec\n",
            "Training set accuracy 0.8905000686645508\n",
            "Test set accuracy 0.5509999394416809\n",
            "Epoch 74 in 292.83 sec\n",
            "Training set accuracy 0.862500011920929\n",
            "Test set accuracy 0.5404999852180481\n",
            "Epoch 75 in 292.71 sec\n",
            "Training set accuracy 0.9204999804496765\n",
            "Test set accuracy 0.5405000448226929\n",
            "Epoch 76 in 292.62 sec\n",
            "Training set accuracy 0.9259998202323914\n",
            "Test set accuracy 0.5519999861717224\n",
            "Epoch 77 in 292.70 sec\n",
            "Training set accuracy 0.9050000309944153\n",
            "Test set accuracy 0.5385000109672546\n",
            "Epoch 78 in 292.68 sec\n",
            "Training set accuracy 0.8855000734329224\n",
            "Test set accuracy 0.5334999561309814\n",
            "Epoch 79 in 292.59 sec\n",
            "Training set accuracy 0.846500039100647\n",
            "Test set accuracy 0.515500009059906\n",
            "Epoch 80 in 292.56 sec\n",
            "Training set accuracy 0.8335000276565552\n",
            "Test set accuracy 0.5109999775886536\n",
            "Epoch 81 in 292.68 sec\n",
            "Training set accuracy 0.8255000114440918\n",
            "Test set accuracy 0.516499936580658\n",
            "Epoch 82 in 292.76 sec\n",
            "Training set accuracy 0.7739999890327454\n",
            "Test set accuracy 0.500999927520752\n",
            "Epoch 83 in 292.58 sec\n",
            "Training set accuracy 0.7610000371932983\n",
            "Test set accuracy 0.4939999580383301\n",
            "Epoch 84 in 292.59 sec\n",
            "Training set accuracy 0.7754999995231628\n",
            "Test set accuracy 0.4934999942779541\n",
            "Epoch 85 in 292.57 sec\n",
            "Training set accuracy 0.7875000238418579\n",
            "Test set accuracy 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}