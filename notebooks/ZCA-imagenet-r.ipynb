{"nbformat":4,"nbformat_minor":5,"metadata":{"notebookId":"7baa2bec-3af4-4684-b9ec-805aeba7b05a","language_info":{"version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"}},"cells":[{"cell_type":"code","source":"#!g1.1\nimport time\nimport numpy as np\nimport seaborn as sns\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport random\nfrom sklearn.utils.extmath import randomized_svd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms, datasets\nfrom torch import utils\nfrom torch.utils.data import DataLoader, random_split\n\n\nfrom linearized_nns.estimator import Estimator\nfrom linearized_nns.pytorch_impl.estimators import SgdEstimator\nfrom linearized_nns.pytorch_impl.nns import Myrtle5, Myrtle7, Myrtle10\nfrom linearized_nns.pytorch_impl import ClassifierTraining\nfrom linearized_nns.pytorch_impl.matrix_exp import matrix_exp, compute_exp_term\nfrom linearized_nns.pytorch_impl.nns.utils import to_one_hot, print_sizes\nfrom linearized_nns.from_neural_kernels import to_zca, CustomTensorDataset, get_cifar_zca","metadata":{"cellId":"sh0i0jlgroqwtnxsuyc05a","trusted":true},"outputs":[],"execution_count":375},{"cell_type":"code","source":"#!g1.1\n\nDATA_DIR = 'imagenet-r'\n\nNUM_CLASSES = 200\nDEVICE = 'cuda'\nN = 30000\nSEED = 42 ","metadata":{"cellId":"qouwphpdbmzqlsnhiura","trusted":true},"outputs":[],"execution_count":475},{"cell_type":"code","source":"#!g1.1\n\nnp.random.seed(SEED)\nrandom.seed(SEED)\ntorch.manual_seed(SEED)\n\nval_transforms = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.RandomCrop(22),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ndataset = datasets.ImageFolder(DATA_DIR, transform=val_transforms)\ntrainset, testset = random_split(dataset, lengths=[27000, 3000])","metadata":{"cellId":"mukuw5jmtj9recqfisusmt","trusted":true},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'np' is not defined","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)","\u001B[0;32m<ipython-input-2-620391b48272>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mseed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mSEED\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mrandom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mseed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mSEED\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmanual_seed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mSEED\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m val_transforms = transforms.Compose([\n","\u001B[0;31mNameError\u001B[0m: name 'np' is not defined"]}],"execution_count":476},{"cell_type":"code","source":"#!g1.1\nclass ZcaTorch:\n    def __init__(self, V, inv_sqrt_zca_eigs, device):\n        self.V = torch.tensor(V, dtype=torch.float) \\\n            .to(device)\n        self.inv_sqrt_zca_eigs = torch.tensor(inv_sqrt_zca_eigs, dtype=torch.float) \\\n            .to(device)\n        self.device = device\n    \n    def apply(self, batch):\n        orig_shape = batch.shape\n        batch = batch.reshape(batch.shape[0], -1).float()\n        \n        # norimize\n        batch -= batch.mean(dim=1, keepdim=True)\n        batch /= torch.norm(batch, dim=1, keepdim=True)\n\n        # apply zca\n        batch = torch.mm(torch.mm(torch.mm(batch, self.V.T), self.inv_sqrt_zca_eigs), self.V)\n        return batch.reshape(orig_shape)","metadata":{"cellId":"cke1rsjj7pu4juhmw27uvj"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nV                 = torch.load('train_zca_V.pt')\ninv_sqrt_zca_eigs = torch.load('train_zca_inv_sqrt_zca_eigs.pt')","metadata":{"cellId":"0ggsp1oc9ynemuf7eycc0ee"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nV.shape, inv_sqrt_zca_eigs.shape","metadata":{"cellId":"82ovn4293yhbuwhwxtdj65"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nzca = ZcaTorch(V, inv_sqrt_zca_eigs, DEVICE)","metadata":{"cellId":"v7i3xwzycsret1660u7z"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nresnet18 = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=NUM_CLASSES)\nresnet18 = resnet18.to(DEVICE)\nresnet18","metadata":{"cellId":"xnirb1iw35maanq963qfk"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\ntrain_loader = DataLoader(trainset, pin_memory=False, shuffle=True,  batch_size=128)\ntest_loader  = DataLoader(testset,  pin_memory=False, shuffle=False, batch_size=100)","metadata":{"cellId":"bkxwsm7blu49nes5kw8lsc"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"cellId":"3m3dp508g8mu6fffws0lq"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\ndef train(model, train_loader, test_loader, num_epochs=30, learning_rate=0.1):\n    optimizer = SGD(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss()\n    \n    for epoch in range(1, num_epochs + 1):\n        print(f'Epoch {epoch}:')\n        \n        model.train()\n        train_loss = 0\n        train_acc = 0\n        for i, (X, y) in enumerate(train_loader):\n            optimizer.zero_grad()\n            \n            X = X.to(DEVICE)\n            y = y.to(DEVICE)\n            \n            y_pred = model.forward(X)\n            loss   = criterion(y_pred, y)\n            loss.backward()\n            optimizer.step()\n            \n            acc = (y == y_pred.argmax(dim=-1)).float().mean().item()\n            \n            train_acc  += (acc               - train_acc)  / (i + 1)\n            train_loss += (loss.cpu().item() - train_loss) / (i + 1)\n            if (i + 1) % 10 == 0:\n                print(f'\\rtrain_acc {train_acc:.4f} train_loss {train_loss:.4f}', end='')\n        print()\n        model.eval()\n        test_loss = 0\n        test_acc  = 0 \n        for i, (X, y) in enumerate(test_loader):\n            X = X.to(DEVICE)\n            y = y.to(DEVICE)\n            \n            y_pred = model.forward(X)\n            loss   = criterion(y_pred, y)\n            \n            acc = (y == y_pred.argmax(dim=-1)).float().mean().item()\n            \n            test_acc  += (acc               - test_acc)  / (i + 1)\n            test_loss += (loss.cpu().item() - test_loss) / (i + 1)\n            \n        print(f'test_acc {test_acc:.4f} test_loss {test_loss:.4f}')\n        print()\n\nresnet18 = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=NUM_CLASSES)\nmodel    = resnet18.to(DEVICE)\ntrain(model, train_loader, test_loader)","metadata":{"cellId":"moifjkbfcgnfgdx5l06oi7"},"outputs":[],"execution_count":null}]}