{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QO6TsBeCK5Sq"
   },
   "source": [
    "## Download repo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Uua_GEmJuZJ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8gB3Yv3JuNh"
   },
   "outputs": [],
   "source": [
    "REPO_ZIP_FILE = 'LinearizedNNs-master.zip'\n",
    "urllib.request.urlretrieve('https://github.com/maxkvant/LinearizedNNs/archive/master.zip', REPO_ZIP_FILE)\n",
    "\n",
    "REPO_PATH = \"LinearizedNNs-master\"\n",
    "if os.path.exists(REPO_PATH):\n",
    "    shutil.rmtree(REPO_PATH)\n",
    "    \n",
    "with zipfile.ZipFile(REPO_ZIP_FILE, 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n",
    "    \n",
    "assert os.path.exists(REPO_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WTefKYSkK97l"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2GUZzUEyJuA6"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(f\"{REPO_PATH}/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "RucjmvnTKf9T",
    "outputId": "c3d68fea-e033-4a76-e685-f0e670145b86"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "\n",
    "from pytorch_impl.estimators import SgdEstimator\n",
    "from pytorch_impl.nns import warm_up_batch_norm\n",
    "from pytorch_impl import ClassifierTraining\n",
    "from pytorch_impl.matrix_exp import matrix_exp, compute_exp_term\n",
    "from pytorch_impl.nns.utils import to_one_hot\n",
    "from from_neural_kernels import to_zca, CustomTensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yGDlFtGDJs9X"
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "def Conv(in_filters, out_filters, groups=1):\n",
    "    conv = nn.Conv2d(in_filters, out_filters, kernel_size=3, stride=1, padding=1, groups=groups, bias=False)\n",
    "    conv.weight.data *= np.sqrt(3)\n",
    "    return conv  \n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return nn.functional.normalize(input, p=2, dim=1, eps=1e-8)  \n",
    "\n",
    "class ReLU2(nn.Module):\n",
    "    C = np.sqrt(2)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.relu(input, inplace=True) * self.C\n",
    "\n",
    "class ResidualConnection(nn.Module):\n",
    "    def __init__(self, *layers):\n",
    "        super(ResidualConnection, self).__init__()\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return (input + self.layers(input)) / 2.\n",
    "\n",
    "class Myrtle10(nn.Module):\n",
    "    def __init__(self, num_classes=10, input_filters=3, num_filters=256, groups=1):\n",
    "        super(Myrtle10, self).__init__()\n",
    "        filters = num_filters * groups\n",
    "\n",
    "        def Activation():\n",
    "            return ReLU2()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            Conv(input_filters, filters),     Activation(),\n",
    "\n",
    "            #ResidualConnection(\n",
    "              Conv(filters, filters, groups), Activation(),\n",
    "              Conv(filters, filters, groups), Activation(),\n",
    "            #),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            #ResidualConnection(\n",
    "              Conv(filters, filters, groups), Activation(),\n",
    "              Conv(filters, filters, groups), Activation(),\n",
    "            #),\n",
    "            Conv(filters, filters, groups),   Activation(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            #ResidualConnection(\n",
    "              Conv(filters, filters, groups), Activation(),\n",
    "              Conv(filters, filters, groups), Activation(),\n",
    "            #),\n",
    "            Conv(filters, filters, groups),   Activation(),\n",
    "            nn.AvgPool2d(kernel_size=8, stride=8),\n",
    "            \n",
    "            Normalize(),\n",
    "            Flatten()\n",
    "        )\n",
    "        self.classifier =  nn.Linear(num_filters, num_classes, bias=True)\n",
    "        \n",
    "    def readout(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.readout(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bxXS-6Im9WI_"
   },
   "outputs": [],
   "source": [
    "class Myrtle5(nn.Module):\n",
    "    def __init__(self, num_classes=10, input_filters=3, num_filters=256, groups=1):\n",
    "        super(Myrtle5, self).__init__()\n",
    "        filters = num_filters * groups\n",
    "\n",
    "        def Activation():\n",
    "            return ReLU2()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            Conv(input_filters, filters),   Activation(),\n",
    "            Conv(filters, filters, groups), Activation(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            Conv(filters, filters, groups), Activation(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            Conv(filters, filters, groups), Activation(),\n",
    "            nn.AvgPool2d(kernel_size=8, stride=8),\n",
    "            \n",
    "            Normalize(),\n",
    "            Flatten()\n",
    "        )\n",
    "        self.classifier =  nn.Linear(num_filters, num_classes, bias=True)\n",
    "        \n",
    "    def readout(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.readout(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fB-JSFBGHn7A"
   },
   "outputs": [],
   "source": [
    "class Myrtle7(nn.Module):\n",
    "    def __init__(self, num_classes=10, input_filters=3, num_filters=256, groups=1):\n",
    "        super(Myrtle7, self).__init__()\n",
    "        filters = num_filters * groups\n",
    "\n",
    "        def Activation():\n",
    "            return ReLU2()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            Conv(input_filters, filters),   Activation(),\n",
    "            Conv(filters, filters, groups), Activation(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "\n",
    "            Conv(filters, filters, groups), Activation(),\n",
    "            Conv(filters, filters, groups), Activation(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            Conv(filters, filters, groups), Activation(),\n",
    "            Conv(filters, filters, groups), Activation(),\n",
    "            nn.AvgPool2d(kernel_size=8, stride=8),\n",
    "            \n",
    "            Normalize(),\n",
    "            Flatten()\n",
    "        )\n",
    "        self.classifier =  nn.Linear(num_filters, num_classes, bias=True)\n",
    "        \n",
    "    def readout(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.readout(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o57Es5Z9ST6b"
   },
   "source": [
    "## Cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JnRBr9JvvTXN"
   },
   "outputs": [],
   "source": [
    "def get_cifar_zca():\n",
    "    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=None)\n",
    "    testset  = datasets.CIFAR10(root='./data', train=False, download=True, transform=None)\n",
    "\n",
    "    X_train = np.asarray(trainset.data).astype(np.float64)\n",
    "    y_train = np.asarray(trainset.targets)\n",
    "    X_test  = np.asarray(testset.data).astype(np.float64)\n",
    "    y_test  = np.asarray(testset.targets)\n",
    "\n",
    "    (X_train, X_test), global_ZCA = to_zca(X_train, X_test)\n",
    "\n",
    "    X_train = np.transpose(X_train, (0,3,1,2))\n",
    "    X_test  = np.transpose(X_test,  (0,3,1,2))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "W-q8tpxOvNz4",
    "outputId": "0b23a6bd-0655-4946-b0c6-40bf68599def"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "CPU times: user 4min 13s, sys: 1min 17s, total: 5min 30s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train, y_train, X_test, y_test = get_cifar_zca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IsQiD_vMYrep",
    "outputId": "72d0a95f-ab52-4c69-a7cb-8b344e82d0d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "cifar_train = CustomTensorDataset(torch.tensor(X_train), torch.tensor(y_train, dtype=torch.long), transform='all')\n",
    "cifar_test  = CustomTensorDataset(torch.tensor(X_test), torch.tensor(y_test, dtype=torch.long), transform=None)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar_train, batch_size=128, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(cifar_test,  batch_size=128, shuffle=True)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "zPAY9M9OBACI",
    "outputId": "5f66443b-e4bd-46a3-cd39-a8832358270d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04611601"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAcuUlEQVR4nO3deXRb533m8e8PAAmIBDdxk0RSohbKsiyvkSWviZcszuok9UncbGriU0+apKedTqeT5XRmkk7PSWZOm6Sdthk3zrE7rRNn3Dh23Mau7XiJYlu2JMuyLEuiJGshJS4SSXEHCeCdPwCqNEWKEAkQuMDzOcYhcHGB+3t15Yev3vvee805h4iIeI8v2wWIiMjcKMBFRDxKAS4i4lEKcBERj1KAi4h4VGAhN1ZTU+Oam5sXcpMiIp63Y8eOU8652qnLFzTAm5ub2b59+0JuUkTE88zs6HTLNYQiIuJRCnAREY9SgIuIeJQCXETEoxTgIiIepQAXEfEoBbiIiEcpwEVEPEoBLiLiUQt6JmaueGDbsXOWfWrz8ixUIiIyd+qBi4h4lAJcRMSjFOAiIh6lABcR8SgFuIiIRynARUQ8SgEuIuJRCnAREY9SgIuIeJQCXETEoxTgIiIepQAXEfEoBbiIiEcpwEVEPEoBLiLiUQpwERGPUoCLiHiUAlxExKMU4CIiHpVygJuZ38xeNbPHkq9Xmtk2MztoZg+aWXHmyhQRkakupAf+B8Cbk15/B/iuc24N0Avclc7CRETk/FIKcDNrBD4I/DD52oBbgIeSq9wPfDQTBYqIyPRS7YF/D/gTIJ58XQ30OeeiyddtQEOaaxMRkfOYNcDN7ENAl3Nux1w2YGZ3m9l2M9ve3d09l68QEZFppNIDvx74iJkdAX5CYujk+0ClmQWS6zQC7dN92Dl3j3Nuo3NuY21tbRpKFhERSCHAnXNfc841OueagTuBXznnPg08A9yRXG0L8EjGqhQRkXPMZx74fwH+yMwOkhgTvzc9JYmISCoCs6/y75xzzwLPJp8fBjalvyQREUmFzsQUEfEoBbiIiEcpwEVEPEoBLiLiUQpwERGPUoCLiHiUAlxExKMU4CIiHqUAFxHxKAW4iIhHKcBFRDxKAS4i4lEKcBERj1KAi4h4lAJcRMSjFOAiIh6lABcR8SgFuIiIRynARUQ8SgEuIuJRCnAREY9SgIuIeJQCXETEoxTgIiIepQAXEfEoBbiIiEcpwEVEPEoBLiLiUQpwERGPUoCLiHiUAlxExKMU4CIiHqUAFxHxKAW4iIhHKcBFRDxKAS4i4lEKcBERj5o1wM0sZGYvm9lrZvaGmX0zuXylmW0zs4Nm9qCZFWe+XBERmZBKDzwC3OKcuxy4ArjNzK4BvgN81zm3BugF7spcmSIiMtWsAe4SBpMvi5IPB9wCPJRcfj/w0YxUKCIi00ppDNzM/Ga2C+gCngQOAX3OuWhylTagYYbP3m1m281se3d3dzpqFhERUgxw51zMOXcF0AhsAtalugHn3D3OuY3OuY21tbVzLFNERKa6oFkozrk+4BngWqDSzALJtxqB9jTXJiIi55HKLJRaM6tMPl8EvAd4k0SQ35FcbQvwSKaKFBGRcwVmX4WlwP1m5icR+D91zj1mZnuBn5jZ/wBeBe7NYJ0iIjLFrAHunNsNXDnN8sMkxsNFRCQLdCamiIhHKcBFRDxKAS4i4lEKcBERj1KAi4h4lAJcRMSjFOAiIh6lABcR8SgFuIiIRynARUQ8SgEuIuJRCnAREY9SgIuIeJQCXETEoxTgIiIepQAXEfEoBbiIiEcpwEVEPEoBLiLiUQpwERGPUoCLiHiUAlxExKMU4CIiHqUAFxHxKAW4iIhHKcBFRDxKAS4i4lEKcBERj1KAi4h4lAJcRMSjFODAYCTKvVvfondoLNuliIikLJDtArJpdDzG1oOn2HrwFGPROF39o3ztAxdnuywRkZQUbA98MBLlu08d4Ff7umipC7OpeTE/39VOLO6yXZqISEoKNsAPdw8yMBrlc9es4NObV/A71zfT2R/hhUOnsl2aiEhKCjbA23tHCPiMNfVhAG5ZV0dZKMDDO9uzXJmISGoKNsDb+kZYUhEi4Ev8EYSK/HzosqU8/kYHQ5FolqsTEZldQQZ43Dna+0ZorFr0tuUfv6qR4bEYT7zRkaXKRERSN2uAm1mTmT1jZnvN7A0z+4Pk8sVm9qSZtSZ/VmW+3PQ4NRBhLBqnobLkbcs3rqiiafEiHn5VwygikvtS6YFHgf/knFsPXAN82czWA18FnnbOtQBPJ197QnvfCMA5PXAz42NXNPCbg6foODOajdJERFI2a4A7504653Ymnw8AbwINwO3A/cnV7gc+mqki062td4Riv4/asuDZZQ9sO8YD244R8PuIO/jWY3uzWKGIyOwuaAzczJqBK4FtQL1z7mTyrQ6gfobP3G1m281se3d39zxKTZ/2vhGWVYbwmZ3zXk04SE24mENdg1moTEQkdSkHuJmFgX8G/tA51z/5PeecA6Y9A8Y5d49zbqNzbmNtbe28ik2H8VicE30jNFQumnGdVTVhjpweIhqLL2BlIiIXJqUAN7MiEuH9T865nyUXd5rZ0uT7S4GuzJSYXq2dg0TjjsaqkhnXWVVbSiQaZ8+J/hnXERHJtlRmoRhwL/Cmc+4vJ731KLAl+XwL8Ej6y0u/3W19ADRUzdwDX1lTCsCLh04vSE0iInORSg/8euCzwC1mtiv5+ADwbeA9ZtYKvDv5Ouftbj9DqMhHdWnxjOuUhYqoKwvy4mEFuIjkrlmvRuic2wqce7Qv4db0lpN5u9v6aKhchE1zAHOyVbWlbD/Sw3gsTpG/IM93EpEcV1DJNDoeY3/HwHnHvyesqgkzPBY7O+QiIpJrCirA93cMMB5z552BMkHj4CKS6woqwI+cHgKgbtIJPDMpDQZYt6RM4+AikrMKKsDbehOn0FeWzHwAc7JrV1ez/UgvkWgsk2WJiMxJgQX4MDXhYooDqTX72lXVRKJxXjt+JsOViYhcuIIK8OM9IzSkcABzwuaV1Zihu/SISE4qqABv6x2m6Twn8ExVUVLEpQ0V/OagAlxEck/BBHg8PnETh9R74AA3ttSw81gfA6PjGapMRGRuCibAuwYijMfcOdcAn80Na2qJxR0vHe7JUGUiInNTMAHe1jsMnHsTh9lctaKSkmI/v27NjUvhiohMKKAAn7gLz4UNoQQDfjavXMzWVo2Di0huKZgAP94ztx44wI0ttRw+NXS2Fy8ikgsKJsDbekeoLQsSKvJf8GdvbKkBUC9cRHJK4QR43/Ccet8Aa+rCLCkP8WtNJxSRHFI4Ad574VMIJ5gZN7TU8JuDp4jFp71znIjIgiuIAI/FHSf6RubcA4fEMErf8DhvnNBp9SKSGwoiwDv7R+c0B3yy69ckxsF/rXFwEckRBRHgE1MIm+Y4hAJQEw5yWWMFT+7tTFdZIiLzUiABPvcphJO9f8NSdh3vo71vJB1liYjMy6z3xMwHEz3wZSnciWeyB7Yde9vraCwOwON7OrjrhpXpKU5EZI4KpgdeN8c54JNVh4MsrQjxy9dPpqkyEZG5K5AAn98MlMk2NFSw/WgvHWdG0/J9IiJzVRABfrx3mKbFcz+AOdmGZRUAPL5HvXARya68D/BoLM7JvtG09cBry4JcVF/Gv+7pSMv3iYjMVd4HeOdAhGjczfkszOm8/9IlvHKkh64BDaOISPbkfYC3zeMqhDP5wKVLcQ6eeENzwkUke/I/wJNTCBsucArh+bTUhVlTF+YXu06k7TtFRC5UwQT4hc4BP58fv3yc1bVhXj7Sw1891XrOfHERkYWQ9wHe3peeOeBTXbW8Ep/B9qO9af1eEZFU5X2At/WO0JDG8e8JZaEiLlpSzs5jvbrErIhkRd4HeHvf3K8DPpuNK6oYjETZ3zGQke8XETmfvA7wePI64Ok8gDnZ2voyykIBth/tycj3i4icT14HeNdAZN7XAT8fv8+4ankV+zsG6OzXnHARWVh5HeATl5HNxBj4hHesqMIBD+1oy9g2RESmk9cBPnHd7qYMBnhNOMjKmlIe2Hbs7OVmRUQWQl4HeCbmgE/nutXVtPeN8G+6W4+ILKC8D/Dq0mJKijN734qLl5azfHEJ9259K6PbERGZbNYAN7MfmVmXme2ZtGyxmT1pZq3Jn1WZLXNu2vsyMwd8Kp8Zv3NdMzuO9rLreF/GtyciAqn1wO8Dbpuy7KvA0865FuDp5Ouc09Y7nLEZKFN94uomyoIB9cJFZMHMGuDOueeBqROdbwfuTz6/H/homuuaN+cc7b2ZmwM+VTgY4M5NTfzr6yd102MRWRBzHQOvd85N3JKmA6ifaUUzu9vMtpvZ9u7u7jlu7sKdGhwjEo0vWIADbLmuGecc//DCkQXbpogUrnkfxHTOOWDGi4E45+5xzm10zm2sra2d7+ZSNtELztRp9FM9sO0Yzx84xSXLKrjvhSP8/fOHF2S7IlK45hrgnWa2FCD5syt9JaXHQpzEM51b19UxFo3z3IGF+9eGiBSmuQb4o8CW5PMtwCPpKSd92idu5LDAAV5XHuLK5VW8dPg0J89oLFxEMieVaYQ/Bl4ELjKzNjO7C/g28B4zawXenXydU9p6RygPBSgPFS34tm9dV4dz8FdPty74tkWkcMx6hotz7rdneOvWNNeSVpm8jOxsqkqL2bRyMT/d3sbv3riKVbXhrNQhIvktb8/EbM/QjRxSddNFtQQDPv7iyQNZq0FE8lteBrhzbkFP4plOWaiI371xFf+y+ySP7+nIWh0ikr/yMsDPjIwzNBZb0Dng0/nyzWvY0FDO1362my5dL1xE0iwvA3ziKoTZGgOfUBzw8b1PXsnIeIw/fmg3cd07U0TSKM8DPLs9cIA1dWG+8cH1PH+gm/tfPJLtckQkj+RlgB/rGQKgKcs98Amf2bycW9bV8ef/8iYPv6o794hIeuRlgB/oHKS2LEhFycLPAZ+OmfG9O6/g6ubF/McHX+Pvnj1E4goEIiJzl5cB3to5wNr63Jp7XR4q4r4vXM2HL1/Gdx7fxzd+vofeobFslyUiHpbZW9VkQTzuaO0a5BMbm7JdyjmCAT/f/+QVLK0Icc/zh/nZzjY+flUjn71mBS11YQL+vPx9KiIZkncBfuLMCMNjMVpyoAf+wLZj0y7/+gcu5o53NPKjrW/x0I42Hth2jIDPaKhaxLKKRQT8BkDHmVGKAz6K/T6CRX6WVYRorimlurQYM3vbd35q8/KMt0dEckveBXhr5yAAa+vLslzJzCaC/bLGSlbVhtl3sp+llSGO9Yxwsm+E0WhifHxkPEb/6Dhj0TjDYzFeiibuel8WDPCO5ipuWFOT8ft9ikjuyrv/+w90DgCwti53A3yycDDAxubFADRUzjxrxjlH92CEI6eGOdA5wHP7u3nx0GmuW13NjS0Ld511EckdeRjgg9Tl0AyUdDEz6spC1JWF2LRyMR39o/xqXxfP7O9m1/E+Lm+q5B0rcvLe0iKSIXl31Ky1ayAnxr8zbUl5iE9tWs4X37UagE/8nxf5m2cOEtPZniIFI68CPB53HOwapMUjwyfpsHxxCb9/Swvv37CE//XEfr5w3yv0j45nuywRWQB5FeDtfYkZKLl8ADMTQkV+/vq3r+TPP7aB3xw8xcf/9gWOnR7OdlkikmF5FeCtXckDmAUwhDLVj18+jmFsua6Z9t4Rbvv+82w7fDrbZYlIBuVVgB9ITiEspCGUqVbXhvm9m1ZTUhzg0z/cxv996ahO2xfJU3kW4AN5OQPlQtWEg3zpptW8c20tf/rzPXz94deJRGPZLktE0iyvAvxg12DBjX/PJFTk5+8/t5Gv3LyGH798nDv+7kX2dfRnuywRSaO8mQcejztaOwe5c1PuXQMlW/w+44/fdxGXNlbw9Z+9zof/eitfubmFL928mqI5XndlKBLlu08e4FjPMCf6RhiIRBmKRBkeixEM+FhU7KekOEB9WZBPXN3E5Y2VrKguOefUfxGZv7wJ8Pa+EUbGC28GyvlMvhbLF9+1msd2n+C7Tx3g4Vfb+Ny1zdyxsZHy0PmHm+Jxx96T/Tx3oJtn93ex81jf2bnmi0uLqVhUxNKKRSwq9jOePOV/aCzKy0d6+M2hxEHUxqpFvPviet67vp5NKxfrol0iaZI3AT5xCn1LXeHNQElFaTDAJ69ezuVN/expP8O3HtvLX/zbft57yRIuXlpGS30ZteEg/SPj9I2Mc6xnmFfe6mH70V7OjCTmlV+yrJz/8M5VDEWiNFWVUBKc+a9PLO7oGhjlWM8w+zsG+MeXjnLfC0cIBwN8avNyfuuqRi5aol+2IvORNwG+r2MiwBUK57NuSTnfun0Du9v6uO+FI/y69RQPv9o+7bo14WJa6sI015TSUhembJbe+mR+n7G0YhFLKxaxeWU1Y9E4BzoH2HW8jx9tfYt7nj/M5U2VfHrzcj582TIWFfvT1USRgpE3Af7s/i4uWVZe8DNQUnVZYyV/+YkrAOgbHqO1a5DTgxEqFhVTVVpEXVmIx/d0pG17xQEfGxoq2NBQwWAkymvH+3jlSA9/8tBu/usje7jz6uV89toVrK7Vv6BEUpUXAX56MMKOo7185ZaWbJfiCTNdpxygZ2ict05ldvvhYIDr19Rw3epqjpweZttbp/mnbYkhluvXVPPZa1Zw68X1cz7QKlIo8iLAn9nfTdzBey6uz3YpcgHMjJU1paysKWVgdJwdR3vZ9lYPX/zHnYSDAT537Qo+eXUTK6pLs12qSE7KiwB/am8n9eVBNjSUZ7sUmaOyUBE3XVTHjS21tHYO8PKRHn7w3CH+9tlDXLm8ko9cvowPXrqUuvJQtksVyRmeD/DR8RjPt3bzsSsbNNc4D/h9xrql5axbWs7N62p5dNcJHtl1gm/+Yi/f/MVe1i8t551ra7lhTQ2XNlTomIcUNM8H+IuHTzM8FuPd6zV8km+e2ddNWaiIz1yzgs7+Ud482U9r1yA//PVhfvDcISBxOd2Ll5axfHEJjVUlLKtcRHW4mOrSYhaXFhMOBvSLXfKW5wP8qb2dlBT7uXZVdbZLkQyqLw9RXx7ipovqGB2PcTx5Jmh73wg7jvbx7P5uIsl7hk5W5DeqShJhXl8eYkl5iCUVIVZUl9BcU8qqmlIqS4qz0CKR+fN0gDvneOrNTt7ZUkuoSPOIC0WoyE9LfeLkownOOQYjUc6MjDMUiTIUSZwROhSJMTwWZTAS5WDXIDuP9jIYiTL5+ozhYIArmipZW1/GuiVlXLy0nJb6sP5OSc7zdIDvae+nsz+i4RPBzCgLFaV0slE0Hqd3aJxTgxFODUbo6o8wMDrOj18+xsh44qqNPoPm6lJW14XPnszUWLmIxqoS6sqDcwr3SDTGwGg0+RhnMBIlEo0zFo0TjTkCfiMY8BEq8lNdWkxdWYjyRRoCkpl5OsD/eWcbPoObL9Jd2SV1AZ+P2rIgtWXBty2PO0fP0BgdZ0Y5eWaUroFRjpwa4pl9XUSn3Gt0UZGfqpIiwqEAxQEfxX4fAZ+PmHPEnSMac4yOxxgZjzEyFmMgEmVsmiGe2QQDvuQvklLW1IZZv6yCyxorWFoRUrCLdwP8hYOnuP/FI9x5dRPV4eCs64vMxmdGTThITTjIhoaKs8tjcceZkXF6h8foGx5jYDRx9cXhsRiRaCwR1mNRYs7hs8T3+CzRmw4HAxT5fYSKEj3riR52qMhPccBHkc/w+334zYg5RywWZyzmGIokeun9o1FODUbYdriHX77ecXbopyZczOWNlVy5vJKrlldxWVMl4fNcm0bykyf3+OnBCH/44C5W1ZTypx9an+1yJM/5fcbi5KyWbBqPxek4M0pb3wjtvcPsbjvD0/u6ADCDtXVlXNFUyWVNFWxYVsFFS8o0jp/nPBfgzjn+80O76Rse577Pb6Kk2HNNEJmTIr+PpsUlNC0uARKzrobHohzvGaGypIhdx/t4Ym8HD24/DkDAZ6yuDbN2SRlr68KsSY7lN1eX6uJheWJe6WdmtwHfB/zAD51z305LVTPoODPK/36mlV/t6+K/f3g965fpzEspbCXFgbOX5X3fJUt47/p6eofHz06x7OwfZWtrN7947cTbPldXFqShahENlYlHfXmIuvIgdWUhasLFVIeDlId0ADXXzTnAzcwP/A3wHqANeMXMHnXO7U1XcRNebzvDvVsP89juk8Sd41Obl7PluuZ0b0bE88z+fbhn8jh+JBrj1OAYpwcjnBoco3dojN6RMY6dHubMyPg5B2nh7XPoK0uKqFyUuIFHRUkRZcEAZaEAZaEiSor9Z+/EFAz4EmP7fh8BX+JYgM8HziUeceeIxh3ReGLmzXgsMQtnPPk8Eo0zHks8ojHHWCxONBYnGnfE4u7sz7hzxOMOR+I7p/Kb4fMZfjP8fqPI5yPgN4oDPoKBxPGHUMBHcNJxiWDAd7b+iQPTRX4ffp8R8Bl+n+XcL7T59MA3AQedc4cBzOwnwO1A2gP8fz6xj51He/nctc18/vrm5D8hRSRVwYD/bG97KuccI+Mx+kejDIwkpjcORaIMJufQD4/FONk3yuHuobOzaqYL/GwwEuP/U2WqPDt7kBoMI/kfNvF6Sj2TS/vF79/AqjRfLnk+Ad4AHJ/0ug3YPHUlM7sbuDv5ctDM9s91g/8t+UiDGiDDF01dcGqTd+Rju/KxTZDGdq3+s3l9fMV0CzN+BNA5dw9wT6a3cyHMbLtzbmO260gntck78rFd+dgmyP12zeeK+e3A5FvANyaXiYjIAphPgL8CtJjZSjMrBu4EHk1PWSIiMps5D6E456Jm9hXgCRLTCH/knHsjbZVlVk4N6aSJ2uQd+diufGwT5Hi7zE0zBUdERHKf7horIuJRCnAREY/KqwA3s9vMbL+ZHTSzr07zftDMHky+v83Mmie997Xk8v1m9r6FrHs2c22XmTWb2YiZ7Uo+frDQtc8khTa908x2mlnUzO6Y8t4WM2tNPrYsXNXnN882xSbtp5yaDJBCu/7IzPaa2W4ze9rMVkx6z6v76nxtyp195ZzLiweJA6mHgFVAMfAasH7KOl8CfpB8fifwYPL5+uT6QWBl8nv82W5TGtrVDOzJdhvm2KZm4DLgH4A7Ji1fDBxO/qxKPq/ycpuS7w1muw3zaNfNQEny+e9N+vvn5X01bZtybV/lUw/87Kn9zrkxYOLU/sluB+5PPn8IuNUSFze4HfiJcy7inHsLOJj8vlwwn3blqlnb5Jw74pzbDUy9C8L7gCedcz3OuV7gSeC2hSh6FvNpUy5LpV3POOeGky9fInFOCHh7X83UppySTwE+3an9DTOt45yLAmdIXJczlc9my3zaBbDSzF41s+fM7MZMF5ui+fx55+q+mm9dITPbbmYvmdlH01vavFxou+4CfjnHzy6U+bQJcmhf6WLa+e0ksNw5d9rM3gH83Mwucc71Z7swOccK51y7ma0CfmVmrzvnDmW7qAthZp8BNgLvynYt6TJDm3JmX+VTDzyVU/vPrmNmAaACOJ3iZ7Nlzu1KDgmdBnDO7SAx7rc24xXPbj5/3rm6r+ZVl3OuPfnzMPAscGU6i5uHlNplZu8GvgF8xDkXuZDPZsF82pRb+yrbg/DpepD418RhEgchJw5MXDJlnS/z9oN9P00+v4S3H8Q8TO4cxJxPu2on2kHigE07sNgLbZq07n2cexDzLRIHxaqSz73epiogmHxeA7Qy5aBaLreLRIAdAlqmLPfsvjpPm3JqX2X9L0iad8wHgAPJP/hvJJd9i8RvUIAQ8P9IHKR8GVg16bPfSH5uP/D+bLclHe0Cfgt4A9gF7AQ+nO22XECbriYxNjlE4l9Jb0z67BeSbT0IfD7bbZlvm4DrgNeTQfI6cFe223KB7XoK6Ez+PdsFPJoH+2raNuXavtKp9CIiHpVPY+AiIgVFAS4i4lEKcBERj1KAi4h4lAJcRMSjFOAiIh6lABcR8aj/D0H7Uav5H5c6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Myrtle10(num_filters=128, groups=2).to(device)\n",
    "for batch_id, (X, y) in enumerate(train_loader):\n",
    "    if batch_id > 20:\n",
    "        break\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    model.readout(X)\n",
    "\n",
    "_, (X, y) = next(enumerate(train_loader))\n",
    "X, y = X.to(device), y.to(device)\n",
    "\n",
    "\n",
    "output = model.readout(X).detach().cpu().numpy()\n",
    "sns.distplot(output.reshape(-1))\n",
    "\n",
    "np.std(output.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "3UjKNNB55UcK",
    "outputId": "fd172ec4-e69a-4dc2-b325-b6387bbb6bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 3, 3])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10])\n",
      "297290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "297290"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_impl.nns.utils import print_sizes\n",
    "\n",
    "print_sizes(Myrtle10(num_filters=64).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mmwUlcrWPPQt"
   },
   "outputs": [],
   "source": [
    "model = Myrtle10(num_filters=256).to(device)\n",
    "\n",
    "learning_rate = 0.07\n",
    "\n",
    "estimator = SgdEstimator(model, nn.CrossEntropyLoss(), learning_rate)\n",
    "training  = ClassifierTraining(estimator, device)\n",
    "\n",
    "# training.train(train_loader, test_loader, num_epochs=30, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RCVsNNKdbaZh"
   },
   "outputs": [],
   "source": [
    "# ClassifierTraining(estimator, device).get_accuracy(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "l6lV0QkGBg-8",
    "outputId": "08a39365-a527-47fc-dbd4-feddb393e805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "CPU times: user 3min 50s, sys: 1min 4s, total: 4min 54s\n",
      "Wall time: 45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train, labels_train, X_test, labels_test = get_cifar_zca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aUiYk3vjZ4tQ"
   },
   "outputs": [],
   "source": [
    "N = 1280\n",
    "\n",
    "X_train      = torch.tensor(X_train[:N]).float()\n",
    "X_test       = torch.tensor(X_test[:N]).float()\n",
    "labels_train = torch.tensor(labels_train[:N], dtype=torch.long)\n",
    "labels_test  = torch.tensor(labels_test[:N],  dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "HpGzq3CIZhWA",
    "outputId": "5b3e2226-30ea-42b2-9671-e4f8dfe092d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "V_jcnc_wZ8kE",
    "outputId": "39b43ec2-dce7-4cf7-9537-26db2198d249"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vloo3zxHGmmo",
    "outputId": "5d98b46e-0f03-4271-c6fc-8fb2d2ccaada"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "device = torch.device('cuda:0') if (torch.cuda.is_available()) else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u8_wyg-AZG6a"
   },
   "outputs": [],
   "source": [
    "def augment_X(X):\n",
    "    def aug(x):\n",
    "        return CustomTensorDataset.augment_x(x, 'flips') \n",
    "    return torch.stack([aug(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Vjn8rnEsZlYG",
    "outputId": "b47bf042-cc03-4ce1-a34f-05c5f85c9214"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 32, 32])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3Z4eePgkapNG",
    "outputId": "00ef0a8d-12c3-4b36-fa64-afc4467dbfd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 32, 32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augment_X(X_train[:2]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sriHlV_-ILz5"
   },
   "outputs": [],
   "source": [
    "def compute_kernels(models, X_train, X_test, device):\n",
    "    with torch.no_grad():\n",
    "        X_train = X_train.to(device)\n",
    "        X_test  = X_test.to(device)\n",
    "\n",
    "        n_train = len(X_train)\n",
    "        n_test  = len(X_test)\n",
    "\n",
    "        train_kernel = torch.zeros([n_train, n_train]).to(device)\n",
    "        test_kernel  = torch.zeros([n_test,  n_train]).to(device)\n",
    "\n",
    "        scale = np.sqrt(1. / 0.0156249953)\n",
    "\n",
    "        m = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for model_i, model in enumerate(models):\n",
    "            model = model.to(device)\n",
    "            if model_i & (model_i - 1) == 0:\n",
    "                print(f\"{model_i} models done. time {time.time() - start_time:.0f}s\")\n",
    "\n",
    "                train_features = scale * model.readout(X_train) \n",
    "                test_features  = scale * model.readout(X_test)\n",
    "\n",
    "                m += train_features.size()[1]\n",
    "\n",
    "                train_kernel += torch.matmul(train_features, train_features.T)\n",
    "                test_kernel  += torch.matmul(test_features,  train_features.T)\n",
    "\n",
    "        train_kernel /= m\n",
    "        test_kernel  /= m\n",
    "\n",
    "        return train_kernel, test_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DFK4RZoU2-OP"
   },
   "outputs": [],
   "source": [
    "n_models = 5000\n",
    "\n",
    "# 5000 * 32 = 160k\n",
    "\n",
    "models = [Myrtle7(num_filters=32) for _ in range(n_models)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "colab_type": "code",
    "id": "gfoLvIho77hY",
    "outputId": "24b15ef9-dbb8-401b-e1ba-9e47ab24567f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 models done. time 0s\n",
      "1 models done. time 0s\n",
      "2 models done. time 0s\n",
      "4 models done. time 0s\n",
      "8 models done. time 0s\n",
      "16 models done. time 0s\n",
      "32 models done. time 1s\n",
      "64 models done. time 1s\n",
      "128 models done. time 3s\n",
      "256 models done. time 6s\n",
      "512 models done. time 11s\n",
      "1024 models done. time 23s\n",
      "2048 models done. time 45s\n",
      "4096 models done. time 90s\n",
      "CPU times: user 1min 24s, sys: 25.6 s, total: 1min 50s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "y_train = to_one_hot(labels_train, num_classes).to(device)\n",
    "y_test  = to_one_hot(labels_test,  num_classes).to(device)\n",
    "\n",
    "train_kernel, test_kernel = compute_kernels(models, X_train, X_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "r_4o9XWILTWP",
    "outputId": "1983743d-ab2b-4e18-d660-f91ef6777600"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000, 1.9919, 1.9859, 1.9944, 1.9915],\n",
       "        [1.9919, 2.0000, 1.9860, 1.9930, 1.9909],\n",
       "        [1.9859, 1.9860, 2.0000, 1.9849, 1.9886],\n",
       "        [1.9944, 1.9930, 1.9849, 2.0000, 1.9894],\n",
       "        [1.9915, 1.9909, 1.9886, 1.9894, 2.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_kernel[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "57eWORmdLwei",
    "outputId": "1e892aad-4485-48c4-a024-edc5bd726f40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9923, 1.9925, 1.9868, 1.9925, 1.9905],\n",
       "        [1.9874, 1.9901, 1.9821, 1.9857, 1.9911],\n",
       "        [1.9897, 1.9934, 1.9902, 1.9897, 1.9904],\n",
       "        [1.9886, 1.9906, 1.9872, 1.9859, 1.9903],\n",
       "        [1.9934, 1.9924, 1.9828, 1.9932, 1.9894]], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_kernel[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3KBjPusiBD8r",
    "outputId": "8ed4b0a6-c640-45bc-b63a-a82be61a314a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6070, device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e5\n",
    "\n",
    "n = len(train_kernel)\n",
    "reg = torch.eye(n).to(device) * 1e-3\n",
    "\n",
    "exp_term = - lr * compute_exp_term(- lr * (train_kernel + reg), device)\n",
    "y_pred = torch.matmul(test_kernel, torch.matmul(exp_term, - y_train))\n",
    "(y_pred.argmax(dim=1) == labels_test.to(device)).float().mean()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Myrtle10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
